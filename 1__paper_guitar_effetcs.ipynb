{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelemiko1/Paper_effects_chain/blob/main/1__paper_guitar_effetcs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HIk8qoVEAK0"
      },
      "source": [
        "###LIBRARIES, RESOURCES AND UTILS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUl-eFzomx0E",
        "outputId": "dff80b15-ec7e-4cef-ddbf-6b9f3001c2dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.7\n",
            "  Downloading tensorflow-2.7.0-cp39-cp39-manylinux2010_x86_64.whl (489.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.7/489.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (1.51.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (1.22.4)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (2.11.2)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (0.4.0)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.1/463.1 KB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (3.19.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (15.0.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (2.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (4.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (0.38.4)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (0.31.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (1.15.0)\n",
            "Collecting flatbuffers<3.0,>=1.12\n",
            "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.7) (1.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.7) (2.16.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7) (4.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow==2.7) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, flatbuffers, keras-preprocessing, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.11.0\n",
            "    Uninstalling tensorflow-2.11.0:\n",
            "      Successfully uninstalled tensorflow-2.11.0\n",
            "Successfully installed flatbuffers-2.0.7 keras-2.7.0 keras-preprocessing-1.1.2 tensorflow-2.7.0 tensorflow-estimator-2.7.0\n",
            "2.7.0\n",
            "Sat Mar 11 18:41:56 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    25W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 54.76 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "# version of tensorflow used in this project\n",
        "!pip install tensorflow==2.7\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# GPU used\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "# RAM how much\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.2f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orALk4XWnFry"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# constant values\n",
        "SEGMENT_SECONDS = 2\n",
        "SAMPLING_RATE = 22050\n",
        "NUMBER_OF_SEGMENTS = 5\n",
        "SEGMENT_LENGTH = SAMPLING_RATE * SEGMENT_SECONDS  # 44100\n",
        "\n",
        "# dataset path (input)\n",
        "# DATASET_PATH_VARY_PARAMS = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/1__dataset/separated_5effects_vary_param'\n",
        "DATASET_PATH_VARY_PARAMS_POSITION = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/1__dataset/separated_5effects_vary_param_position'\n",
        "\n",
        "# output path (output)\n",
        "# DATASET_PATH_MEL_SPEC = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/1__dataset/preprocessed/mel_spec_5eff_vary_params.pickle'\n",
        "DATASET_PATH_MEL_SPEC_POSITION = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/1__dataset/preprocessed/mel_spec_5eff_vary_params_position.pickle'\n",
        "DATASET_PATH_MEL_SPEC_PARAM = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/1__dataset/preprocessed/mel_spec_5eff_vary_params.pickle'\n",
        "DATASET_PATH_MEL_SPEC_FIXED = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/1__dataset/preprocessed/fixed_correct_s.pickle'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZekD22RsYg0"
      },
      "outputs": [],
      "source": [
        "# utils\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "\n",
        "\n",
        "def load_data_pickle(data_path):\n",
        "  with open(data_path, \"rb\") as fp:\n",
        "      data = pickle.load(fp)\n",
        "  return data\n",
        "  \n",
        "\n",
        "# build and compile the model\n",
        "def build_and_compile_model(indiv, input_shape, print_model=True):\n",
        "\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # create first conv layer + pooling layer\n",
        "  model.add(keras.layers.Conv2D(filters=indiv[1], kernel_size=(indiv[2], indiv[3]), input_shape=input_shape, activation='relu', padding='same'))\n",
        "  model.add(keras.layers.MaxPool2D(pool_size=(indiv[4], indiv[5]), padding='same'))\n",
        "  model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "  # create other conv layers + pooling layers\n",
        "  remain_conv_layer = indiv[0] - 1\n",
        "  for i in range(6, 6 + remain_conv_layer * 4, 5):\n",
        "    model.add(keras.layers.Conv2D(filters=indiv[i], kernel_size=(indiv[i+1], indiv[i+2]), activation='relu', padding='same'))\n",
        "    model.add(keras.layers.MaxPool2D(pool_size=(indiv[i+3], indiv[i+4]), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    \n",
        "  # flatten\n",
        "  model.add(keras.layers.Flatten())\n",
        "\n",
        "  # create dense layers + dropout\n",
        "  dense_layers = indiv[26]  # how many dense layers we have\n",
        "  for j in range(27, 27 + dense_layers * 2, 2):\n",
        "    model.add(keras.layers.Dense(units=indiv[j], activation='relu'))\n",
        "    model.add(keras.layers.Dropout(indiv[j+1]))\n",
        "\n",
        "  # add final layer\n",
        "  model.add(keras.layers.Dense(units=5, activation='sigmoid'))\n",
        "\n",
        "  # compile the model\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.00005)\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  if print_model:\n",
        "    print(model.summary())\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def prepare_dataset_for_guitar_cross_validation(data, test_guitar = 'tele'):\n",
        "\n",
        "    # 64000 segments in total\n",
        "\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    N_test = []\n",
        "\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    N_train = []\n",
        "    \n",
        "    count_test = 0\n",
        "    count_train = 0\n",
        "    \n",
        "    # i goes from 0 to 63999\n",
        "    for i, name in enumerate(data['names']):\n",
        "      if name[:3] == test_guitar[:3]:   \n",
        "        \n",
        "        X_test.append(data['spectrograms'][i])\n",
        "        y_test.append(data['labels'][i])\n",
        "        N_test.append(data['names'][i])\n",
        "        count_test += 1\n",
        "\n",
        "      else:\n",
        "\n",
        "        X_train.append(data['spectrograms'][i])\n",
        "        y_train.append(data['labels'][i])\n",
        "        N_train.append(data['names'][i])\n",
        "        count_train += 1\n",
        "\n",
        "    print(f'train set: {count_train}')\n",
        "    print(f'test set: {count_test} (guitar: {test_guitar})')\n",
        "\n",
        "    # from list to numpy array \n",
        "    X_train = np.array(X_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_train = np.array(y_train)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    # add 3rd dimension\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, N_train, N_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-cElUkd1kpP"
      },
      "source": [
        "### PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-5zgCmBq1Yq"
      },
      "outputs": [],
      "source": [
        "# functions for preprocessing\n",
        "def get_list_plugins(file_name):\n",
        "    \"\"\"returns the list of plugins associated to a specific audio file\n",
        "    ex: les_bridge_fing01__01101.wav returns [0, 1, 1, 0, 1]\"\"\"\n",
        "\n",
        "    # get only the string associated to plugin values es: '01101'\n",
        "    file_name_part = file_name[-9: -4]\n",
        "    list_plugins = []\n",
        "\n",
        "    for number in file_name_part:\n",
        "        if number == '0':\n",
        "            list_plugins.append(0)\n",
        "        if number == '1':\n",
        "            list_plugins.append(1)\n",
        "    return list_plugins\n",
        "\n",
        "\n",
        "def print_path_folders_files_info(path, folders, files):\n",
        "    print(\"\\n\\npath:\", path)\n",
        "    print(\"folders:\", folders)\n",
        "    print(\"how many files:\", len(files))\n",
        "    print(\"file example:\", files[:3], end=\"\\n\\n\")\n",
        "\n",
        "def print_percentage_completion(count, total_files, step):\n",
        "    if count % step == 0:\n",
        "        print(\"progress\", round(count/total_files, 2), \"%\")\n",
        "    return count + 1\n",
        "\n",
        "def prepare_dataset(dataset_path, mel_spec_path):\n",
        "    \"\"\"saves mel-spectrogram and label for each audio file (segment)\"\"\"\n",
        "\n",
        "    data = {\n",
        "        \"names\":[],\n",
        "        \"spectrograms\": [],  # [ spec1, spec2, spec3, ...]\n",
        "        \"labels\": []        # [ [0,0,0,1,0], [0,1,0,1,1], [1,1,1,0,0], ...]\n",
        "    }\n",
        "    files_count = 0\n",
        "\n",
        "    count = 0\n",
        "    for i, (path, folders, files) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        # path: /content/.../1__dataset/separated_5effects_vary_param\n",
        "        # folders: ['les', 'prs', 'tele', 'str']\n",
        "        # files: []\n",
        "\n",
        "        if path is not dataset_path:\n",
        "\n",
        "            print_path_folders_files_info(path, folders, files)\n",
        "            \n",
        "            for file_name in files:\n",
        "                \n",
        "                # monitor percentage of completion\n",
        "                count = print_percentage_completion(count, 12800, 128)\n",
        "\n",
        "                file_path = os.path.join(path, file_name)  # get the entire path\n",
        "                audio_file, sr = librosa.load(file_path, sr=SAMPLING_RATE)  # load audio file                    \n",
        "                y = get_list_plugins(file_name)  # get the current label\n",
        "  \n",
        "                # divide the signal into segments and store\n",
        "                for segment_index in range(NUMBER_OF_SEGMENTS):\n",
        "\n",
        "                    # divide signal into segments\n",
        "                    segment_start = segment_index * SEGMENT_LENGTH\n",
        "                    current_segment = audio_file[segment_start:segment_start + SEGMENT_LENGTH]\n",
        "\n",
        "                    # get the mel spectrogram\n",
        "                    mel_spectrogram = librosa.feature.melspectrogram(y=current_segment, sr=SAMPLING_RATE, n_fft=2048,\n",
        "                                                                      hop_length=512, n_mels=128)\n",
        "                    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram)\n",
        "                    log_mel_spectrogram = log_mel_spectrogram.T\n",
        "\n",
        "                    # save data      \n",
        "                    current_name = file_name[:-4] + f'__segm{segment_index + 1}'             \n",
        "                    data[\"spectrograms\"].append(log_mel_spectrogram.tolist())\n",
        "                    data[\"labels\"].append(y)\n",
        "                    data[\"names\"].append(current_name)\n",
        "                \n",
        "    with open(mel_spec_path, \"wb\") as fb:\n",
        "        pickle.dump(data, fb)\n",
        "\n",
        "prepare_dataset(DATASET_PATH_VARY_PARAMS_POSITION, DATASET_PATH_MEL_SPEC_POSITION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mc4ChhngPsX"
      },
      "outputs": [],
      "source": [
        "# load dataset of mel spec\n",
        "def load_data_pickle(data_path):\n",
        "  with open(data_path, \"rb\") as fp:\n",
        "      data = pickle.load(fp)\n",
        "  return data\n",
        "  \n",
        "entire_dataset = load_data_pickle(DATASET_PATH_MEL_SPEC_POSITION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "uOX806Jmg5co",
        "outputId": "124b08fa-e95f-4e02-9aab-17b1b2235d32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "indeces: [ 1430 23230 57717 16349  1677 47476]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1368x576 with 7 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plotting 6 random mel spectrograms\n",
        "dataset_length = len(entire_dataset[\"labels\"])\n",
        "\n",
        "indeces = np.random.randint(dataset_length, size=6)  # ex. [ 9467 43814 58297  3831 29183 55152]\n",
        "print(\"indeces:\", indeces)\n",
        "\n",
        "spectrograms = []\n",
        "labels = []\n",
        "\n",
        "# save names and spectrograms (transposing them)\n",
        "for index in indeces:\n",
        "  spectrogram = np.array(entire_dataset[\"spectrograms\"][index]).T\n",
        "  spectrograms.append(spectrogram)\n",
        "\n",
        "  label = entire_dataset[\"names\"][index]\n",
        "  labels.append(label)\n",
        "\n",
        "# position of each spectrgram in the figure\n",
        "index_config = [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)] \n",
        "\n",
        "# plot the spectrograms\n",
        "fig, ax = plt.subplots(2, 3, figsize=(19, 8))\n",
        "for i in range(6):\n",
        "  img = librosa.display.specshow(spectrograms[i], y_axis='mel', sr=22050, fmax=11050, ax=ax[index_config[i]])\n",
        "  img = librosa.display.specshow(spectrograms[i] - np.max(spectrograms[i]), y_axis='mel', sr=22050, fmax=11050, ax=ax[index_config[i]]) #max=0db\n",
        "  ax[index_config[i]].set(title=labels[i])\n",
        "\n",
        "ax[1, 0].set_xlabel(\"Time\")\n",
        "ax[1, 1].set_xlabel(\"Time\")\n",
        "ax[1, 2].set_xlabel(\"Time\")\n",
        "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
        "\n",
        "# save graph \n",
        "save_path_mel_spec = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/4__plots/mel_spec_examples_300_black.png'\n",
        "#plt.savefig(save_path_mel_spec)\n",
        "plt.savefig(save_path_mel_spec, dpi=300)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wqMuxPbC84h"
      },
      "outputs": [],
      "source": [
        "def investigate_data(data):\n",
        "\n",
        "  # verify some informations about data dictionary\n",
        "  print(f\"type of data is: {type(data)}\")\n",
        "  print(f\"dictionary keys of dict are: {data.keys()}\")\n",
        "\n",
        "  # shape\n",
        "  print(f\"shape of data['spectrograms'] is: {np.shape(data['spectrograms'])}\")\n",
        "  print(f\"shape of data['labels'] is: {np.shape(data['labels'])}\")\n",
        "\n",
        "  # length\n",
        "  print(f\"len of data['spectrograms'] is: {len(data['spectrograms'])}\")\n",
        "  print(f\"len of data['labels'] is: {len(data['labels'])}\")\n",
        "\n",
        "  # type\n",
        "  print(f\"type of data['spectrograms'] is: {type(data['spectrograms'])}\")\n",
        "  print(f\"type of data['labels'] is: {type(data['labels'])}\")\n",
        "\n",
        "  # one element\n",
        "  print(f\"one element in data['names'] is: {data['names'][12]}\")\n",
        "  print(f\"one element in data['spectrograms'] is: {data['spectrograms'][12]}\")\n",
        "  print(f\"one element in data['labels'] is: {data['labels'][12]}\")\n",
        "\n",
        "investigate_data(entire_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsZrLj4NuwQb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ctxo4VT0ui4A"
      },
      "outputs": [],
      "source": [
        "# MODIFY NAME spectrogram into spectrograms!!\n",
        "\n",
        "# # view structure of fixed dataset\n",
        "# entire_dataset_1_fixed = load_data_pickle(DATASET_PATH_MEL_SPEC_FIXED)\n",
        "\n",
        "# # export fixed dataset (dataset 1) with correction spectrogram -> spectrograms\n",
        "# #dictionary[new_key] = dictionary.pop(old_key)\n",
        "# print(entire_dataset_1_fixed.keys())\n",
        "\n",
        "# entire_dataset_1_fixed['spectrograms'] = entire_dataset_1_fixed.pop('spectrogram')\n",
        "\n",
        "# def investigate_data(data):\n",
        "\n",
        "#   # verify some informations about data dictionary\n",
        "#   print(f\"type of data is: {type(data)}\")\n",
        "#   print(f\"dictionary keys of dict are: {data.keys()}\")\n",
        "\n",
        "#   # shape\n",
        "#   print(f\"shape of data['spectrograms'] is: {np.shape(data['spectrograms'])}\")\n",
        "#   print(f\"shape of data['labels'] is: {np.shape(data['labels'])}\")\n",
        "\n",
        "#   # length\n",
        "#   print(f\"len of data['spectrograms'] is: {len(data['spectrograms'])}\")\n",
        "#   print(f\"len of data['labels'] is: {len(data['labels'])}\")\n",
        "\n",
        "#   # type\n",
        "#   print(f\"type of data['spectrograms'] is: {type(data['spectrograms'])}\")\n",
        "#   print(f\"type of data['labels'] is: {type(data['labels'])}\")\n",
        "\n",
        "#   # one element\n",
        "#   print(f\"one element in data['names'] is: {data['names'][12]}\")\n",
        "#   print(f\"one element in data['spectrograms'] is: {data['spectrograms'][12]}\")\n",
        "#   print(f\"one element in data['labels'] is: {data['labels'][12]}\")\n",
        "\n",
        "# investigate_data(entire_dataset_1_fixed)\n",
        "\n",
        "\n",
        "# #new_path = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/1__dataset/preprocessed/fixed_correct_s.pickle'\n",
        "\n",
        "# #with open(new_path, \"wb\") as fb:\n",
        "# #  pickle.dump(entire_dataset_1_fixed, fb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAMbPZI7DuBh"
      },
      "source": [
        "### BASIC CLASSIFICATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrvUBssADiip"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# load dataset of mel spec\n",
        "def load_data_pickle(data_path):\n",
        "  with open(data_path, \"rb\") as fp:\n",
        "      data = pickle.load(fp)\n",
        "  return data\n",
        "  \n",
        "\n",
        "def divide_dataset_into_train_test(data):\n",
        "    X = np.array(data[\"spectrograms\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def verify_input_shape(file):\n",
        "    shape = np.shape(file)\n",
        "    print(f\"X input shape is {shape}\\nthe meaning is (samples, frames, coefficients)\")\n",
        "\n",
        "\n",
        "def normalize_spectrogram(matrix):\n",
        "    \"\"\"normalizes between 0 and 1\"\"\"\n",
        "    min = np.min(matrix)\n",
        "    max = np.max(matrix)\n",
        "    new_matrix = (matrix - min) / (max - min)\n",
        "    return new_matrix\n",
        "\n",
        "\n",
        "def standardize_spectrogram(matrix):\n",
        "    mean = np.mean(matrix)\n",
        "    std = np.std(matrix)\n",
        "    new_matrix = (matrix - mean) / std\n",
        "    return new_matrix\n",
        "\n",
        "\n",
        "def build_model(input_shape):\n",
        "    \n",
        "    # create model\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # 1st conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # 2nd conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # 3rd conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPool2D((2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    # 4th conv layer\n",
        "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(keras.layers.MaxPool2D((2,2), strides=(2, 2), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    \n",
        "    # flatten the output and feed into dense layer\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    model.add(keras.layers.Dense(32, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "\n",
        "    model.add(keras.layers.Dense(32, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "\n",
        "    # output layer\n",
        "    model.add(keras.layers.Dense(5, activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def compile_model(model, learning_rate=0.001):  \n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "\n",
        "def prepare_dataset_for_guitar_cross_validation(data, test_guitar = 'strato'):\n",
        "\n",
        "    # 64000 segments in total\n",
        "\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    N_test = []\n",
        "\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    N_train = []\n",
        "    \n",
        "    count_test = 0\n",
        "    count_train = 0\n",
        "    \n",
        "    # i goes from 0 to 63999\n",
        "    for i, name in enumerate(data['names']):\n",
        "      if name[:3] == test_guitar[:3]:   \n",
        "        \n",
        "        X_test.append(data['spectrograms'][i])\n",
        "        y_test.append(data['labels'][i])\n",
        "        N_test.append(data['names'][i])\n",
        "        count_test += 1\n",
        "\n",
        "      else:\n",
        "\n",
        "        X_train.append(data['spectrograms'][i])\n",
        "        y_train.append(data['labels'][i])\n",
        "        N_train.append(data['names'][i])\n",
        "        count_train += 1\n",
        "\n",
        "    print(f'train set: {count_train}')\n",
        "    print(f'test set: {count_test} (guitar: {test_guitar})')\n",
        "\n",
        "    # from list to numpy array \n",
        "    X_train = np.array(X_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_train = np.array(y_train)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    # add 3rd dimension\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, N_train, N_test\n",
        "\n",
        "\n",
        "CNN_MODEL_SAVE_PATH = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/2__models/manually_selected/CNN_vary_param_manual_position_vX.h5'\n",
        "\n",
        "def generic_cnn(entire_dataset):\n",
        "\n",
        "  # new - use one guitar as test the other 3 guitars as train\n",
        "  X_train, X_test, y_train, y_test, N_train, N_test = prepare_dataset_for_guitar_cross_validation(entire_dataset, 'tele')\n",
        "\n",
        "  # build the CNN net\n",
        "  input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
        "  print(f\"input_shape: {input_shape}\")\n",
        "\n",
        "  model = build_model(input_shape)\n",
        "  model = compile_model(model, learning_rate=0.00005)\n",
        "  history = model.fit(X_train, y_train,\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      batch_size=64, epochs=20, shuffle=True) \n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_pred = y_pred.round()\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(f\"sklearn_accuracy:\", accuracy)\n",
        "\n",
        "  # plot history and save model\n",
        "  plot_history(history)\n",
        "  model.save(CNN_MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vUjleBMqH-jn",
        "outputId": "6504381a-0d7a-4316-e957-95ee510fb910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set: 48000\n",
            "test set: 16000 (guitar: tele)\n",
            "input_shape: (87, 128, 1)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 85, 126, 32)       320       \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 43, 63, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 43, 63, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 41, 61, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 21, 31, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 21, 31, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 19, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 10, 15, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 10, 15, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 8, 13, 32)         9248      \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 4, 7, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 4, 7, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 896)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                28704     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58,501\n",
            "Trainable params: 58,245\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "750/750 [==============================] - 255s 339ms/step - loss: 0.6194 - accuracy: 0.2504 - val_loss: 0.5409 - val_accuracy: 0.3645\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 253s 337ms/step - loss: 0.5509 - accuracy: 0.3175 - val_loss: 0.4971 - val_accuracy: 0.3920\n",
            "Epoch 3/20\n",
            "418/750 [===============>..............] - ETA: 1:45 - loss: 0.5156 - accuracy: 0.3621"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f0801b618509>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mentire_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH_MEL_SPEC_POSITION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgeneric_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentire_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-d9703e871c40>\u001b[0m in \u001b[0;36mgeneric_cnn\u001b[0;34m(entire_dataset)\u001b[0m\n\u001b[1;32m    173\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m   history = model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m    176\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                       batch_size=64, epochs=20, shuffle=True) \n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "entire_dataset = load_data_pickle(DATASET_PATH_MEL_SPEC_POSITION)\n",
        "generic_cnn(entire_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtvmOAP2R2Ne"
      },
      "outputs": [],
      "source": [
        "# STATISTICS considering each segment separately\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "CNN_MODEL_SAVE_PATH = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/2__models/manually_selected/CNN_vary_param_manual_position_v2.h5'\n",
        "\n",
        "# make predictions on the test set\n",
        "model = tf.keras.models.load_model(CNN_MODEL_SAVE_PATH)\n",
        "X_train, X_test, y_train, y_test, N_train, N_test = prepare_dataset_for_guitar_cross_validation(entire_dataset, 'tele')\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred.round()\n",
        "\n",
        "# print precision recall and f1-score\n",
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    output_dict=False,\n",
        "    target_names=['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "))\n",
        "\n",
        "\n",
        "# MAJORITY VOTE\n",
        "\n",
        "# verify that the segments order is correct\n",
        "count_correct_audio_files=0\n",
        "for index in range(len(y_test)):\n",
        "  if N_test[index][-5:] == 'segm1':\n",
        "    if N_test[index+1][-5:] == 'segm2':\n",
        "      if N_test[index+2][-5:] == 'segm3':\n",
        "        if N_test[index+3][-5:] == 'segm4':\n",
        "          if N_test[index+4][-5:] == 'segm5':\n",
        "            count_correct_audio_files +=1      \n",
        "print(\"correct segment sequence (should be 3200):\", count_correct_audio_files)\n",
        "\n",
        "\n",
        "# verify that the y_test and N_names correspond\n",
        "correct_correspondecies = 0\n",
        "for index in range(len(y_test)):\n",
        "  if N_test[index][-12:-7] == '{}{}{}{}{}'.format(*y_test[index]):\n",
        "    correct_correspondecies+=1\n",
        "print(\"correct correspondance of names and labels (should be 16000):\", correct_correspondecies)\n",
        "\n",
        "\n",
        "def get_correct_answer_for_5_segments(y_pred, index):\n",
        "\n",
        "  y_majority_vote = []  \n",
        "  # consider the vote for each label (0, 1, 2, 3, 4)\n",
        "  for label in range(5):    \n",
        "    # create a vector with the answer of each of the 5 segments for a single class\n",
        "    answer_of_each_segment = [y_pred[index+s][label] for s in range(5)]    \n",
        "    # get the mean to get the most voted answer\n",
        "    result = np.mean(answer_of_each_segment)\n",
        "    if result > 0.5:\n",
        "      y_majority_vote.append(1)\n",
        "    else:\n",
        "      y_majority_vote.append(0)\n",
        "\n",
        "  return y_majority_vote\n",
        "  \n",
        "\n",
        "def get_y_pred_fusing_segment_results(y_pred):\n",
        "  \n",
        "  y_pred_audio = []\n",
        "  for index in range(len(y_pred)):\n",
        "    if N_test[index][-5:] == 'segm1':      \n",
        "      y_pred_audio.append(get_correct_answer_for_5_segments(y_pred, index))\n",
        "      \n",
        "  return y_pred_audio\n",
        "\n",
        "\n",
        "def get_y_true_fusing_segment_resuls(y_test):\n",
        "  y_test_audio = []\n",
        "  for index in range(len(y_test)):\n",
        "    # consider only the value of segm1 (which is the same if segm2, 3, 4,4)\n",
        "    if N_test[index][-5:] == 'segm1':\n",
        "      y_test_audio.append(y_test[index])\n",
        "      \n",
        "  return y_test_audio\n",
        "\n",
        "# compute y_pred (and y_test) using majority vote\n",
        "y_pred_audio = get_y_pred_fusing_segment_results(y_pred)\n",
        "y_test_audio = get_y_pred_fusing_segment_results(y_test)\n",
        "\n",
        "print('\\n', classification_report(\n",
        "    y_test_audio,\n",
        "    y_pred_audio,\n",
        "    output_dict=False,\n",
        "    target_names=['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "))\n",
        "\n",
        "\n",
        "# plot confusion matrix for each effect\n",
        "def normalize_confusion_matrix(matrix):\n",
        "  return normalize(matrix, axis=1, norm='l1')\n",
        "\n",
        "\n",
        "def plot_confusio_matrix_multilabel(y_test, y_pred, normalize=True):\n",
        "\n",
        "  # get confusion matrix for each label and normalize\n",
        "  multilabel_cm = multilabel_confusion_matrix(y_test, y_pred)\n",
        "  if normalize:\n",
        "    multilabel_cm = np.array(list(map(normalize_confusion_matrix, multilabel_cm)))\n",
        "    multilabel_cm = np.around(multilabel_cm, decimals=2)\n",
        "\n",
        "  # create subplots\n",
        "  fig, ax = plt.subplots(2, 3, figsize=(13, 9))\n",
        "    \n",
        "  # position of each spectrgram in the figure\n",
        "  indeces_config = [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1)]\n",
        "\n",
        "  labels = ['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "\n",
        "  for numeration, (index, confusion_matrix) in enumerate(zip(indeces_config, multilabel_cm)):\n",
        "\n",
        "    ax[index].matshow(confusion_matrix, cmap=plt.cm.Blues, alpha=0.5)\n",
        "    for i in range(confusion_matrix.shape[0]):\n",
        "      for j in range(confusion_matrix.shape[1]):\n",
        "          ax[index].text(x=j, y=i, s=confusion_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        "          ax[index].set_title(labels[numeration], size='xx-large')\n",
        "          ax[index].set_xlabel('predicted label')\n",
        "          ax[index].set_ylabel('true label')\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plot_confusio_matrix_multilabel(y_test, y_pred, normalize=True)\n",
        "plot_confusio_matrix_multilabel(y_test_audio, y_pred_audio, normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo0y2ZxXtNsd"
      },
      "source": [
        "### OPTIMIZATION WITH GENETIC ALGORITHMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgEAmD4cs-VB"
      },
      "outputs": [],
      "source": [
        "from random import randint, uniform, random\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import time\n",
        "import gc\n",
        "\n",
        "\n",
        "# load dataset of mel spec\n",
        "def load_data_pickle(data_path):\n",
        "  with open(data_path, \"rb\") as fp:\n",
        "      data = pickle.load(fp)\n",
        "  return data\n",
        "\n",
        "\n",
        "def divide_dataset_into_train_test(data):\n",
        "    X = np.array(data[\"spectrograms\"])\n",
        "    y = np.array(data[\"labels\"])\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def initialize_first_population(population_size, verbose=True, start_with_low_values=True):\n",
        "  \"\"\"Initialize the fist population of Genetic Algorithms(GAs).\n",
        "  Create each individual randomly\"\"\"\n",
        "\n",
        "  # parameters\n",
        "  # 0 - HOW MANY CONV. LAYERS                   [min: 1, max: 5]\n",
        "  \n",
        "  # 1 - filters          of 1st conv layer      [2 -> 64]\n",
        "  # 2 - x kernel dim.    of 1st conv layer      [2 -> 7]\n",
        "  # 3 - y kernel dim.    of 1st conv layer      [2 -> 7]\n",
        "  # 4 - x size           of 1st maxpool layer   [1 -> 2]\n",
        "  # 5 - y size           of 1st maxpool layer   [1 -> 2]\n",
        "\n",
        "  #  6,  7,  8,  9, 10 - same but considering 2nd layer (if present)\n",
        "  # 11, 12, 13, 14, 15 - same but considering 3rd layer (if present)\n",
        "  # 16, 17, 18, 19, 20 - same but considering 4th layer (if present)\n",
        "  # 21, 22, 23, 24, 25 - same but considering 5th layer (if present)\n",
        "  # ----------------------------------------------------\n",
        "  \n",
        "  # 26 - HOW MANY DENSE LAYERS [min: 1, max: 3]\n",
        "  \n",
        "  # 27 - neurons         of 1st dense layer     [2 -> 64]\n",
        "  # 28 - dropout prob.   of 1st dense layer     [0 -> 0.5]\n",
        "  # 29 - neurons         of 2nd dense layer (if present)\n",
        "  # 30 - dropout prob.   of 2nd dense layer (if present)\n",
        "  # 31 - neurons         of 3rd dense layer (if present)\n",
        "  # 32 - dropout prob.   of 3rd dense layer (if present)\n",
        "\n",
        "  print_info_first_individual = verbose\n",
        "  \n",
        "  \n",
        "  # list that will contain all the individuals\n",
        "  population = []\n",
        "\n",
        "  for individual_index in range(population_size):\n",
        "    \n",
        "    if verbose:\n",
        "      print(f\"Creating individual {individual_index + 1} out of {population_size}\")\n",
        "    \n",
        "    current_individual = [0] * 33  # [0, 0, 0...., 0]\n",
        "    \n",
        "    # define how many conv layers and dense layers\n",
        "    current_individual[0] = randint(1, 5)\n",
        "    current_individual[26] = randint(1, 3)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working on # of filters' of conv layers  (index: 1, 6, 11, 16, 21)\")\n",
        "    for list_index in range(1, 22, 5):\n",
        "      if start_with_low_values:\n",
        "        current_individual[list_index] = randint(2, 8)\n",
        "      else:\n",
        "        current_individual[list_index] = randint(2, 64)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working on x and y kernel dimensions     (index: 2, 3, 7, 8, 12, 13, 17, 18, 22, 23)\")\n",
        "    for list_index in range(2, 23, 5):\n",
        "      current_individual[list_index] = randint(2, 7)\n",
        "      current_individual[list_index + 1] = randint(2, 7)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working on x and y MaxPooling size       (index: 4, 5, 9, 10, 14, 15, 19, 20, 24, 25)\")\n",
        "    for list_index in range(4, 25, 5):\n",
        "      current_individual[list_index] = randint(1, 2)\n",
        "      current_individual[list_index + 1] = randint(1, 2)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working # of neurons in dense layers     (index: 27, 29, 31)\")\n",
        "    for list_index in range(27, 32, 2):\n",
        "      if start_with_low_values:\n",
        "        current_individual[list_index] = randint(2, 8)\n",
        "      else:\n",
        "        current_individual[list_index] = randint(2, 64)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working dropout prob. after dense layers (index: 28, 30, 32)\")\n",
        "    for list_index in range(28, 33, 2):\n",
        "      # round approx. the number to second decimal\n",
        "      current_individual[list_index] = round(uniform(0.0, 0.5), 2)\n",
        "\n",
        "    if verbose:\n",
        "      print(current_individual, end=\"\\n\\n\")\n",
        "\n",
        "    population.append(current_individual)\n",
        "\n",
        "    print_info_first_individual = False\n",
        "      \n",
        "  return population\n",
        "\n",
        "\n",
        "# build and compile the model\n",
        "def build_and_compile_model(indiv, input_shape):\n",
        "\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # create first conv layer + pooling layer\n",
        "  model.add(keras.layers.Conv2D(filters=indiv[1], kernel_size=(indiv[2], indiv[3]), input_shape=input_shape, activation='relu', padding='same'))\n",
        "  model.add(keras.layers.MaxPool2D(pool_size=(indiv[4], indiv[5]), padding='same'))\n",
        "  model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "  # create other conv layers + pooling layers\n",
        "  remain_conv_layer = indiv[0] - 1\n",
        "  for i in range(6, 6 + remain_conv_layer * 4, 5):\n",
        "    model.add(keras.layers.Conv2D(filters=indiv[i], kernel_size=(indiv[i+1], indiv[i+2]), activation='relu', padding='same'))\n",
        "    model.add(keras.layers.MaxPool2D(pool_size=(indiv[i+3], indiv[i+4]), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    \n",
        "  # flatten\n",
        "  model.add(keras.layers.Flatten())\n",
        "\n",
        "  # create dense layers + dropout\n",
        "  dense_layers = indiv[26]  # how many dense layers we have\n",
        "  for j in range(27, 27 + dense_layers * 2, 2):\n",
        "    model.add(keras.layers.Dense(units=indiv[j], activation='relu'))\n",
        "    model.add(keras.layers.Dropout(indiv[j+1]))\n",
        "\n",
        "  # add final layer\n",
        "  model.add(keras.layers.Dense(units=5, activation='sigmoid'))\n",
        "\n",
        "  # compile the model\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.00005)\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model\n",
        "\n",
        "#individual = [2, 44, 3, 7, 1, 1, 33, 2, 2, 1, 2, 51, 6, 5, 1, 1, 28, 5, 5, 2, 1, 36, 3, 4, 2, 1, 3, 9, 0.15, 63, 0.13, 38, 0.25]\n",
        "#build_and_compile_model(individual, (78, 80, 1))\n",
        "\n",
        "\n",
        "#INPUT_SHAPE = (87, 128)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def fitness_evaluation(individual, dataset):\n",
        "\n",
        "  # print current individual\n",
        "  print(f\"fitness_evaluation function. Individual considered:\\n{individual}\")\n",
        "\n",
        "  # get train and test data from dataset\n",
        "  (X_train, y_train), (X_valid, y_valid) = dataset\n",
        "\n",
        "  # build CNN associated to the individual\n",
        "  input_shape = np.shape(X_train[1])\n",
        "  model = build_and_compile_model(individual, input_shape)\n",
        "\n",
        "  # evaluate the model/individual (implementing early stopping??)\n",
        "  model.fit(X_train, y_train, epochs=15, batch_size=64, shuffle=True, validation_data = (X_valid, y_valid))\n",
        "\n",
        "  # get the accuracy on valid set (not used now)\n",
        "  loss, accuracy = model.evaluate(X_valid, y_valid)   # can use loss intead of accuracy\n",
        "\n",
        "  # NEW - sklearn accuracy\n",
        "  y_pred = model.predict(X_valid)\n",
        "  y_pred = y_pred.round()\n",
        "  sklearn_accuracy = accuracy_score(y_valid, y_pred)\n",
        "  print(f\"sklearn_accuracy:\", sklearn_accuracy)\n",
        "\n",
        "  # I can consider to return - (1/loss)\n",
        "  return sklearn_accuracy\n",
        "\n",
        "\n",
        "# population evaluation (funzione testata)\n",
        "def population_evaluation(population, dataset):\n",
        "  \"\"\"population_evaluation gets the performace of each individual in the current population\"\"\"\n",
        "  \n",
        "  # dictionary to store information about population\n",
        "  population_eval ={\n",
        "      \"population\":[],\n",
        "      \"fitness\":[],\n",
        "      \"probability\":[],\n",
        "      \"best_individual\": [],\n",
        "      \"statistics\": {\"min\":0, \"max\":0, \"average\":0}\n",
        "  }\n",
        "\n",
        "  # save pupulation into dictionary\n",
        "  population_eval[\"population\"] = population.copy()\n",
        "\n",
        "  # perform and save fitness for each individual - enumerate counts starting from 1\n",
        "  for i, individual in enumerate(population, 1):\n",
        "\n",
        "    # Here a CNN is built and evaluated\n",
        "    print(f\"\\n({i}/{POPULATION_SIZE})\", end=\" - \")\n",
        "    fitness = fitness_evaluation(individual, dataset)\n",
        "\n",
        "    # free memory occupied by keras model\n",
        "    gc.collect()\n",
        "\n",
        "    population_eval[\"fitness\"].append(fitness)\n",
        "  \n",
        "  # perform and save probability for each individual\n",
        "  sum_of_fitnesses = np.sum(population_eval[\"fitness\"])\n",
        "  for fitness_value in population_eval[\"fitness\"]:\n",
        "    probability_value = fitness_value / sum_of_fitnesses\n",
        "    population_eval[\"probability\"].append(probability_value)\n",
        "\n",
        "  # save best individual\n",
        "  best_individual_index = np.argmax(population_eval[\"fitness\"])\n",
        "  best_individual = population_eval[\"population\"][best_individual_index]\n",
        "  population_eval[\"best_individual\"].append(best_individual)\n",
        "\n",
        "  # save min, max and average\n",
        "  max = np.max(population_eval[\"fitness\"])\n",
        "  min = np.min(population_eval[\"fitness\"])\n",
        "  average = np.average(population_eval[\"fitness\"])\n",
        "\n",
        "  population_eval[\"statistics\"][\"min\"] = min\n",
        "  population_eval[\"statistics\"][\"max\"] = max\n",
        "  population_eval[\"statistics\"][\"average\"] = average\n",
        "\n",
        "  return population_eval\n",
        "\n",
        "\n",
        "# selection function\n",
        "def selection(population_eval):\n",
        "  \"\"\"selects one individual based on roulette wheels selection\"\"\"\n",
        "\n",
        "  # implement roulette wheel selection\n",
        "  R = random()\n",
        "\n",
        "  # first iter (p.1), second iter (p.1 + p.2), ...\n",
        "  sum_of_probabilities = 0\n",
        "  \n",
        "  for index in range(len(population_eval[\"probability\"])):\n",
        "\n",
        "    sum_of_probabilities += population_eval[\"probability\"][index]\n",
        "\n",
        "    if sum_of_probabilities > R:\n",
        "\n",
        "      selected_individual = population_eval[\"population\"][index]\n",
        "      break\n",
        "\n",
        "  return selected_individual, index\n",
        "\n",
        "\n",
        "def select_two_individuals(population_eval):\n",
        "  \"\"\"selects two different individuals in current population \"\"\"\n",
        "\n",
        "  first_individual, first_index = selection(population_eval)\n",
        "  second_individual, second_index = selection(population_eval)\n",
        "\n",
        "  while first_index == second_index:\n",
        "    second_individual, second_index = selection(population_eval)\n",
        "\n",
        "  return first_individual, second_individual\n",
        "\n",
        "\n",
        "# crossover function\n",
        "def single_point_crossover(individual_1, individual_2, CROSSOVER_PROB):\n",
        "  \"\"\"performs single point crossover between two individuals with a certain probability.\n",
        "  returns 1' individual if crossover is not performed \"\"\"\n",
        "\n",
        "  # single point crossover\n",
        "  random_crossover_point = randint(1, len(individual_1)-1)  # how many elements I keep from 1' individual\n",
        "  #print(f\"crossover_point: {random_crossover_point}\")\n",
        "\n",
        "  # create new individual\n",
        "  new_individual = []\n",
        "  for index in range(len(individual_1)):\n",
        "    if index < random_crossover_point:\n",
        "      new_individual.append(individual_1[index])\n",
        "    else:\n",
        "       new_individual.append(individual_2[index])\n",
        "\n",
        "  # consider crossover probability\n",
        "  random_value = random()\n",
        "  \n",
        "  if CROSSOVER_PROB > random_value:\n",
        "    return new_individual\n",
        "  return individual_1\n",
        "  \n",
        "\n",
        "# mutation function\n",
        "def mutation(individual, MUTATION_PROB):\n",
        "\n",
        "  # parameters\n",
        "  # 0 - HOW MANY CONV. LAYERS                   [min: 1, max: 5]\n",
        "  \n",
        "  # 1 - filters          of 1st conv layer      [2 -> 64]\n",
        "  # 2 - x kernel dim.    of 1st conv layer      [2 -> 7]\n",
        "  # 3 - y kernel dim.    of 1st conv layer      [2 -> 7]\n",
        "  # 4 - x size           of 1st maxpool layer   [1 -> 2]\n",
        "  # 5 - y size           of 1st maxpool layer   [1 -> 2]\n",
        "\n",
        "  #  6,  7,  8,  9, 10 - same but considering 2nd layer (if present)\n",
        "  # 11, 12, 13, 14, 15 - same but considering 3rd layer (if present)\n",
        "  # 16, 17, 18, 19, 20 - same but considering 4th layer (if present)\n",
        "  # 21, 22, 23, 24, 25 - same but considering 5th layer (if present)\n",
        "  # ----------------------------------------------------\n",
        "  \n",
        "  # 26 - HOW MANY DENSE LAYERS [min: 1, max: 3]\n",
        "  \n",
        "  # 27 - neurons         of 1st dense layer     [2 -> 64]\n",
        "  # 28 - dropout prob.   of 1st dense layer     [0 -> 0.5]\n",
        "  # 29 - neurons         of 2nd dense layer (if present)\n",
        "  # 30 - dropout prob.   of 2nd dense layer (if present)\n",
        "  # 31 - neurons         of 3rd dense layer (if present)\n",
        "  # 32 - dropout prob.   of 3rd dense layer (if present)\n",
        "\n",
        "  # define how many conv layers and dense layers\n",
        "    \n",
        "  indeces_with_filters_or_neurons = [1, 6, 11, 16, 21, 27, 29, 31]\n",
        "  indeces_with_kernel_dim = [2, 3, 7, 8, 12, 13, 17, 18, 22, 23]\n",
        "  indeces_with_MaxPool_dim = [4, 5, 9, 10, 14, 15, 19, 20, 24, 25]\n",
        "  indeces_with_dropout_prob = [28, 30, 32]\n",
        "\n",
        "  for index in range(len(individual)):\n",
        "\n",
        "    random_number = random()\n",
        "    if MUTATION_PROB > random_number:\n",
        "\n",
        "      # new - use lower probability (half!) for number of layers\n",
        "      if random() > 0.5:  # not in thesis implementation\n",
        "        if index == 0:\n",
        "          individual[index] = randint(1, 5)\n",
        "\n",
        "        if index == 26:\n",
        "          individual[index] = randint(1, 3)\n",
        "\n",
        "      # consider conv filters and neurons in dense layer\n",
        "      if index in indeces_with_filters_or_neurons:\n",
        "        new_value = individual[index] + randint(-3, 3) + 5  # in thesis implementation +3 (not + 5)\n",
        "        # if value is not in range try again\n",
        "        while (not 2 <= new_value <= 64):\n",
        "          new_value = individual[index] + randint(-3, 3) + 5\n",
        "        individual[index] = new_value\n",
        "\n",
        "      # consider kernel dimension\n",
        "      if index in indeces_with_kernel_dim:\n",
        "        individual[index] = randint(2, 7)\n",
        "\n",
        "      # consider maxpool dimension\n",
        "      if index in indeces_with_MaxPool_dim:\n",
        "        individual[index] = randint(1, 2)\n",
        "\n",
        "      # consider dropout probability\n",
        "      if index in indeces_with_dropout_prob:\n",
        "\n",
        "        variation = (random() - 0.5) * 0.2  # from [-0.1 to 0.1) \n",
        "        new_value = round(individual[index] + variation, 2)\n",
        "        # if value is not in range try again (try to avoid -0.0)\n",
        "\n",
        "        while (not 0.001 <= new_value <= 0.5):\n",
        "          variation = (random() - 0.5) * 0.2\n",
        "          new_value = round(individual[index] + variation, 2)\n",
        "        individual[index] = new_value \n",
        "\n",
        "  # I'm not makineg individual.copy at the beginning, so I'm modifying the individual\n",
        "  return individual\n",
        "\n",
        "    \n",
        "   \n",
        "#individual = [2, 44, 3, 7, 1, 1, 33, 2, 2, 1, 2, 51, 6, 5, 1, 1, 28, 5, 5, 2, 1, 36, 3, 4, 2, 1, 3, 9, 0.15, 63, 0.13, 38, 0.25]\n",
        "#print(mutation(individual, 0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIXQe_RTw7GN",
        "outputId": "c02e2b40-155c-430f-a204-45a6352813f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/1__gen_algorithm_optimization/statistics_11Mar2023_position_P8_G1_no_low_values.json\n",
            "Creating individual 1 out of 8\n",
            "- working on # of filters' of conv layers  (index: 1, 6, 11, 16, 21)\n",
            "- working on x and y kernel dimensions     (index: 2, 3, 7, 8, 12, 13, 17, 18, 22, 23)\n",
            "- working on x and y MaxPooling size       (index: 4, 5, 9, 10, 14, 15, 19, 20, 24, 25)\n",
            "- working # of neurons in dense layers     (index: 27, 29, 31)\n",
            "- working dropout prob. after dense layers (index: 28, 30, 32)\n",
            "[1, 7, 7, 2, 1, 1, 23, 5, 3, 2, 2, 63, 2, 7, 1, 2, 48, 2, 2, 1, 1, 36, 5, 4, 1, 1, 3, 10, 0.38, 19, 0.14, 38, 0.26]\n",
            "\n",
            "Creating individual 2 out of 8\n",
            "[5, 46, 2, 7, 1, 2, 3, 3, 7, 2, 2, 48, 6, 7, 1, 1, 23, 3, 4, 1, 1, 7, 2, 6, 1, 2, 2, 31, 0.3, 37, 0.37, 34, 0.08]\n",
            "\n",
            "Creating individual 3 out of 8\n",
            "[5, 28, 2, 4, 2, 2, 62, 6, 6, 1, 1, 13, 5, 6, 1, 2, 4, 2, 3, 2, 2, 15, 4, 4, 2, 1, 2, 8, 0.36, 41, 0.46, 39, 0.46]\n",
            "\n",
            "Creating individual 4 out of 8\n",
            "[4, 27, 6, 5, 2, 1, 55, 2, 2, 1, 2, 52, 6, 6, 1, 2, 44, 5, 7, 1, 2, 22, 6, 2, 2, 2, 3, 59, 0.08, 43, 0.28, 64, 0.31]\n",
            "\n",
            "Creating individual 5 out of 8\n",
            "[3, 37, 4, 3, 2, 2, 3, 3, 2, 2, 2, 34, 5, 6, 1, 2, 2, 3, 7, 2, 1, 56, 5, 5, 2, 1, 1, 9, 0.33, 28, 0.23, 35, 0.23]\n",
            "\n",
            "Creating individual 6 out of 8\n",
            "[4, 10, 6, 2, 2, 2, 28, 5, 5, 2, 1, 22, 7, 4, 1, 1, 44, 5, 6, 2, 2, 2, 2, 6, 2, 2, 3, 6, 0.01, 22, 0.28, 42, 0.39]\n",
            "\n",
            "Creating individual 7 out of 8\n",
            "[4, 27, 5, 4, 1, 2, 58, 4, 2, 1, 1, 21, 4, 3, 1, 1, 43, 4, 5, 2, 1, 28, 3, 7, 2, 2, 1, 59, 0.38, 59, 0.02, 43, 0.38]\n",
            "\n",
            "Creating individual 8 out of 8\n",
            "[3, 45, 6, 3, 2, 1, 24, 7, 5, 1, 1, 26, 6, 5, 1, 2, 3, 4, 7, 1, 2, 33, 5, 3, 1, 2, 1, 4, 0.48, 38, 0.23, 22, 0.14]\n",
            "\n",
            "(main) first population initialized\n",
            "[1, 7, 7, 2, 1, 1, 23, 5, 3, 2, 2, 63, 2, 7, 1, 2, 48, 2, 2, 1, 1, 36, 5, 4, 1, 1, 3, 10, 0.38, 19, 0.14, 38, 0.26]\n",
            "[5, 46, 2, 7, 1, 2, 3, 3, 7, 2, 2, 48, 6, 7, 1, 1, 23, 3, 4, 1, 1, 7, 2, 6, 1, 2, 2, 31, 0.3, 37, 0.37, 34, 0.08]\n",
            "[5, 28, 2, 4, 2, 2, 62, 6, 6, 1, 1, 13, 5, 6, 1, 2, 4, 2, 3, 2, 2, 15, 4, 4, 2, 1, 2, 8, 0.36, 41, 0.46, 39, 0.46]\n",
            "[4, 27, 6, 5, 2, 1, 55, 2, 2, 1, 2, 52, 6, 6, 1, 2, 44, 5, 7, 1, 2, 22, 6, 2, 2, 2, 3, 59, 0.08, 43, 0.28, 64, 0.31]\n",
            "[3, 37, 4, 3, 2, 2, 3, 3, 2, 2, 2, 34, 5, 6, 1, 2, 2, 3, 7, 2, 1, 56, 5, 5, 2, 1, 1, 9, 0.33, 28, 0.23, 35, 0.23]\n",
            "[4, 10, 6, 2, 2, 2, 28, 5, 5, 2, 1, 22, 7, 4, 1, 1, 44, 5, 6, 2, 2, 2, 2, 6, 2, 2, 3, 6, 0.01, 22, 0.28, 42, 0.39]\n",
            "[4, 27, 5, 4, 1, 2, 58, 4, 2, 1, 1, 21, 4, 3, 1, 1, 43, 4, 5, 2, 1, 28, 3, 7, 2, 2, 1, 59, 0.38, 59, 0.02, 43, 0.38]\n",
            "[3, 45, 6, 3, 2, 1, 24, 7, 5, 1, 1, 26, 6, 5, 1, 2, 3, 4, 7, 1, 2, 33, 5, 3, 1, 2, 1, 4, 0.48, 38, 0.23, 22, 0.14]\n",
            "train set: 48000\n",
            "test set: 16000 (guitar: strato)\n",
            "\n",
            "(main) dataset loaded\n",
            "X_train dimension: (48000, 87, 128, 1)\n",
            "\n",
            " - GENERATION 1\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 7, 7, 2, 1, 1, 23, 5, 3, 2, 2, 63, 2, 7, 1, 2, 48, 2, 2, 1, 1, 36, 5, 4, 1, 1, 3, 10, 0.38, 19, 0.14, 38, 0.26]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 87, 128, 7)        105       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 87, 128, 7)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 87, 128, 7)       28        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 77952)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                779530    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 19)                209       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 19)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 38)                760       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 38)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 780,827\n",
            "Trainable params: 780,813\n",
            "Non-trainable params: 14\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 17s 10ms/step - loss: 0.6941 - accuracy: 0.2009 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.2664 - val_loss: 0.6932 - val_accuracy: 0.5311\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.3192 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.2978 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.2205 - val_loss: 0.6932 - val_accuracy: 0.5311\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.2769 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.2243 - val_loss: 0.6932 - val_accuracy: 0.5311\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.2738 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.1607 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.1510 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.2031 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.1313 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.2609 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.1673 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.6932 - accuracy: 0.0974 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.2500\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 46, 2, 7, 1, 2, 3, 3, 7, 2, 2, 48, 6, 7, 1, 1, 23, 3, 4, 1, 1, 7, 2, 6, 1, 2, 2, 31, 0.3, 37, 0.37, 34, 0.08]\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 87, 128, 46)       690       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 87, 64, 46)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 87, 64, 46)       184       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 87, 64, 3)         2901      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 44, 32, 3)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 44, 32, 3)        12        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 44, 32, 48)        6096      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 44, 32, 48)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 44, 32, 48)       192       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 44, 32, 23)        13271     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 44, 32, 23)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 44, 32, 23)       92        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 44, 32, 7)         1939      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 44, 16, 7)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 44, 16, 7)        28        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4928)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 31)                152799    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 31)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 37)                1184      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 37)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 5)                 190       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 179,578\n",
            "Trainable params: 179,324\n",
            "Non-trainable params: 254\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 33s 42ms/step - loss: 0.5679 - accuracy: 0.2746 - val_loss: 0.4766 - val_accuracy: 0.4036\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.4531 - accuracy: 0.4558 - val_loss: 0.4719 - val_accuracy: 0.4863\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.4241 - accuracy: 0.4638 - val_loss: 0.3977 - val_accuracy: 0.5469\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.4081 - accuracy: 0.4721 - val_loss: 0.4636 - val_accuracy: 0.6021\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3968 - accuracy: 0.4839 - val_loss: 0.4141 - val_accuracy: 0.5488\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3877 - accuracy: 0.4957 - val_loss: 0.4230 - val_accuracy: 0.4757\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3794 - accuracy: 0.4884 - val_loss: 0.3988 - val_accuracy: 0.4238\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3707 - accuracy: 0.4787 - val_loss: 0.5205 - val_accuracy: 0.3869\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3631 - accuracy: 0.4768 - val_loss: 0.5324 - val_accuracy: 0.4349\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3591 - accuracy: 0.4634 - val_loss: 0.3856 - val_accuracy: 0.4450\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3538 - accuracy: 0.4536 - val_loss: 0.3676 - val_accuracy: 0.4405\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3482 - accuracy: 0.4541 - val_loss: 0.5223 - val_accuracy: 0.3532\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3470 - accuracy: 0.4560 - val_loss: 0.4297 - val_accuracy: 0.3996\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3425 - accuracy: 0.4597 - val_loss: 0.3930 - val_accuracy: 0.4666\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.3406 - accuracy: 0.4553 - val_loss: 0.3935 - val_accuracy: 0.3746\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.3935 - accuracy: 0.3746\n",
            "sklearn_accuracy: 0.21225\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 28, 2, 4, 2, 2, 62, 6, 6, 1, 1, 13, 5, 6, 1, 2, 4, 2, 3, 2, 2, 15, 4, 4, 2, 1, 2, 8, 0.36, 41, 0.46, 39, 0.46]\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 87, 128, 28)       252       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 44, 64, 28)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 44, 64, 28)       112       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 44, 64, 62)        62558     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 44, 64, 62)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 44, 64, 62)       248       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 44, 64, 13)        24193     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 44, 32, 13)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 44, 32, 13)       52        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 44, 32, 4)         316       \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 22, 16, 4)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 22, 16, 4)        16        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 22, 16, 15)        975       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 11, 16, 15)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 11, 16, 15)       60        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2640)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 8)                 21128     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 41)                369       \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 41)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 210       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 110,489\n",
            "Trainable params: 110,245\n",
            "Non-trainable params: 244\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 35s 45ms/step - loss: 0.6435 - accuracy: 0.0985 - val_loss: 0.5815 - val_accuracy: 0.1486\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.5699 - accuracy: 0.1289 - val_loss: 0.5378 - val_accuracy: 0.1166\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.5322 - accuracy: 0.1500 - val_loss: 0.5342 - val_accuracy: 0.1715\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.5204 - accuracy: 0.1631 - val_loss: 0.5231 - val_accuracy: 0.1911\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.5134 - accuracy: 0.1677 - val_loss: 0.5201 - val_accuracy: 0.1367\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.5086 - accuracy: 0.1664 - val_loss: 0.5147 - val_accuracy: 0.2312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.5047 - accuracy: 0.1699 - val_loss: 0.5036 - val_accuracy: 0.1764\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.5020 - accuracy: 0.1698 - val_loss: 0.4970 - val_accuracy: 0.2114\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.5008 - accuracy: 0.1744 - val_loss: 0.4949 - val_accuracy: 0.1795\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.4979 - accuracy: 0.1699 - val_loss: 0.4972 - val_accuracy: 0.1995\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.4901 - accuracy: 0.1799 - val_loss: 0.4907 - val_accuracy: 0.1988\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.4807 - accuracy: 0.1880 - val_loss: 0.4571 - val_accuracy: 0.2183\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.4696 - accuracy: 0.1989 - val_loss: 0.4549 - val_accuracy: 0.2216\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.4596 - accuracy: 0.2136 - val_loss: 0.4671 - val_accuracy: 0.2650\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.4449 - accuracy: 0.2404 - val_loss: 0.4938 - val_accuracy: 0.2632\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.4938 - accuracy: 0.2632\n",
            "sklearn_accuracy: 0.1356875\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 27, 6, 5, 2, 1, 55, 2, 2, 1, 2, 52, 6, 6, 1, 2, 44, 5, 7, 1, 2, 22, 6, 2, 2, 2, 3, 59, 0.08, 43, 0.28, 64, 0.31]\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_11 (Conv2D)          (None, 87, 128, 27)       837       \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 44, 128, 27)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 44, 128, 27)      108       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 44, 128, 55)       5995      \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 44, 64, 55)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 44, 64, 55)       220       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 44, 64, 52)        103012    \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 44, 32, 52)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 44, 32, 52)       208       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 44, 32, 44)        80124     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 44, 16, 44)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 44, 16, 44)       176       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 30976)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 59)                1827643   \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 59)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 43)                2580      \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 43)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                2816      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,024,044\n",
            "Trainable params: 2,023,688\n",
            "Non-trainable params: 356\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 48s 62ms/step - loss: 0.6148 - accuracy: 0.1306 - val_loss: 0.5786 - val_accuracy: 0.2371\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 46s 61ms/step - loss: 0.5469 - accuracy: 0.1433 - val_loss: 0.5523 - val_accuracy: 0.1642\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 46s 61ms/step - loss: 0.5240 - accuracy: 0.1447 - val_loss: 0.5005 - val_accuracy: 0.1643\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 46s 61ms/step - loss: 0.4940 - accuracy: 0.2361 - val_loss: 0.6193 - val_accuracy: 0.1227\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 46s 61ms/step - loss: 0.4604 - accuracy: 0.2914 - val_loss: 0.4598 - val_accuracy: 0.3362\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 45s 61ms/step - loss: 0.4481 - accuracy: 0.3046 - val_loss: 0.4424 - val_accuracy: 0.2798\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.4420 - accuracy: 0.3041 - val_loss: 0.4905 - val_accuracy: 0.2823\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.4366 - accuracy: 0.2966 - val_loss: 0.4446 - val_accuracy: 0.3083\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.4327 - accuracy: 0.3036 - val_loss: 0.4561 - val_accuracy: 0.3664\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.4293 - accuracy: 0.3070 - val_loss: 0.4348 - val_accuracy: 0.3256\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.4051 - accuracy: 0.3949 - val_loss: 0.4114 - val_accuracy: 0.3414\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 45s 61ms/step - loss: 0.3823 - accuracy: 0.4763 - val_loss: 0.4219 - val_accuracy: 0.4699\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 45s 61ms/step - loss: 0.3773 - accuracy: 0.5095 - val_loss: 0.4161 - val_accuracy: 0.5058\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.3720 - accuracy: 0.5338 - val_loss: 0.6627 - val_accuracy: 0.5763\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.3661 - accuracy: 0.5456 - val_loss: 0.5501 - val_accuracy: 0.5052\n",
            "500/500 [==============================] - 5s 8ms/step - loss: 0.5501 - accuracy: 0.5052\n",
            "sklearn_accuracy: 0.19375\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 37, 4, 3, 2, 2, 3, 3, 2, 2, 2, 34, 5, 6, 1, 2, 2, 3, 7, 2, 1, 56, 5, 5, 2, 1, 1, 9, 0.33, 28, 0.23, 35, 0.23]\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 87, 128, 37)       481       \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 44, 64, 37)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 44, 64, 37)       148       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 44, 64, 3)         669       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 22, 32, 3)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 22, 32, 3)        12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 22, 32, 34)        3094      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 22, 16, 34)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 22, 16, 34)       136       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 11968)             0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 9)                 107721    \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 5)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 112,311\n",
            "Trainable params: 112,163\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 17s 21ms/step - loss: 0.6936 - accuracy: 0.2552 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.1903 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.2140 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.3948 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.0938 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.1598 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.2395 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.2679 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.1954 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.2390 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.1093 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.1231 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.3206 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.1781 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6932 - accuracy: 0.1825 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.5312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 10, 6, 2, 2, 2, 28, 5, 5, 2, 1, 22, 7, 4, 1, 1, 44, 5, 6, 2, 2, 2, 2, 6, 2, 2, 3, 6, 0.01, 22, 0.28, 42, 0.39]\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 87, 128, 10)       130       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 44, 64, 10)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 44, 64, 10)       40        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 44, 64, 28)        7028      \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 22, 64, 28)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 22, 64, 28)       112       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 22, 64, 22)        17270     \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 22, 64, 22)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 22, 64, 22)       88        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 22, 64, 44)        29084     \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 11, 32, 44)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 11, 32, 44)       176       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 15488)             0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 6)                 92934     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 22)                154       \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 22)                0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 42)                966       \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 42)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 215       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 148,197\n",
            "Trainable params: 147,989\n",
            "Non-trainable params: 208\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 19s 23ms/step - loss: 0.6101 - accuracy: 0.1319 - val_loss: 0.5590 - val_accuracy: 0.0940\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.5605 - accuracy: 0.1359 - val_loss: 0.5401 - val_accuracy: 0.1325\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.5411 - accuracy: 0.1375 - val_loss: 0.5271 - val_accuracy: 0.1889\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.5201 - accuracy: 0.1384 - val_loss: 0.5370 - val_accuracy: 0.1441\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.5078 - accuracy: 0.1539 - val_loss: 0.5104 - val_accuracy: 0.1406\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4986 - accuracy: 0.1716 - val_loss: 0.4986 - val_accuracy: 0.2208\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4907 - accuracy: 0.1840 - val_loss: 0.5743 - val_accuracy: 0.1698\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4816 - accuracy: 0.1995 - val_loss: 0.4727 - val_accuracy: 0.1865\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4721 - accuracy: 0.2110 - val_loss: 0.4865 - val_accuracy: 0.2272\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4659 - accuracy: 0.2215 - val_loss: 0.4558 - val_accuracy: 0.2098\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4593 - accuracy: 0.2266 - val_loss: 0.4642 - val_accuracy: 0.2278\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4574 - accuracy: 0.2370 - val_loss: 0.4582 - val_accuracy: 0.2222\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4541 - accuracy: 0.2379 - val_loss: 0.4823 - val_accuracy: 0.2519\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4503 - accuracy: 0.2387 - val_loss: 0.4511 - val_accuracy: 0.2434\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.4471 - accuracy: 0.2392 - val_loss: 0.4831 - val_accuracy: 0.2630\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.4831 - accuracy: 0.2630\n",
            "sklearn_accuracy: 0.1391875\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 27, 5, 4, 1, 2, 58, 4, 2, 1, 1, 21, 4, 3, 1, 1, 43, 4, 5, 2, 1, 28, 3, 7, 2, 2, 1, 59, 0.38, 59, 0.02, 43, 0.38]\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_22 (Conv2D)          (None, 87, 128, 27)       567       \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 87, 64, 27)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 87, 64, 27)       108       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 87, 64, 58)        12586     \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 87, 64, 58)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 87, 64, 58)       232       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 87, 64, 21)        14637     \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 87, 64, 21)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 87, 64, 21)       84        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 87, 64, 43)        18103     \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 44, 64, 43)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 44, 64, 43)       172       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 121088)            0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 59)                7144251   \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 59)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 5)                 300       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,191,040\n",
            "Trainable params: 7,190,742\n",
            "Non-trainable params: 298\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 61s 79ms/step - loss: 0.7240 - accuracy: 0.2780 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6932 - accuracy: 0.1150 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6932 - accuracy: 0.1275 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6932 - accuracy: 0.2517 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6932 - accuracy: 0.1482 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6932 - accuracy: 0.3063 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6954 - accuracy: 0.1632 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1137 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1620 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6932 - accuracy: 0.1967 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6932 - accuracy: 0.2581 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1901 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1038 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6932 - accuracy: 0.3350 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1470 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "500/500 [==============================] - 6s 11ms/step - loss: 0.6932 - accuracy: 0.0625\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 45, 6, 3, 2, 1, 24, 7, 5, 1, 1, 26, 6, 5, 1, 2, 3, 4, 7, 1, 2, 33, 5, 3, 1, 2, 1, 4, 0.48, 38, 0.23, 22, 0.14]\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 87, 128, 45)       855       \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 44, 128, 45)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 44, 128, 45)      180       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 44, 128, 24)       37824     \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 44, 128, 24)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 44, 128, 24)      96        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 44, 128, 26)       18746     \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 44, 64, 26)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 44, 64, 26)       104       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 73216)             0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 4)                 292868    \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 5)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 350,698\n",
            "Trainable params: 350,508\n",
            "Non-trainable params: 190\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 50s 65ms/step - loss: 0.6933 - accuracy: 0.1760 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 48s 64ms/step - loss: 0.6932 - accuracy: 0.2139 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 48s 64ms/step - loss: 0.6932 - accuracy: 0.1452 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 48s 64ms/step - loss: 0.6932 - accuracy: 0.2297 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 48s 64ms/step - loss: 0.6932 - accuracy: 0.2155 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 48s 64ms/step - loss: 0.6932 - accuracy: 0.1917 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 48s 64ms/step - loss: 0.6932 - accuracy: 0.1423 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 48s 64ms/step - loss: 0.6932 - accuracy: 0.2835 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 48s 64ms/step - loss: 0.6932 - accuracy: 0.3000 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 48s 64ms/step - loss: 0.6932 - accuracy: 0.1547 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 48s 63ms/step - loss: 0.6932 - accuracy: 0.2988 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 47s 63ms/step - loss: 0.6932 - accuracy: 0.1238 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 47s 63ms/step - loss: 0.6932 - accuracy: 0.3012 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 47s 63ms/step - loss: 0.6932 - accuracy: 0.2426 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 47s 63ms/step - loss: 0.6932 - accuracy: 0.1080 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "500/500 [==============================] - 5s 8ms/step - loss: 0.6931 - accuracy: 0.2500\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(main) 1' population has been evaluated\n",
            "best individual: [[5, 46, 2, 7, 1, 2, 3, 3, 7, 2, 2, 48, 6, 7, 1, 1, 23, 3, 4, 1, 1, 7, 2, 6, 1, 2, 2, 31, 0.3, 37, 0.37, 34, 0.08]]\n",
            "statistics: {'min': 0.03125, 'max': 0.21225, 'average': 0.100734375}\n",
            "\n",
            "\n",
            "(main) 2' population initialized\n",
            "[5, 46, 2, 7, 1, 2, 3, 3, 7, 2, 2, 48, 6, 7, 1, 1, 23, 3, 4, 1, 1, 7, 2, 6, 1, 2, 2, 31, 0.3, 37, 0.37, 34, 0.08]\n",
            "[5, 46, 2, 7, 1, 2, 9, 6, 7, 2, 2, 48, 6, 7, 1, 1, 23, 3, 7, 1, 1, 7, 2, 6, 1, 2, 2, 31, 0.3, 37, 0.28, 34, 0.1]\n",
            "[4, 10, 6, 2, 2, 2, 11, 6, 7, 2, 2, 48, 6, 7, 1, 1, 29, 3, 7, 1, 1, 7, 2, 5, 1, 1, 2, 31, 0.3, 37, 0.28, 34, 0.1]\n",
            "[4, 30, 2, 5, 1, 1, 55, 2, 2, 2, 2, 48, 2, 7, 1, 1, 27, 6, 5, 1, 1, 7, 2, 6, 1, 2, 2, 31, 0.3, 37, 0.28, 34, 0.19]\n",
            "[5, 28, 2, 4, 2, 2, 62, 6, 6, 1, 2, 13, 5, 6, 1, 2, 4, 5, 3, 2, 2, 7, 2, 6, 1, 2, 2, 31, 0.22, 37, 0.28, 34, 0.15]\n",
            "[3, 37, 4, 3, 2, 2, 28, 5, 5, 2, 1, 22, 7, 4, 1, 1, 44, 2, 5, 2, 2, 2, 2, 6, 2, 2, 3, 9, 0.01, 22, 0.24, 42, 0.39]\n",
            "[5, 51, 7, 7, 1, 1, 62, 2, 2, 1, 1, 52, 6, 6, 1, 2, 44, 5, 7, 1, 2, 22, 6, 3, 2, 2, 3, 59, 0.08, 43, 0.25, 64, 0.31]\n",
            "[4, 27, 6, 5, 2, 1, 55, 2, 2, 1, 2, 57, 6, 6, 1, 2, 50, 5, 5, 2, 2, 22, 6, 2, 2, 2, 3, 59, 0.08, 43, 0.36, 64, 0.29]\n"
          ]
        }
      ],
      "source": [
        "START_WITH_LOW_VALUES = False\n",
        "\n",
        "POPULATION_SIZE = 8\n",
        "NUM_GENERATIONS = 1\n",
        "CROSSOVER_PROB = 0.8\n",
        "MUTATION_PROB = 0.3\n",
        "\n",
        "# input path\n",
        "DATASET_PATH = DATASET_PATH_MEL_SPEC_POSITION\n",
        "\n",
        "date_string = time.asctime(time.localtime(time.time()))  # ex. Wed Nov 16 10:40:52 2022\n",
        "date_month_year = date_string[8:10] + date_string[4:7] + date_string[-4:]  # ex. 6Nov2022\n",
        "\n",
        "VARY_POSITION_PATH = f'/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/1__gen_algorithm_optimization/statistics_{date_month_year}_position_P{POPULATION_SIZE}_G{NUM_GENERATIONS}.json'\n",
        "VARY_PARAMS_PATH = f'/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/1__gen_algorithm_optimization/statistics_{date_month_year}_params_P{POPULATION_SIZE}_G{NUM_GENERATIONS}.json'\n",
        "FIXED_PATH = f'/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/1__gen_algorithm_optimization/statistics_{date_month_year}_fixed_P{POPULATION_SIZE}_G{NUM_GENERATIONS}.json'\n",
        "\n",
        "# output path\n",
        "output_statistics_path = VARY_POSITION_PATH\n",
        "\n",
        "if START_WITH_LOW_VALUES==False:\n",
        "  output_statistics_path = output_statistics_path[:-5] +  '_no_low_values.json'\n",
        "\n",
        "print(output_statistics_path)\n",
        "\n",
        "\n",
        "\n",
        "def main(verbose=True):\n",
        "\n",
        "  #data = load_data_pickle(PICKLE_PATH_ENTIRE_NAMES) - new 1/3\n",
        "\n",
        "  statistics_dict = {\n",
        "      \"best_individuals\":[],\n",
        "      \"min\":[],\n",
        "      \"max\":[],\n",
        "      \"average\":[]\n",
        "  }\n",
        "\n",
        "  # build the first population\n",
        "  population = initialize_first_population(POPULATION_SIZE, start_with_low_values=START_WITH_LOW_VALUES)\n",
        "  if verbose:\n",
        "    print(\"(main) first population initialized\")\n",
        "    for indiv in population:\n",
        "      print(indiv)\n",
        "\n",
        "  # load entire dataset\n",
        "  #data_complete = load_data_pickle(DATASET_PATH_MEL_SPEC)\n",
        "  data_complete = load_data_pickle(DATASET_PATH)\n",
        "\n",
        "  # new - test with 1 guitar as test set (ex: tele)\n",
        "  X_train, X_test, y_train, y_test, N_train, N_test = prepare_dataset_for_guitar_cross_validation(data_complete, 'strato')\n",
        "  data = (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "  del data_complete\n",
        "  \n",
        "  if verbose:\n",
        "    print(\"\\n(main) dataset loaded\")\n",
        "    print(f\"X_train dimension: {np.shape(X_train)}\")\n",
        "\n",
        "  \n",
        "  # START WITH GENERATIONS\n",
        "  for generation in range(NUM_GENERATIONS):\n",
        "\n",
        "    # EVALUATE\n",
        "    \n",
        "    print(f\"\\n - GENERATION {generation+1}\\n\")\n",
        "\n",
        "    population_eval  = population_evaluation(population, data)\n",
        "\n",
        "    # save statistics\n",
        "    statistics_dict[\"best_individuals\"].append(population_eval['best_individual'][0])\n",
        "    statistics_dict[\"min\"].append(population_eval['statistics'][\"min\"])\n",
        "    statistics_dict[\"max\"].append(population_eval['statistics'][\"max\"])\n",
        "    statistics_dict[\"average\"].append(population_eval['statistics'][\"average\"])\n",
        "\n",
        "    # consider elitism - save best individual for next generation\n",
        "    survived_individual = population_eval['best_individual'][0].copy()\n",
        "\n",
        "    if verbose:\n",
        "      print(f\"\\n(main) {generation+1}' population has been evaluated\")\n",
        "      print(f\"best individual: {population_eval['best_individual']}\")\n",
        "      print(f\"statistics: {population_eval['statistics']}\")\n",
        "\n",
        "    # NEW POPULATION - selection, crossover, mutation\n",
        "\n",
        "    new_population = []\n",
        "    new_population.append(survived_individual)\n",
        "\n",
        "    for i in range(POPULATION_SIZE - 1):\n",
        "      \n",
        "      # selection\n",
        "      individual_1, individual_2 = select_two_individuals(population_eval)\n",
        "\n",
        "      # crossover\n",
        "      crossed_individual = single_point_crossover(individual_1,individual_2, CROSSOVER_PROB)\n",
        "\n",
        "      # mutation\n",
        "      mutated_individual = mutation(crossed_individual, MUTATION_PROB)\n",
        "\n",
        "      # append to new population\n",
        "      new_population.append(mutated_individual)\n",
        "\n",
        "    population = new_population  # or new_population.copy() ?\n",
        "\n",
        "    print(f\"\\n\\n(main) {generation+2}' population initialized\")\n",
        "    for indiv in population:\n",
        "      print(indiv)\n",
        "\n",
        "  return statistics_dict\n",
        "\n",
        "\n",
        "statistics = main()\n",
        "\n",
        "\n",
        "\n",
        "name = f'name_P{POPULATION_SIZE}_G{NUM_GENERATIONS}.json'\n",
        "\n",
        "\n",
        "with open(output_statistics_path, \"w\") as fp:\n",
        "    json.dump(statistics, fp, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZd5Y-iPCuyj"
      },
      "source": [
        "###RANDOM SEARCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAV5S_eIC2eJ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from random import randint, uniform, random\n",
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import time\n",
        "import gc\n",
        "\n",
        "\n",
        "def initialize_first_population(population_size, verbose=True, start_with_low_values=True):\n",
        "  \"\"\"Initialize the fist population of Genetic Algorithms(GAs).\n",
        "  Create each individual randomly\"\"\"\n",
        "\n",
        "  # parameters\n",
        "  # 0 - HOW MANY CONV. LAYERS                   [min: 1, max: 5]\n",
        "  \n",
        "  # 1 - filters          of 1st conv layer      [2 -> 64]\n",
        "  # 2 - x kernel dim.    of 1st conv layer      [2 -> 7]\n",
        "  # 3 - y kernel dim.    of 1st conv layer      [2 -> 7]\n",
        "  # 4 - x size           of 1st maxpool layer   [1 -> 2]\n",
        "  # 5 - y size           of 1st maxpool layer   [1 -> 2]\n",
        "\n",
        "  #  6,  7,  8,  9, 10 - same but considering 2nd layer (if present)\n",
        "  # 11, 12, 13, 14, 15 - same but considering 3rd layer (if present)\n",
        "  # 16, 17, 18, 19, 20 - same but considering 4th layer (if present)\n",
        "  # 21, 22, 23, 24, 25 - same but considering 5th layer (if present)\n",
        "  # ----------------------------------------------------\n",
        "  \n",
        "  # 26 - HOW MANY DENSE LAYERS [min: 1, max: 3]\n",
        "  \n",
        "  # 27 - neurons         of 1st dense layer     [2 -> 64]\n",
        "  # 28 - dropout prob.   of 1st dense layer     [0 -> 0.5]\n",
        "  # 29 - neurons         of 2nd dense layer (if present)\n",
        "  # 30 - dropout prob.   of 2nd dense layer (if present)\n",
        "  # 31 - neurons         of 3rd dense layer (if present)\n",
        "  # 32 - dropout prob.   of 3rd dense layer (if present)\n",
        "\n",
        "  print_info_first_individual = verbose\n",
        "  \n",
        "  \n",
        "  # list that will contain all the individuals\n",
        "  population = []\n",
        "\n",
        "  for individual_index in range(population_size):\n",
        "    \n",
        "    if verbose:\n",
        "      print(f\"Creating individual {individual_index + 1} out of {population_size}\")\n",
        "    \n",
        "    current_individual = [0] * 33  # [0, 0, 0...., 0]\n",
        "    \n",
        "    # define how many conv layers and dense layers\n",
        "    current_individual[0] = randint(1, 5)\n",
        "    current_individual[26] = randint(1, 3)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working on # of filters' of conv layers  (index: 1, 6, 11, 16, 21)\")\n",
        "    for list_index in range(1, 22, 5):\n",
        "      if start_with_low_values:\n",
        "        current_individual[list_index] = randint(2, 8)\n",
        "      else:\n",
        "        current_individual[list_index] = randint(2, 64)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working on x and y kernel dimensions     (index: 2, 3, 7, 8, 12, 13, 17, 18, 22, 23)\")\n",
        "    for list_index in range(2, 23, 5):\n",
        "      current_individual[list_index] = randint(2, 7)\n",
        "      current_individual[list_index + 1] = randint(2, 7)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working on x and y MaxPooling size       (index: 4, 5, 9, 10, 14, 15, 19, 20, 24, 25)\")\n",
        "    for list_index in range(4, 25, 5):\n",
        "      current_individual[list_index] = randint(1, 2)\n",
        "      current_individual[list_index + 1] = randint(1, 2)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working # of neurons in dense layers     (index: 27, 29, 31)\")\n",
        "    for list_index in range(27, 32, 2):\n",
        "      if start_with_low_values:\n",
        "        current_individual[list_index] = randint(2, 8)\n",
        "      else:\n",
        "        current_individual[list_index] = randint(2, 64)\n",
        "\n",
        "    if print_info_first_individual:\n",
        "      print(\"- working dropout prob. after dense layers (index: 28, 30, 32)\")\n",
        "    for list_index in range(28, 33, 2):\n",
        "      # round approx. the number to second decimal\n",
        "      current_individual[list_index] = round(uniform(0.0, 0.5), 2)\n",
        "\n",
        "    if verbose:\n",
        "      print(current_individual, end=\"\\n\\n\")\n",
        "\n",
        "    population.append(current_individual)\n",
        "\n",
        "    print_info_first_individual = False\n",
        "      \n",
        "  return population\n",
        "\n",
        "\n",
        "# build and compile the model\n",
        "def build_and_compile_model(indiv, input_shape=(78, 128, 1)):\n",
        "\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # create first conv layer + pooling layer\n",
        "  model.add(keras.layers.Conv2D(filters=indiv[1], kernel_size=(indiv[2], indiv[3]), input_shape=input_shape, activation='relu', padding='same'))\n",
        "  model.add(keras.layers.MaxPool2D(pool_size=(indiv[4], indiv[5]), padding='same'))\n",
        "  model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "  # create other conv layers + pooling layers\n",
        "  remain_conv_layer = indiv[0] - 1\n",
        "  for i in range(6, 6 + remain_conv_layer * 4, 5):\n",
        "    model.add(keras.layers.Conv2D(filters=indiv[i], kernel_size=(indiv[i+1], indiv[i+2]), activation='relu', padding='same'))\n",
        "    model.add(keras.layers.MaxPool2D(pool_size=(indiv[i+3], indiv[i+4]), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    \n",
        "  # flatten\n",
        "  model.add(keras.layers.Flatten())\n",
        "\n",
        "  # create dense layers + dropout\n",
        "  dense_layers = indiv[26]  # how many dense layers we have\n",
        "  for j in range(27, 27 + dense_layers * 2, 2):\n",
        "    model.add(keras.layers.Dense(units=indiv[j], activation='relu'))\n",
        "    model.add(keras.layers.Dropout(indiv[j+1]))\n",
        "\n",
        "  # add final layer\n",
        "  model.add(keras.layers.Dense(units=5, activation='sigmoid'))\n",
        "\n",
        "  # compile the model\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.00005)\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "#INPUT_SHAPE = (87, 128)\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def fitness_evaluation(individual, dataset):\n",
        "\n",
        "  # print current individual\n",
        "  print(f\"fitness_evaluation function. Individual considered:\\n{individual}\")\n",
        "\n",
        "  # get train and test data from dataset\n",
        "  (X_train, y_train), (X_valid, y_valid) = dataset\n",
        "\n",
        "  # build CNN associated to the individual\n",
        "  input_shape = np.shape(X_train[1])\n",
        "  model = build_and_compile_model(individual, input_shape)\n",
        "\n",
        "  # evaluate the model/individual (implementing early stopping??)\n",
        "  model.fit(X_train, y_train, epochs=15, batch_size=64, shuffle=True, validation_data = (X_valid, y_valid))\n",
        "\n",
        "  # get the accuracy on valid set (not used now)\n",
        "  loss, accuracy = model.evaluate(X_valid, y_valid)   # can use loss intead of accuracy\n",
        "\n",
        "  # NEW - sklearn accuracy\n",
        "  y_pred = model.predict(X_valid)\n",
        "  y_pred = y_pred.round()\n",
        "  sklearn_accuracy = accuracy_score(y_valid, y_pred)\n",
        "  print(f\"sklearn_accuracy:\", sklearn_accuracy)\n",
        "\n",
        "  # I can consider to return - (1/loss)\n",
        "  return sklearn_accuracy\n",
        "\n",
        "\n",
        "def population_evaluation(population, dataset, population_size):\n",
        "  \"\"\"population_evaluation gets the performace of each individual in the current population\"\"\"\n",
        "  \n",
        "  # dictionary to store information about population\n",
        "  population_eval ={\n",
        "      \"population\":[],\n",
        "      \"fitness\":[],\n",
        "      \"probability\":[],\n",
        "      \"best_individual\": [],\n",
        "      \"statistics\": {\"min\":0, \"max\":0, \"average\":0}\n",
        "  }\n",
        "\n",
        "  # save pupulation into dictionary\n",
        "  population_eval[\"population\"] = population.copy()\n",
        "\n",
        "  # perform and save fitness for each individual - enumerate counts starting from 1\n",
        "  for i, individual in enumerate(population, 1):\n",
        "\n",
        "    # Here a CNN is built and evaluated\n",
        "    print(f\"\\n({i}/{population_size})\", end=\" - \")\n",
        "    fitness = fitness_evaluation(individual, dataset)\n",
        "\n",
        "    # free memory occupied by keras model\n",
        "    gc.collect()\n",
        "\n",
        "    population_eval[\"fitness\"].append(fitness)\n",
        "  \n",
        "  # perform and save probability for each individual\n",
        "  sum_of_fitnesses = np.sum(population_eval[\"fitness\"])\n",
        "  for fitness_value in population_eval[\"fitness\"]:\n",
        "    probability_value = fitness_value / sum_of_fitnesses\n",
        "    population_eval[\"probability\"].append(probability_value)\n",
        "\n",
        "  # save best individual\n",
        "  best_individual_index = np.argmax(population_eval[\"fitness\"])\n",
        "  best_individual = population_eval[\"population\"][best_individual_index]\n",
        "  population_eval[\"best_individual\"].append(best_individual)\n",
        "\n",
        "  # save min, max and average\n",
        "  max = np.max(population_eval[\"fitness\"])\n",
        "  min = np.min(population_eval[\"fitness\"])\n",
        "  average = np.average(population_eval[\"fitness\"])\n",
        "\n",
        "  population_eval[\"statistics\"][\"min\"] = min\n",
        "  population_eval[\"statistics\"][\"max\"] = max\n",
        "  population_eval[\"statistics\"][\"average\"] = average\n",
        "\n",
        "  return population_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BynBCw-MHv6",
        "outputId": "dd193e08-eb3b-4194-9746-747471044ee0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " max_pooling2d_209 (MaxPooli  (None, 87, 128, 22)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_209 (Ba  (None, 87, 128, 22)      88        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_210 (Conv2D)         (None, 87, 128, 27)       29133     \n",
            "                                                                 \n",
            " max_pooling2d_210 (MaxPooli  (None, 87, 64, 27)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_210 (Ba  (None, 87, 64, 27)       108       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_69 (Flatten)        (None, 150336)            0         \n",
            "                                                                 \n",
            " dense_203 (Dense)           (None, 27)                4059099   \n",
            "                                                                 \n",
            " dropout_134 (Dropout)       (None, 27)                0         \n",
            "                                                                 \n",
            " dense_204 (Dense)           (None, 35)                980       \n",
            "                                                                 \n",
            " dropout_135 (Dropout)       (None, 35)                0         \n",
            "                                                                 \n",
            " dense_205 (Dense)           (None, 51)                1836      \n",
            "                                                                 \n",
            " dropout_136 (Dropout)       (None, 51)                0         \n",
            "                                                                 \n",
            " dense_206 (Dense)           (None, 5)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,091,834\n",
            "Trainable params: 4,091,736\n",
            "Non-trainable params: 98\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 44s 56ms/step - loss: 0.7021 - accuracy: 0.2800 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.2277 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.1989 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.1145 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.2215 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.1861 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.1843 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.2813 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.1517 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.1385 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.2103 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.1576 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.3026 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.1376 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 41s 54ms/step - loss: 0.6932 - accuracy: 0.1228 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6932 - accuracy: 0.2500\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 34, 3, 2, 2, 2, 28, 6, 4, 1, 1, 10, 4, 7, 1, 2, 48, 2, 4, 2, 1, 54, 4, 3, 1, 1, 1, 35, 0.06, 46, 0.39, 30, 0.22]\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_211 (Conv2D)         (None, 87, 128, 34)       238       \n",
            "                                                                 \n",
            " max_pooling2d_211 (MaxPooli  (None, 44, 64, 34)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_211 (Ba  (None, 44, 64, 34)       136       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_212 (Conv2D)         (None, 44, 64, 28)        22876     \n",
            "                                                                 \n",
            " max_pooling2d_212 (MaxPooli  (None, 44, 64, 28)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_212 (Ba  (None, 44, 64, 28)       112       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_213 (Conv2D)         (None, 44, 64, 10)        7850      \n",
            "                                                                 \n",
            " max_pooling2d_213 (MaxPooli  (None, 44, 32, 10)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_213 (Ba  (None, 44, 32, 10)       40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_214 (Conv2D)         (None, 44, 32, 48)        3888      \n",
            "                                                                 \n",
            " max_pooling2d_214 (MaxPooli  (None, 22, 32, 48)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_214 (Ba  (None, 22, 32, 48)       192       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_70 (Flatten)        (None, 33792)             0         \n",
            "                                                                 \n",
            " dense_207 (Dense)           (None, 35)                1182755   \n",
            "                                                                 \n",
            " dropout_137 (Dropout)       (None, 35)                0         \n",
            "                                                                 \n",
            " dense_208 (Dense)           (None, 5)                 180       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,218,267\n",
            "Trainable params: 1,218,027\n",
            "Non-trainable params: 240\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 31s 40ms/step - loss: 0.4765 - accuracy: 0.1741 - val_loss: 0.4199 - val_accuracy: 0.4259\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 28s 38ms/step - loss: 0.3383 - accuracy: 0.3970 - val_loss: 0.3621 - val_accuracy: 0.4156\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.3036 - accuracy: 0.4380 - val_loss: 0.3137 - val_accuracy: 0.4212\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 28s 38ms/step - loss: 0.2914 - accuracy: 0.4495 - val_loss: 0.3325 - val_accuracy: 0.4439\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 28s 38ms/step - loss: 0.2861 - accuracy: 0.4507 - val_loss: 0.3835 - val_accuracy: 0.3127\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.2816 - accuracy: 0.4576 - val_loss: 0.3577 - val_accuracy: 0.4318\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.2795 - accuracy: 0.4522 - val_loss: 0.4306 - val_accuracy: 0.3743\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 28s 38ms/step - loss: 0.2744 - accuracy: 0.4410 - val_loss: 0.3576 - val_accuracy: 0.4983\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.2674 - accuracy: 0.4426 - val_loss: 0.2731 - val_accuracy: 0.4192\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.2161 - accuracy: 0.4595 - val_loss: 0.2605 - val_accuracy: 0.4031\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 28s 38ms/step - loss: 0.2098 - accuracy: 0.4410 - val_loss: 0.2327 - val_accuracy: 0.3749\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 28s 38ms/step - loss: 0.1424 - accuracy: 0.4256 - val_loss: 0.1517 - val_accuracy: 0.3092\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 28s 38ms/step - loss: 0.0870 - accuracy: 0.4179 - val_loss: 0.1593 - val_accuracy: 0.3501\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.0787 - accuracy: 0.3685 - val_loss: 0.1040 - val_accuracy: 0.3506\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 28s 38ms/step - loss: 0.0769 - accuracy: 0.3482 - val_loss: 0.1036 - val_accuracy: 0.3101\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1036 - accuracy: 0.3101\n",
            "sklearn_accuracy: 0.8689375\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 27, 3, 6, 2, 2, 7, 4, 7, 2, 1, 21, 5, 3, 2, 2, 62, 7, 5, 1, 2, 33, 2, 3, 2, 2, 3, 36, 0.42, 58, 0.4, 20, 0.15]\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_215 (Conv2D)         (None, 87, 128, 27)       513       \n",
            "                                                                 \n",
            " max_pooling2d_215 (MaxPooli  (None, 44, 64, 27)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_215 (Ba  (None, 44, 64, 27)       108       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_216 (Conv2D)         (None, 44, 64, 7)         5299      \n",
            "                                                                 \n",
            " max_pooling2d_216 (MaxPooli  (None, 22, 64, 7)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_216 (Ba  (None, 22, 64, 7)        28        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_217 (Conv2D)         (None, 22, 64, 21)        2226      \n",
            "                                                                 \n",
            " max_pooling2d_217 (MaxPooli  (None, 11, 32, 21)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_217 (Ba  (None, 11, 32, 21)       84        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_218 (Conv2D)         (None, 11, 32, 62)        45632     \n",
            "                                                                 \n",
            " max_pooling2d_218 (MaxPooli  (None, 11, 16, 62)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_218 (Ba  (None, 11, 16, 62)       248       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_219 (Conv2D)         (None, 11, 16, 33)        12309     \n",
            "                                                                 \n",
            " max_pooling2d_219 (MaxPooli  (None, 6, 8, 33)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_219 (Ba  (None, 6, 8, 33)         132       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_71 (Flatten)        (None, 1584)              0         \n",
            "                                                                 \n",
            " dense_209 (Dense)           (None, 36)                57060     \n",
            "                                                                 \n",
            " dropout_138 (Dropout)       (None, 36)                0         \n",
            "                                                                 \n",
            " dense_210 (Dense)           (None, 58)                2146      \n",
            "                                                                 \n",
            " dropout_139 (Dropout)       (None, 58)                0         \n",
            "                                                                 \n",
            " dense_211 (Dense)           (None, 20)                1180      \n",
            "                                                                 \n",
            " dropout_140 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_212 (Dense)           (None, 5)                 105       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 127,070\n",
            "Trainable params: 126,770\n",
            "Non-trainable params: 300\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 20s 25ms/step - loss: 0.5627 - accuracy: 0.1404 - val_loss: 0.4329 - val_accuracy: 0.1950\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.4160 - accuracy: 0.2348 - val_loss: 0.3396 - val_accuracy: 0.2585\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3624 - accuracy: 0.2935 - val_loss: 0.3188 - val_accuracy: 0.3325\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3399 - accuracy: 0.3224 - val_loss: 0.3507 - val_accuracy: 0.3314\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3281 - accuracy: 0.3350 - val_loss: 0.3267 - val_accuracy: 0.3500\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3214 - accuracy: 0.3250 - val_loss: 0.3264 - val_accuracy: 0.3268\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3151 - accuracy: 0.3298 - val_loss: 0.3085 - val_accuracy: 0.3449\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3098 - accuracy: 0.3320 - val_loss: 0.3301 - val_accuracy: 0.3172\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3068 - accuracy: 0.3404 - val_loss: 1.1819 - val_accuracy: 0.1316\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3049 - accuracy: 0.3229 - val_loss: 0.3385 - val_accuracy: 0.2910\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.3035 - accuracy: 0.3133 - val_loss: 1.4340 - val_accuracy: 0.1159\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.2986 - accuracy: 0.3362 - val_loss: 0.3171 - val_accuracy: 0.3635\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.2981 - accuracy: 0.3269 - val_loss: 0.3970 - val_accuracy: 0.3074\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.2973 - accuracy: 0.3359 - val_loss: 0.4050 - val_accuracy: 0.2771\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.2971 - accuracy: 0.3273 - val_loss: 0.3290 - val_accuracy: 0.2758\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.3290 - accuracy: 0.2758\n",
            "sklearn_accuracy: 0.24175\n",
            "(62.5 % )\n",
            "Creating individual 1 out of 8\n",
            "- working on # of filters' of conv layers  (index: 1, 6, 11, 16, 21)\n",
            "- working on x and y kernel dimensions     (index: 2, 3, 7, 8, 12, 13, 17, 18, 22, 23)\n",
            "- working on x and y MaxPooling size       (index: 4, 5, 9, 10, 14, 15, 19, 20, 24, 25)\n",
            "- working # of neurons in dense layers     (index: 27, 29, 31)\n",
            "- working dropout prob. after dense layers (index: 28, 30, 32)\n",
            "[1, 38, 2, 3, 1, 2, 60, 2, 4, 1, 2, 52, 2, 3, 1, 1, 64, 7, 2, 1, 1, 41, 5, 2, 2, 1, 3, 55, 0.0, 49, 0.45, 38, 0.07]\n",
            "\n",
            "Creating individual 2 out of 8\n",
            "[3, 4, 2, 6, 1, 1, 16, 4, 2, 1, 1, 6, 5, 7, 1, 2, 64, 7, 4, 1, 2, 52, 5, 4, 1, 2, 3, 49, 0.04, 25, 0.0, 7, 0.32]\n",
            "\n",
            "Creating individual 3 out of 8\n",
            "[4, 24, 3, 5, 1, 2, 38, 7, 6, 1, 1, 41, 5, 2, 2, 2, 54, 4, 2, 2, 2, 24, 7, 5, 2, 2, 3, 41, 0.45, 36, 0.29, 40, 0.0]\n",
            "\n",
            "Creating individual 4 out of 8\n",
            "[1, 19, 6, 4, 1, 1, 37, 3, 4, 2, 2, 15, 2, 6, 1, 2, 57, 7, 5, 1, 1, 4, 4, 4, 1, 1, 2, 35, 0.04, 39, 0.0, 61, 0.2]\n",
            "\n",
            "Creating individual 5 out of 8\n",
            "[4, 17, 5, 5, 1, 1, 34, 5, 2, 2, 1, 12, 6, 4, 1, 1, 17, 2, 5, 2, 2, 2, 3, 4, 1, 1, 3, 33, 0.1, 40, 0.22, 23, 0.36]\n",
            "\n",
            "Creating individual 6 out of 8\n",
            "[2, 17, 7, 2, 1, 1, 49, 4, 4, 2, 2, 40, 7, 5, 1, 2, 64, 6, 3, 2, 1, 25, 7, 3, 2, 1, 3, 54, 0.4, 11, 0.04, 50, 0.09]\n",
            "\n",
            "Creating individual 7 out of 8\n",
            "[2, 45, 5, 5, 1, 2, 7, 7, 2, 1, 2, 62, 2, 4, 1, 2, 31, 5, 5, 1, 2, 42, 6, 5, 2, 2, 2, 64, 0.34, 58, 0.39, 51, 0.34]\n",
            "\n",
            "Creating individual 8 out of 8\n",
            "[1, 44, 6, 6, 2, 1, 3, 5, 6, 2, 2, 18, 5, 2, 1, 2, 39, 4, 4, 2, 1, 22, 3, 5, 2, 1, 3, 23, 0.36, 49, 0.16, 58, 0.29]\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 38, 2, 3, 1, 2, 60, 2, 4, 1, 2, 52, 2, 3, 1, 1, 64, 7, 2, 1, 1, 41, 5, 2, 2, 1, 3, 55, 0.0, 49, 0.45, 38, 0.07]\n",
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_220 (Conv2D)         (None, 87, 128, 38)       266       \n",
            "                                                                 \n",
            " max_pooling2d_220 (MaxPooli  (None, 87, 64, 38)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_220 (Ba  (None, 87, 64, 38)       152       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_72 (Flatten)        (None, 211584)            0         \n",
            "                                                                 \n",
            " dense_213 (Dense)           (None, 55)                11637175  \n",
            "                                                                 \n",
            " dropout_141 (Dropout)       (None, 55)                0         \n",
            "                                                                 \n",
            " dense_214 (Dense)           (None, 49)                2744      \n",
            "                                                                 \n",
            " dropout_142 (Dropout)       (None, 49)                0         \n",
            "                                                                 \n",
            " dense_215 (Dense)           (None, 38)                1900      \n",
            "                                                                 \n",
            " dropout_143 (Dropout)       (None, 38)                0         \n",
            "                                                                 \n",
            " dense_216 (Dense)           (None, 5)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,642,432\n",
            "Trainable params: 11,642,356\n",
            "Non-trainable params: 76\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.7365 - accuracy: 0.2473 - val_loss: 0.6931 - val_accuracy: 0.5311\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.2954 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1187 - val_loss: 0.6931 - val_accuracy: 0.0313\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1284 - val_loss: 0.6931 - val_accuracy: 0.2498\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.3377 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 15s 21ms/step - loss: 0.6932 - accuracy: 0.1161 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 15s 21ms/step - loss: 0.6932 - accuracy: 0.2350 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 15s 21ms/step - loss: 0.6932 - accuracy: 0.1783 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.3042 - val_loss: 0.6931 - val_accuracy: 0.2498\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1733 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1155 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1847 - val_loss: 0.6931 - val_accuracy: 0.0313\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1464 - val_loss: 0.6931 - val_accuracy: 0.1251\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 15s 21ms/step - loss: 0.6932 - accuracy: 0.2705 - val_loss: 0.6931 - val_accuracy: 0.2498\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.2021 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.6931 - accuracy: 0.5312\n",
            "sklearn_accuracy: 0.0311875\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 4, 2, 6, 1, 1, 16, 4, 2, 1, 1, 6, 5, 7, 1, 2, 64, 7, 4, 1, 2, 52, 5, 4, 1, 2, 3, 49, 0.04, 25, 0.0, 7, 0.32]\n",
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_221 (Conv2D)         (None, 87, 128, 4)        52        \n",
            "                                                                 \n",
            " max_pooling2d_221 (MaxPooli  (None, 87, 128, 4)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_221 (Ba  (None, 87, 128, 4)       16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_222 (Conv2D)         (None, 87, 128, 16)       528       \n",
            "                                                                 \n",
            " max_pooling2d_222 (MaxPooli  (None, 87, 128, 16)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_222 (Ba  (None, 87, 128, 16)      64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_223 (Conv2D)         (None, 87, 128, 6)        3366      \n",
            "                                                                 \n",
            " max_pooling2d_223 (MaxPooli  (None, 87, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_223 (Ba  (None, 87, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_73 (Flatten)        (None, 33408)             0         \n",
            "                                                                 \n",
            " dense_217 (Dense)           (None, 49)                1637041   \n",
            "                                                                 \n",
            " dropout_144 (Dropout)       (None, 49)                0         \n",
            "                                                                 \n",
            " dense_218 (Dense)           (None, 25)                1250      \n",
            "                                                                 \n",
            " dropout_145 (Dropout)       (None, 25)                0         \n",
            "                                                                 \n",
            " dense_219 (Dense)           (None, 7)                 182       \n",
            "                                                                 \n",
            " dropout_146 (Dropout)       (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_220 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,642,563\n",
            "Trainable params: 1,642,511\n",
            "Non-trainable params: 52\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 0.6944 - accuracy: 0.2573 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.1895 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.3553 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.1657 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.2938 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6935 - accuracy: 0.1558 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.1906 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.3105 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.1238 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.1770 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.2835 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.1490 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.2450 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.1744 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 33ms/step - loss: 0.6932 - accuracy: 0.2571 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 24, 3, 5, 1, 2, 38, 7, 6, 1, 1, 41, 5, 2, 2, 2, 54, 4, 2, 2, 2, 24, 7, 5, 2, 2, 3, 41, 0.45, 36, 0.29, 40, 0.0]\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_224 (Conv2D)         (None, 87, 128, 24)       384       \n",
            "                                                                 \n",
            " max_pooling2d_224 (MaxPooli  (None, 87, 64, 24)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_224 (Ba  (None, 87, 64, 24)       96        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_225 (Conv2D)         (None, 87, 64, 38)        38342     \n",
            "                                                                 \n",
            " max_pooling2d_225 (MaxPooli  (None, 87, 64, 38)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_225 (Ba  (None, 87, 64, 38)       152       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_226 (Conv2D)         (None, 87, 64, 41)        15621     \n",
            "                                                                 \n",
            " max_pooling2d_226 (MaxPooli  (None, 44, 32, 41)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_226 (Ba  (None, 44, 32, 41)       164       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_227 (Conv2D)         (None, 44, 32, 54)        17766     \n",
            "                                                                 \n",
            " max_pooling2d_227 (MaxPooli  (None, 22, 16, 54)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_227 (Ba  (None, 22, 16, 54)       216       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_74 (Flatten)        (None, 19008)             0         \n",
            "                                                                 \n",
            " dense_221 (Dense)           (None, 41)                779369    \n",
            "                                                                 \n",
            " dropout_147 (Dropout)       (None, 41)                0         \n",
            "                                                                 \n",
            " dense_222 (Dense)           (None, 36)                1512      \n",
            "                                                                 \n",
            " dropout_148 (Dropout)       (None, 36)                0         \n",
            "                                                                 \n",
            " dense_223 (Dense)           (None, 40)                1480      \n",
            "                                                                 \n",
            " dropout_149 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_224 (Dense)           (None, 5)                 205       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 855,307\n",
            "Trainable params: 854,993\n",
            "Non-trainable params: 314\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 55s 72ms/step - loss: 0.6944 - accuracy: 0.3122 - val_loss: 0.6931 - val_accuracy: 0.1251\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.2417 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.1107 - val_loss: 0.6931 - val_accuracy: 0.5313\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.3318 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.2168 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.1410 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.1680 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.3218 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.2321 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.1808 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.2115 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.1594 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.2380 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.2030 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.6932 - accuracy: 0.1237 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.6932 - accuracy: 0.0312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 19, 6, 4, 1, 1, 37, 3, 4, 2, 2, 15, 2, 6, 1, 2, 57, 7, 5, 1, 1, 4, 4, 4, 1, 1, 2, 35, 0.04, 39, 0.0, 61, 0.2]\n",
            "Model: \"sequential_75\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_228 (Conv2D)         (None, 87, 128, 19)       475       \n",
            "                                                                 \n",
            " max_pooling2d_228 (MaxPooli  (None, 87, 128, 19)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_228 (Ba  (None, 87, 128, 19)      76        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_75 (Flatten)        (None, 211584)            0         \n",
            "                                                                 \n",
            " dense_225 (Dense)           (None, 35)                7405475   \n",
            "                                                                 \n",
            " dropout_150 (Dropout)       (None, 35)                0         \n",
            "                                                                 \n",
            " dense_226 (Dense)           (None, 39)                1404      \n",
            "                                                                 \n",
            " dropout_151 (Dropout)       (None, 39)                0         \n",
            "                                                                 \n",
            " dense_227 (Dense)           (None, 5)                 200       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,407,630\n",
            "Trainable params: 7,407,592\n",
            "Non-trainable params: 38\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6286 - accuracy: 0.3841 - val_loss: 0.5255 - val_accuracy: 0.4635\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.4649 - accuracy: 0.5493 - val_loss: 0.5248 - val_accuracy: 0.3804\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.4468 - accuracy: 0.5647 - val_loss: 0.5464 - val_accuracy: 0.5067\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.4289 - accuracy: 0.5750 - val_loss: 0.5416 - val_accuracy: 0.4924\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.4273 - accuracy: 0.5764 - val_loss: 0.5763 - val_accuracy: 0.4534\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.4198 - accuracy: 0.5780 - val_loss: 0.6293 - val_accuracy: 0.5738\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.4105 - accuracy: 0.5824 - val_loss: 0.6332 - val_accuracy: 0.5718\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.4029 - accuracy: 0.5843 - val_loss: 0.6136 - val_accuracy: 0.4811\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.3940 - accuracy: 0.5873 - val_loss: 0.5525 - val_accuracy: 0.4323\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.3897 - accuracy: 0.5874 - val_loss: 1.1257 - val_accuracy: 0.5797\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.3840 - accuracy: 0.5884 - val_loss: 0.6279 - val_accuracy: 0.5089\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.3804 - accuracy: 0.5881 - val_loss: 0.6711 - val_accuracy: 0.4831\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.3724 - accuracy: 0.5893 - val_loss: 0.6383 - val_accuracy: 0.4921\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.3668 - accuracy: 0.5923 - val_loss: 0.7265 - val_accuracy: 0.5196\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 11s 15ms/step - loss: 0.3592 - accuracy: 0.5954 - val_loss: 0.7729 - val_accuracy: 0.5510\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.7729 - accuracy: 0.5510\n",
            "sklearn_accuracy: 0.188\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 17, 5, 5, 1, 1, 34, 5, 2, 2, 1, 12, 6, 4, 1, 1, 17, 2, 5, 2, 2, 2, 3, 4, 1, 1, 3, 33, 0.1, 40, 0.22, 23, 0.36]\n",
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_229 (Conv2D)         (None, 87, 128, 17)       442       \n",
            "                                                                 \n",
            " max_pooling2d_229 (MaxPooli  (None, 87, 128, 17)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_229 (Ba  (None, 87, 128, 17)      68        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_230 (Conv2D)         (None, 87, 128, 34)       5814      \n",
            "                                                                 \n",
            " max_pooling2d_230 (MaxPooli  (None, 44, 128, 34)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_230 (Ba  (None, 44, 128, 34)      136       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_231 (Conv2D)         (None, 44, 128, 12)       9804      \n",
            "                                                                 \n",
            " max_pooling2d_231 (MaxPooli  (None, 44, 128, 12)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_231 (Ba  (None, 44, 128, 12)      48        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_232 (Conv2D)         (None, 44, 128, 17)       2057      \n",
            "                                                                 \n",
            " max_pooling2d_232 (MaxPooli  (None, 22, 64, 17)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_232 (Ba  (None, 22, 64, 17)       68        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_76 (Flatten)        (None, 23936)             0         \n",
            "                                                                 \n",
            " dense_228 (Dense)           (None, 33)                789921    \n",
            "                                                                 \n",
            " dropout_152 (Dropout)       (None, 33)                0         \n",
            "                                                                 \n",
            " dense_229 (Dense)           (None, 40)                1360      \n",
            "                                                                 \n",
            " dropout_153 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_230 (Dense)           (None, 23)                943       \n",
            "                                                                 \n",
            " dropout_154 (Dropout)       (None, 23)                0         \n",
            "                                                                 \n",
            " dense_231 (Dense)           (None, 5)                 120       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 810,781\n",
            "Trainable params: 810,621\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 54s 70ms/step - loss: 0.6089 - accuracy: 0.1638 - val_loss: 0.5209 - val_accuracy: 0.1755\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 51s 67ms/step - loss: 0.5204 - accuracy: 0.1666 - val_loss: 0.5113 - val_accuracy: 0.1689\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.5060 - accuracy: 0.1742 - val_loss: 0.4904 - val_accuracy: 0.2039\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.5024 - accuracy: 0.1845 - val_loss: 0.5397 - val_accuracy: 0.2281\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.4884 - accuracy: 0.1949 - val_loss: 0.4542 - val_accuracy: 0.2137\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.4656 - accuracy: 0.2185 - val_loss: 0.4323 - val_accuracy: 0.1909\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.4532 - accuracy: 0.2210 - val_loss: 0.4278 - val_accuracy: 0.2462\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.4422 - accuracy: 0.2240 - val_loss: 0.4242 - val_accuracy: 0.2101\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.4331 - accuracy: 0.2289 - val_loss: 0.4078 - val_accuracy: 0.2148\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.4152 - accuracy: 0.2283 - val_loss: 0.4070 - val_accuracy: 0.2306\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.3968 - accuracy: 0.2339 - val_loss: 0.3849 - val_accuracy: 0.2763\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.3594 - accuracy: 0.2409 - val_loss: 0.3084 - val_accuracy: 0.2108\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.3331 - accuracy: 0.2304 - val_loss: 0.4298 - val_accuracy: 0.2796\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.3273 - accuracy: 0.2400 - val_loss: 0.3283 - val_accuracy: 0.2324\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 50s 67ms/step - loss: 0.3169 - accuracy: 0.2456 - val_loss: 0.9619 - val_accuracy: 0.4881\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.9619 - accuracy: 0.4881\n",
            "sklearn_accuracy: 0.1796875\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 17, 7, 2, 1, 1, 49, 4, 4, 2, 2, 40, 7, 5, 1, 2, 64, 6, 3, 2, 1, 25, 7, 3, 2, 1, 3, 54, 0.4, 11, 0.04, 50, 0.09]\n",
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_233 (Conv2D)         (None, 87, 128, 17)       255       \n",
            "                                                                 \n",
            " max_pooling2d_233 (MaxPooli  (None, 87, 128, 17)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_233 (Ba  (None, 87, 128, 17)      68        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_234 (Conv2D)         (None, 87, 128, 49)       13377     \n",
            "                                                                 \n",
            " max_pooling2d_234 (MaxPooli  (None, 44, 64, 49)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_234 (Ba  (None, 44, 64, 49)       196       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_77 (Flatten)        (None, 137984)            0         \n",
            "                                                                 \n",
            " dense_232 (Dense)           (None, 54)                7451190   \n",
            "                                                                 \n",
            " dropout_155 (Dropout)       (None, 54)                0         \n",
            "                                                                 \n",
            " dense_233 (Dense)           (None, 11)                605       \n",
            "                                                                 \n",
            " dropout_156 (Dropout)       (None, 11)                0         \n",
            "                                                                 \n",
            " dense_234 (Dense)           (None, 50)                600       \n",
            "                                                                 \n",
            " dropout_157 (Dropout)       (None, 50)                0         \n",
            "                                                                 \n",
            " dense_235 (Dense)           (None, 5)                 255       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,466,546\n",
            "Trainable params: 7,466,414\n",
            "Non-trainable params: 132\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 43s 55ms/step - loss: 0.6337 - accuracy: 0.1202 - val_loss: 0.5420 - val_accuracy: 0.1019\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.5645 - accuracy: 0.1241 - val_loss: 0.5092 - val_accuracy: 0.2056\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.5447 - accuracy: 0.1755 - val_loss: 0.4735 - val_accuracy: 0.1853\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.5151 - accuracy: 0.2250 - val_loss: 0.4663 - val_accuracy: 0.2452\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.4945 - accuracy: 0.2529 - val_loss: 0.6566 - val_accuracy: 0.2899\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.4899 - accuracy: 0.2833 - val_loss: 0.4394 - val_accuracy: 0.3284\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.4836 - accuracy: 0.2873 - val_loss: 0.4608 - val_accuracy: 0.3353\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.4786 - accuracy: 0.2857 - val_loss: 0.4329 - val_accuracy: 0.3625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.4744 - accuracy: 0.2849 - val_loss: 0.4956 - val_accuracy: 0.3757\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.4744 - accuracy: 0.2860 - val_loss: 0.4389 - val_accuracy: 0.3837\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.4678 - accuracy: 0.2777 - val_loss: 0.4292 - val_accuracy: 0.3714\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.4675 - accuracy: 0.2814 - val_loss: 0.4225 - val_accuracy: 0.3888\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.4595 - accuracy: 0.2863 - val_loss: 0.4155 - val_accuracy: 0.3375\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 39s 53ms/step - loss: 0.4630 - accuracy: 0.2801 - val_loss: 0.4553 - val_accuracy: 0.3831\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 40s 53ms/step - loss: 0.4544 - accuracy: 0.2877 - val_loss: 0.4921 - val_accuracy: 0.3816\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.4921 - accuracy: 0.3816\n",
            "sklearn_accuracy: 0.1623125\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 45, 5, 5, 1, 2, 7, 7, 2, 1, 2, 62, 2, 4, 1, 2, 31, 5, 5, 1, 2, 42, 6, 5, 2, 2, 2, 64, 0.34, 58, 0.39, 51, 0.34]\n",
            "Model: \"sequential_78\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_235 (Conv2D)         (None, 87, 128, 45)       1170      \n",
            "                                                                 \n",
            " max_pooling2d_235 (MaxPooli  (None, 87, 64, 45)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_235 (Ba  (None, 87, 64, 45)       180       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_236 (Conv2D)         (None, 87, 64, 7)         4417      \n",
            "                                                                 \n",
            " max_pooling2d_236 (MaxPooli  (None, 87, 32, 7)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_236 (Ba  (None, 87, 32, 7)        28        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_78 (Flatten)        (None, 19488)             0         \n",
            "                                                                 \n",
            " dense_236 (Dense)           (None, 64)                1247296   \n",
            "                                                                 \n",
            " dropout_158 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_237 (Dense)           (None, 58)                3770      \n",
            "                                                                 \n",
            " dropout_159 (Dropout)       (None, 58)                0         \n",
            "                                                                 \n",
            " dense_238 (Dense)           (None, 5)                 295       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,257,156\n",
            "Trainable params: 1,257,052\n",
            "Non-trainable params: 104\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 29s 37ms/step - loss: 0.6949 - accuracy: 0.2338 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.1468 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.1873 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.1702 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 0.6932 - accuracy: 0.2731 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.1709 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.3069 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 0.6932 - accuracy: 0.1780 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.2850 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 0.6932 - accuracy: 0.2205 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.3021 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.1546 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.2734 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6932 - accuracy: 0.2510 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.6937 - accuracy: 0.2344 - val_loss: 1.0970 - val_accuracy: 0.1596\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 1.0970 - accuracy: 0.1596\n",
            "sklearn_accuracy: 0.0514375\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 44, 6, 6, 2, 1, 3, 5, 6, 2, 2, 18, 5, 2, 1, 2, 39, 4, 4, 2, 1, 22, 3, 5, 2, 1, 3, 23, 0.36, 49, 0.16, 58, 0.29]\n",
            "Model: \"sequential_79\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_237 (Conv2D)         (None, 87, 128, 44)       1628      \n",
            "                                                                 \n",
            " max_pooling2d_237 (MaxPooli  (None, 44, 128, 44)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_237 (Ba  (None, 44, 128, 44)      176       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_79 (Flatten)        (None, 247808)            0         \n",
            "                                                                 \n",
            " dense_239 (Dense)           (None, 23)                5699607   \n",
            "                                                                 \n",
            " dropout_160 (Dropout)       (None, 23)                0         \n",
            "                                                                 \n",
            " dense_240 (Dense)           (None, 49)                1176      \n",
            "                                                                 \n",
            " dropout_161 (Dropout)       (None, 49)                0         \n",
            "                                                                 \n",
            " dense_241 (Dense)           (None, 58)                2900      \n",
            "                                                                 \n",
            " dropout_162 (Dropout)       (None, 58)                0         \n",
            "                                                                 \n",
            " dense_242 (Dense)           (None, 5)                 295       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,705,782\n",
            "Trainable params: 5,705,694\n",
            "Non-trainable params: 88\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.7011 - accuracy: 0.2180 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2047 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2104 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.1014 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.0989 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.1989 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2503 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.1482 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.1085 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2496 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2678 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2412 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2236 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2367 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.0691 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.6931 - accuracy: 0.0625\n",
            "sklearn_accuracy: 0.03125\n",
            "(68.75 % )\n",
            "Creating individual 1 out of 8\n",
            "- working on # of filters' of conv layers  (index: 1, 6, 11, 16, 21)\n",
            "- working on x and y kernel dimensions     (index: 2, 3, 7, 8, 12, 13, 17, 18, 22, 23)\n",
            "- working on x and y MaxPooling size       (index: 4, 5, 9, 10, 14, 15, 19, 20, 24, 25)\n",
            "- working # of neurons in dense layers     (index: 27, 29, 31)\n",
            "- working dropout prob. after dense layers (index: 28, 30, 32)\n",
            "[3, 59, 2, 7, 2, 2, 40, 3, 3, 2, 1, 45, 5, 6, 2, 1, 2, 5, 6, 1, 2, 6, 3, 4, 2, 1, 1, 17, 0.35, 22, 0.05, 58, 0.14]\n",
            "\n",
            "Creating individual 2 out of 8\n",
            "[5, 2, 4, 5, 1, 2, 34, 2, 4, 1, 2, 28, 4, 3, 1, 1, 22, 6, 2, 1, 2, 64, 6, 7, 2, 2, 2, 9, 0.41, 16, 0.09, 44, 0.48]\n",
            "\n",
            "Creating individual 3 out of 8\n",
            "[5, 58, 3, 4, 1, 2, 45, 7, 7, 2, 2, 63, 4, 3, 2, 1, 28, 6, 2, 2, 1, 30, 5, 6, 2, 1, 2, 7, 0.2, 19, 0.44, 7, 0.32]\n",
            "\n",
            "Creating individual 4 out of 8\n",
            "[2, 27, 7, 3, 1, 1, 32, 7, 5, 1, 2, 64, 7, 2, 2, 2, 6, 5, 5, 2, 1, 9, 3, 3, 1, 2, 2, 34, 0.3, 26, 0.48, 34, 0.2]\n",
            "\n",
            "Creating individual 5 out of 8\n",
            "[1, 44, 4, 6, 2, 2, 37, 5, 2, 1, 2, 21, 4, 2, 2, 2, 8, 4, 5, 2, 2, 25, 6, 6, 1, 1, 2, 3, 0.06, 29, 0.48, 62, 0.32]\n",
            "\n",
            "Creating individual 6 out of 8\n",
            "[3, 19, 4, 4, 2, 2, 35, 7, 4, 1, 2, 49, 5, 7, 2, 2, 63, 5, 5, 1, 2, 42, 7, 7, 2, 1, 1, 64, 0.06, 18, 0.41, 9, 0.04]\n",
            "\n",
            "Creating individual 7 out of 8\n",
            "[5, 4, 5, 5, 2, 2, 64, 6, 2, 2, 1, 36, 5, 7, 1, 2, 64, 3, 5, 1, 2, 9, 6, 7, 2, 2, 1, 10, 0.47, 33, 0.47, 40, 0.2]\n",
            "\n",
            "Creating individual 8 out of 8\n",
            "[1, 13, 4, 6, 1, 1, 46, 2, 6, 2, 2, 46, 5, 5, 1, 2, 39, 7, 3, 1, 1, 39, 3, 2, 2, 2, 3, 24, 0.29, 54, 0.33, 48, 0.09]\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 59, 2, 7, 2, 2, 40, 3, 3, 2, 1, 45, 5, 6, 2, 1, 2, 5, 6, 1, 2, 6, 3, 4, 2, 1, 1, 17, 0.35, 22, 0.05, 58, 0.14]\n",
            "Model: \"sequential_80\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_238 (Conv2D)         (None, 87, 128, 59)       885       \n",
            "                                                                 \n",
            " max_pooling2d_238 (MaxPooli  (None, 44, 64, 59)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_238 (Ba  (None, 44, 64, 59)       236       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_239 (Conv2D)         (None, 44, 64, 40)        21280     \n",
            "                                                                 \n",
            " max_pooling2d_239 (MaxPooli  (None, 22, 64, 40)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_239 (Ba  (None, 22, 64, 40)       160       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_240 (Conv2D)         (None, 22, 64, 45)        54045     \n",
            "                                                                 \n",
            " max_pooling2d_240 (MaxPooli  (None, 11, 64, 45)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_240 (Ba  (None, 11, 64, 45)       180       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_80 (Flatten)        (None, 31680)             0         \n",
            "                                                                 \n",
            " dense_243 (Dense)           (None, 17)                538577    \n",
            "                                                                 \n",
            " dropout_163 (Dropout)       (None, 17)                0         \n",
            "                                                                 \n",
            " dense_244 (Dense)           (None, 5)                 90        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 615,453\n",
            "Trainable params: 615,165\n",
            "Non-trainable params: 288\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6941 - accuracy: 0.2992 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.0873 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1415 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1139 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.3334 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1450 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1674 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.2750 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.2634 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.0787 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.3320 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.0944 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.2491 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1800 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1573 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6932 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 2, 4, 5, 1, 2, 34, 2, 4, 1, 2, 28, 4, 3, 1, 1, 22, 6, 2, 1, 2, 64, 6, 7, 2, 2, 2, 9, 0.41, 16, 0.09, 44, 0.48]\n",
            "Model: \"sequential_81\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_241 (Conv2D)         (None, 87, 128, 2)        42        \n",
            "                                                                 \n",
            " max_pooling2d_241 (MaxPooli  (None, 87, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_241 (Ba  (None, 87, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_242 (Conv2D)         (None, 87, 64, 34)        578       \n",
            "                                                                 \n",
            " max_pooling2d_242 (MaxPooli  (None, 87, 32, 34)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_242 (Ba  (None, 87, 32, 34)       136       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_243 (Conv2D)         (None, 87, 32, 28)        11452     \n",
            "                                                                 \n",
            " max_pooling2d_243 (MaxPooli  (None, 87, 32, 28)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_243 (Ba  (None, 87, 32, 28)       112       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_244 (Conv2D)         (None, 87, 32, 22)        7414      \n",
            "                                                                 \n",
            " max_pooling2d_244 (MaxPooli  (None, 87, 16, 22)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_244 (Ba  (None, 87, 16, 22)       88        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_245 (Conv2D)         (None, 87, 16, 64)        59200     \n",
            "                                                                 \n",
            " max_pooling2d_245 (MaxPooli  (None, 44, 8, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_245 (Ba  (None, 44, 8, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_81 (Flatten)        (None, 22528)             0         \n",
            "                                                                 \n",
            " dense_245 (Dense)           (None, 9)                 202761    \n",
            "                                                                 \n",
            " dropout_164 (Dropout)       (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_246 (Dense)           (None, 16)                160       \n",
            "                                                                 \n",
            " dropout_165 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_247 (Dense)           (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 282,292\n",
            "Trainable params: 281,992\n",
            "Non-trainable params: 300\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 30s 38ms/step - loss: 0.6933 - accuracy: 0.1546 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.4020 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2203 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2201 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.3247 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.1799 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.4064 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.0774 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2227 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2097 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.1472 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2997 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2258 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2179 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.1633 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.0312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 58, 3, 4, 1, 2, 45, 7, 7, 2, 2, 63, 4, 3, 2, 1, 28, 6, 2, 2, 1, 30, 5, 6, 2, 1, 2, 7, 0.2, 19, 0.44, 7, 0.32]\n",
            "Model: \"sequential_82\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_246 (Conv2D)         (None, 87, 128, 58)       754       \n",
            "                                                                 \n",
            " max_pooling2d_246 (MaxPooli  (None, 87, 64, 58)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_246 (Ba  (None, 87, 64, 58)       232       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_247 (Conv2D)         (None, 87, 64, 45)        127935    \n",
            "                                                                 \n",
            " max_pooling2d_247 (MaxPooli  (None, 44, 32, 45)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_247 (Ba  (None, 44, 32, 45)       180       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_248 (Conv2D)         (None, 44, 32, 63)        34083     \n",
            "                                                                 \n",
            " max_pooling2d_248 (MaxPooli  (None, 22, 32, 63)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_248 (Ba  (None, 22, 32, 63)       252       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_249 (Conv2D)         (None, 22, 32, 28)        21196     \n",
            "                                                                 \n",
            " max_pooling2d_249 (MaxPooli  (None, 11, 32, 28)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_249 (Ba  (None, 11, 32, 28)       112       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_250 (Conv2D)         (None, 11, 32, 30)        25230     \n",
            "                                                                 \n",
            " max_pooling2d_250 (MaxPooli  (None, 6, 32, 30)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_250 (Ba  (None, 6, 32, 30)        120       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_82 (Flatten)        (None, 5760)              0         \n",
            "                                                                 \n",
            " dense_248 (Dense)           (None, 7)                 40327     \n",
            "                                                                 \n",
            " dropout_166 (Dropout)       (None, 7)                 0         \n",
            "                                                                 \n",
            " dense_249 (Dense)           (None, 19)                152       \n",
            "                                                                 \n",
            " dropout_167 (Dropout)       (None, 19)                0         \n",
            "                                                                 \n",
            " dense_250 (Dense)           (None, 5)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 250,673\n",
            "Trainable params: 250,225\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 62s 79ms/step - loss: 0.6933 - accuracy: 0.1790 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.2062 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1872 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1437 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.2364 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1939 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1824 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.2389 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1314 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1335 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.1805 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6932 - accuracy: 0.1908 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6932 - accuracy: 0.2117 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 58s 78ms/step - loss: 0.6932 - accuracy: 0.1465 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 58s 77ms/step - loss: 0.6932 - accuracy: 0.2439 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 6s 11ms/step - loss: 0.6932 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 27, 7, 3, 1, 1, 32, 7, 5, 1, 2, 64, 7, 2, 2, 2, 6, 5, 5, 2, 1, 9, 3, 3, 1, 2, 2, 34, 0.3, 26, 0.48, 34, 0.2]\n",
            "Model: \"sequential_83\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_251 (Conv2D)         (None, 87, 128, 27)       594       \n",
            "                                                                 \n",
            " max_pooling2d_251 (MaxPooli  (None, 87, 128, 27)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_251 (Ba  (None, 87, 128, 27)      108       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_252 (Conv2D)         (None, 87, 128, 32)       30272     \n",
            "                                                                 \n",
            " max_pooling2d_252 (MaxPooli  (None, 87, 64, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_252 (Ba  (None, 87, 64, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_83 (Flatten)        (None, 178176)            0         \n",
            "                                                                 \n",
            " dense_251 (Dense)           (None, 34)                6058018   \n",
            "                                                                 \n",
            " dropout_168 (Dropout)       (None, 34)                0         \n",
            "                                                                 \n",
            " dense_252 (Dense)           (None, 26)                910       \n",
            "                                                                 \n",
            " dropout_169 (Dropout)       (None, 26)                0         \n",
            "                                                                 \n",
            " dense_253 (Dense)           (None, 5)                 135       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,090,165\n",
            "Trainable params: 6,090,047\n",
            "Non-trainable params: 118\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 47s 61ms/step - loss: 0.7094 - accuracy: 0.0876 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 44s 59ms/step - loss: 0.6932 - accuracy: 0.2390 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.2076 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.2677 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.1690 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.3067 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.1090 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.3228 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.1453 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.2003 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.1382 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.2097 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.1499 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.3259 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 44s 58ms/step - loss: 0.6932 - accuracy: 0.2776 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.6932 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 44, 4, 6, 2, 2, 37, 5, 2, 1, 2, 21, 4, 2, 2, 2, 8, 4, 5, 2, 2, 25, 6, 6, 1, 1, 2, 3, 0.06, 29, 0.48, 62, 0.32]\n",
            "Model: \"sequential_84\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_253 (Conv2D)         (None, 87, 128, 44)       1100      \n",
            "                                                                 \n",
            " max_pooling2d_253 (MaxPooli  (None, 44, 64, 44)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_253 (Ba  (None, 44, 64, 44)       176       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_84 (Flatten)        (None, 123904)            0         \n",
            "                                                                 \n",
            " dense_254 (Dense)           (None, 3)                 371715    \n",
            "                                                                 \n",
            " dropout_170 (Dropout)       (None, 3)                 0         \n",
            "                                                                 \n",
            " dense_255 (Dense)           (None, 29)                116       \n",
            "                                                                 \n",
            " dropout_171 (Dropout)       (None, 29)                0         \n",
            "                                                                 \n",
            " dense_256 (Dense)           (None, 5)                 150       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 373,257\n",
            "Trainable params: 373,169\n",
            "Non-trainable params: 88\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.6932 - accuracy: 0.1804 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2545 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1766 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1615 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1566 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6949 - accuracy: 0.1274 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.2087 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.1717 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.1825 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.2020 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.1634 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1971 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2142 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.2062 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 12s 17ms/step - loss: 0.6932 - accuracy: 0.2639 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.6931 - accuracy: 0.0625\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 19, 4, 4, 2, 2, 35, 7, 4, 1, 2, 49, 5, 7, 2, 2, 63, 5, 5, 1, 2, 42, 7, 7, 2, 1, 1, 64, 0.06, 18, 0.41, 9, 0.04]\n",
            "Model: \"sequential_85\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_254 (Conv2D)         (None, 87, 128, 19)       323       \n",
            "                                                                 \n",
            " max_pooling2d_254 (MaxPooli  (None, 44, 64, 19)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_254 (Ba  (None, 44, 64, 19)       76        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_255 (Conv2D)         (None, 44, 64, 35)        18655     \n",
            "                                                                 \n",
            " max_pooling2d_255 (MaxPooli  (None, 44, 32, 35)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_255 (Ba  (None, 44, 32, 35)       140       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_256 (Conv2D)         (None, 44, 32, 49)        60074     \n",
            "                                                                 \n",
            " max_pooling2d_256 (MaxPooli  (None, 22, 16, 49)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_256 (Ba  (None, 22, 16, 49)       196       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_85 (Flatten)        (None, 17248)             0         \n",
            "                                                                 \n",
            " dense_257 (Dense)           (None, 64)                1103936   \n",
            "                                                                 \n",
            " dropout_172 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_258 (Dense)           (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,183,725\n",
            "Trainable params: 1,183,519\n",
            "Non-trainable params: 206\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 25s 32ms/step - loss: 0.3092 - accuracy: 0.3321 - val_loss: 0.3327 - val_accuracy: 0.2785\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0671 - accuracy: 0.4455 - val_loss: 0.0886 - val_accuracy: 0.5504\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0309 - accuracy: 0.6386 - val_loss: 0.2109 - val_accuracy: 0.7325\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0208 - accuracy: 0.6900 - val_loss: 0.4250 - val_accuracy: 0.4053\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0176 - accuracy: 0.7292 - val_loss: 0.1328 - val_accuracy: 0.7157\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0160 - accuracy: 0.7676 - val_loss: 0.1593 - val_accuracy: 0.7530\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0148 - accuracy: 0.7852 - val_loss: 0.1871 - val_accuracy: 0.7348\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0109 - accuracy: 0.8091 - val_loss: 0.1458 - val_accuracy: 0.6478\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0093 - accuracy: 0.8215 - val_loss: 0.1252 - val_accuracy: 0.7412\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0114 - accuracy: 0.8196 - val_loss: 0.1079 - val_accuracy: 0.7039\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0081 - accuracy: 0.8331 - val_loss: 0.2629 - val_accuracy: 0.6208\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0080 - accuracy: 0.8300 - val_loss: 0.1569 - val_accuracy: 0.6496\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0080 - accuracy: 0.8276 - val_loss: 0.2265 - val_accuracy: 0.8726\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0076 - accuracy: 0.8466 - val_loss: 0.1901 - val_accuracy: 0.6883\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 22s 30ms/step - loss: 0.0076 - accuracy: 0.8231 - val_loss: 0.1741 - val_accuracy: 0.7584\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.1741 - accuracy: 0.7584\n",
            "sklearn_accuracy: 0.8735\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 4, 5, 5, 2, 2, 64, 6, 2, 2, 1, 36, 5, 7, 1, 2, 64, 3, 5, 1, 2, 9, 6, 7, 2, 2, 1, 10, 0.47, 33, 0.47, 40, 0.2]\n",
            "Model: \"sequential_86\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_257 (Conv2D)         (None, 87, 128, 4)        104       \n",
            "                                                                 \n",
            " max_pooling2d_257 (MaxPooli  (None, 44, 64, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_257 (Ba  (None, 44, 64, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_258 (Conv2D)         (None, 44, 64, 64)        3136      \n",
            "                                                                 \n",
            " max_pooling2d_258 (MaxPooli  (None, 22, 64, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_258 (Ba  (None, 22, 64, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_259 (Conv2D)         (None, 22, 64, 36)        80676     \n",
            "                                                                 \n",
            " max_pooling2d_259 (MaxPooli  (None, 22, 32, 36)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_259 (Ba  (None, 22, 32, 36)       144       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_260 (Conv2D)         (None, 22, 32, 64)        34624     \n",
            "                                                                 \n",
            " max_pooling2d_260 (MaxPooli  (None, 22, 16, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_260 (Ba  (None, 22, 16, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_261 (Conv2D)         (None, 22, 16, 9)         24201     \n",
            "                                                                 \n",
            " max_pooling2d_261 (MaxPooli  (None, 11, 8, 9)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_261 (Ba  (None, 11, 8, 9)         36        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_86 (Flatten)        (None, 792)               0         \n",
            "                                                                 \n",
            " dense_259 (Dense)           (None, 10)                7930      \n",
            "                                                                 \n",
            " dropout_173 (Dropout)       (None, 10)                0         \n",
            "                                                                 \n",
            " dense_260 (Dense)           (None, 5)                 55        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 151,434\n",
            "Trainable params: 151,080\n",
            "Non-trainable params: 354\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 26s 33ms/step - loss: 0.5750 - accuracy: 0.1545 - val_loss: 0.4268 - val_accuracy: 0.1421\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 23s 31ms/step - loss: 0.4575 - accuracy: 0.2791 - val_loss: 0.3452 - val_accuracy: 0.4054\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3869 - accuracy: 0.4411 - val_loss: 0.2976 - val_accuracy: 0.5943\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3619 - accuracy: 0.4880 - val_loss: 0.2496 - val_accuracy: 0.4567\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3520 - accuracy: 0.4991 - val_loss: 0.2784 - val_accuracy: 0.4823\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3505 - accuracy: 0.4866 - val_loss: 0.2428 - val_accuracy: 0.5447\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3438 - accuracy: 0.4890 - val_loss: 0.3148 - val_accuracy: 0.4549\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3417 - accuracy: 0.4932 - val_loss: 0.2415 - val_accuracy: 0.6284\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3387 - accuracy: 0.4889 - val_loss: 0.2451 - val_accuracy: 0.4984\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3355 - accuracy: 0.4882 - val_loss: 0.2680 - val_accuracy: 0.3996\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3294 - accuracy: 0.4929 - val_loss: 0.2705 - val_accuracy: 0.3870\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3291 - accuracy: 0.4848 - val_loss: 0.2065 - val_accuracy: 0.4634\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3276 - accuracy: 0.4954 - val_loss: 0.2530 - val_accuracy: 0.6047\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3218 - accuracy: 0.4954 - val_loss: 0.2169 - val_accuracy: 0.5271\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.3202 - accuracy: 0.4863 - val_loss: 0.3584 - val_accuracy: 0.6250\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.3584 - accuracy: 0.6250\n",
            "sklearn_accuracy: 0.396375\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 13, 4, 6, 1, 1, 46, 2, 6, 2, 2, 46, 5, 5, 1, 2, 39, 7, 3, 1, 1, 39, 3, 2, 2, 2, 3, 24, 0.29, 54, 0.33, 48, 0.09]\n",
            "Model: \"sequential_87\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_262 (Conv2D)         (None, 87, 128, 13)       325       \n",
            "                                                                 \n",
            " max_pooling2d_262 (MaxPooli  (None, 87, 128, 13)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_262 (Ba  (None, 87, 128, 13)      52        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_87 (Flatten)        (None, 144768)            0         \n",
            "                                                                 \n",
            " dense_261 (Dense)           (None, 24)                3474456   \n",
            "                                                                 \n",
            " dropout_174 (Dropout)       (None, 24)                0         \n",
            "                                                                 \n",
            " dense_262 (Dense)           (None, 54)                1350      \n",
            "                                                                 \n",
            " dropout_175 (Dropout)       (None, 54)                0         \n",
            "                                                                 \n",
            " dense_263 (Dense)           (None, 48)                2640      \n",
            "                                                                 \n",
            " dropout_176 (Dropout)       (None, 48)                0         \n",
            "                                                                 \n",
            " dense_264 (Dense)           (None, 5)                 245       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,479,068\n",
            "Trainable params: 3,479,042\n",
            "Non-trainable params: 26\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.7030 - accuracy: 0.3654 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.1411 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.1488 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.2039 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.2590 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.2231 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.1769 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.1925 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.2053 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.1392 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.2362 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.2860 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.2017 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.1720 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.6932 - accuracy: 0.1945 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.6932 - accuracy: 0.2500\n",
            "sklearn_accuracy: 0.03125\n",
            "(75.0 % )\n",
            "Creating individual 1 out of 8\n",
            "- working on # of filters' of conv layers  (index: 1, 6, 11, 16, 21)\n",
            "- working on x and y kernel dimensions     (index: 2, 3, 7, 8, 12, 13, 17, 18, 22, 23)\n",
            "- working on x and y MaxPooling size       (index: 4, 5, 9, 10, 14, 15, 19, 20, 24, 25)\n",
            "- working # of neurons in dense layers     (index: 27, 29, 31)\n",
            "- working dropout prob. after dense layers (index: 28, 30, 32)\n",
            "[3, 46, 2, 4, 1, 2, 31, 6, 6, 2, 1, 25, 4, 3, 2, 1, 34, 3, 5, 2, 2, 23, 4, 3, 2, 2, 1, 30, 0.49, 21, 0.36, 46, 0.01]\n",
            "\n",
            "Creating individual 2 out of 8\n",
            "[2, 13, 2, 6, 1, 2, 34, 7, 4, 1, 1, 24, 5, 5, 1, 2, 36, 6, 6, 1, 2, 57, 5, 5, 1, 2, 1, 57, 0.36, 59, 0.26, 61, 0.37]\n",
            "\n",
            "Creating individual 3 out of 8\n",
            "[2, 56, 5, 4, 1, 2, 20, 4, 3, 2, 2, 32, 2, 2, 2, 2, 20, 4, 4, 1, 2, 2, 2, 5, 1, 1, 3, 6, 0.07, 29, 0.07, 12, 0.18]\n",
            "\n",
            "Creating individual 4 out of 8\n",
            "[5, 33, 7, 3, 1, 1, 7, 6, 6, 1, 1, 60, 5, 2, 2, 2, 14, 3, 2, 2, 1, 11, 3, 6, 2, 2, 2, 4, 0.05, 19, 0.42, 13, 0.45]\n",
            "\n",
            "Creating individual 5 out of 8\n",
            "[4, 44, 6, 7, 1, 1, 58, 6, 5, 1, 2, 49, 4, 3, 2, 2, 6, 5, 3, 2, 1, 54, 4, 7, 2, 1, 3, 41, 0.2, 5, 0.18, 21, 0.2]\n",
            "\n",
            "Creating individual 6 out of 8\n",
            "[2, 34, 6, 5, 1, 1, 64, 2, 5, 2, 1, 44, 7, 6, 2, 1, 55, 3, 2, 1, 2, 8, 3, 3, 2, 2, 1, 12, 0.17, 57, 0.29, 25, 0.42]\n",
            "\n",
            "Creating individual 7 out of 8\n",
            "[3, 40, 5, 3, 1, 2, 39, 3, 2, 2, 2, 24, 3, 4, 2, 1, 53, 2, 4, 1, 1, 17, 3, 3, 1, 2, 3, 47, 0.4, 23, 0.01, 45, 0.23]\n",
            "\n",
            "Creating individual 8 out of 8\n",
            "[1, 6, 3, 3, 2, 1, 8, 4, 2, 2, 2, 10, 4, 7, 2, 1, 17, 6, 3, 1, 2, 4, 4, 2, 2, 1, 3, 63, 0.24, 4, 0.15, 5, 0.33]\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 46, 2, 4, 1, 2, 31, 6, 6, 2, 1, 25, 4, 3, 2, 1, 34, 3, 5, 2, 2, 23, 4, 3, 2, 2, 1, 30, 0.49, 21, 0.36, 46, 0.01]\n",
            "Model: \"sequential_88\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_263 (Conv2D)         (None, 87, 128, 46)       414       \n",
            "                                                                 \n",
            " max_pooling2d_263 (MaxPooli  (None, 87, 64, 46)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_263 (Ba  (None, 87, 64, 46)       184       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_264 (Conv2D)         (None, 87, 64, 31)        51367     \n",
            "                                                                 \n",
            " max_pooling2d_264 (MaxPooli  (None, 44, 64, 31)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_264 (Ba  (None, 44, 64, 31)       124       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_265 (Conv2D)         (None, 44, 64, 25)        9325      \n",
            "                                                                 \n",
            " max_pooling2d_265 (MaxPooli  (None, 22, 64, 25)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_265 (Ba  (None, 22, 64, 25)       100       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_88 (Flatten)        (None, 35200)             0         \n",
            "                                                                 \n",
            " dense_265 (Dense)           (None, 30)                1056030   \n",
            "                                                                 \n",
            " dropout_177 (Dropout)       (None, 30)                0         \n",
            "                                                                 \n",
            " dense_266 (Dense)           (None, 5)                 155       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,117,699\n",
            "Trainable params: 1,117,495\n",
            "Non-trainable params: 204\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 46s 59ms/step - loss: 0.6956 - accuracy: 0.2537 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.1040 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.0821 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.1794 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.1332 - val_loss: 0.6932 - val_accuracy: 0.2499\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.1993 - val_loss: 0.6932 - val_accuracy: 0.2499\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.1688 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.1726 - val_loss: 0.6932 - val_accuracy: 0.2499\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.2206 - val_loss: 0.6932 - val_accuracy: 0.0313\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.1556 - val_loss: 0.6932 - val_accuracy: 0.0313\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.2849 - val_loss: 0.6932 - val_accuracy: 0.0313\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6941 - accuracy: 0.1552 - val_loss: 11.1224 - val_accuracy: 0.1714\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6935 - accuracy: 0.1275 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.2755 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6932 - accuracy: 0.1478 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 0.6932 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 13, 2, 6, 1, 2, 34, 7, 4, 1, 1, 24, 5, 5, 1, 2, 36, 6, 6, 1, 2, 57, 5, 5, 1, 2, 1, 57, 0.36, 59, 0.26, 61, 0.37]\n",
            "Model: \"sequential_89\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_266 (Conv2D)         (None, 87, 128, 13)       169       \n",
            "                                                                 \n",
            " max_pooling2d_266 (MaxPooli  (None, 87, 64, 13)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_266 (Ba  (None, 87, 64, 13)       52        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_267 (Conv2D)         (None, 87, 64, 34)        12410     \n",
            "                                                                 \n",
            " max_pooling2d_267 (MaxPooli  (None, 87, 64, 34)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_267 (Ba  (None, 87, 64, 34)       136       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_89 (Flatten)        (None, 189312)            0         \n",
            "                                                                 \n",
            " dense_267 (Dense)           (None, 57)                10790841  \n",
            "                                                                 \n",
            " dropout_178 (Dropout)       (None, 57)                0         \n",
            "                                                                 \n",
            " dense_268 (Dense)           (None, 5)                 290       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,803,898\n",
            "Trainable params: 10,803,804\n",
            "Non-trainable params: 94\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 28s 36ms/step - loss: 0.7436 - accuracy: 0.1387 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6933 - accuracy: 0.1982 - val_loss: 0.6933 - val_accuracy: 0.5318\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.2636 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.1650 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.2008 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.1465 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.1940 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.2586 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.3237 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.1145 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.2366 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.2071 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.2528 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.0699 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.6932 - accuracy: 0.1965 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.0625\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 56, 5, 4, 1, 2, 20, 4, 3, 2, 2, 32, 2, 2, 2, 2, 20, 4, 4, 1, 2, 2, 2, 5, 1, 1, 3, 6, 0.07, 29, 0.07, 12, 0.18]\n",
            "Model: \"sequential_90\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_268 (Conv2D)         (None, 87, 128, 56)       1176      \n",
            "                                                                 \n",
            " max_pooling2d_268 (MaxPooli  (None, 87, 64, 56)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_268 (Ba  (None, 87, 64, 56)       224       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_269 (Conv2D)         (None, 87, 64, 20)        13460     \n",
            "                                                                 \n",
            " max_pooling2d_269 (MaxPooli  (None, 44, 32, 20)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_269 (Ba  (None, 44, 32, 20)       80        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_90 (Flatten)        (None, 28160)             0         \n",
            "                                                                 \n",
            " dense_269 (Dense)           (None, 6)                 168966    \n",
            "                                                                 \n",
            " dropout_179 (Dropout)       (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_270 (Dense)           (None, 29)                203       \n",
            "                                                                 \n",
            " dropout_180 (Dropout)       (None, 29)                0         \n",
            "                                                                 \n",
            " dense_271 (Dense)           (None, 12)                360       \n",
            "                                                                 \n",
            " dropout_181 (Dropout)       (None, 12)                0         \n",
            "                                                                 \n",
            " dense_272 (Dense)           (None, 5)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 184,534\n",
            "Trainable params: 184,382\n",
            "Non-trainable params: 152\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 34s 44ms/step - loss: 0.6933 - accuracy: 0.1587 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.2517 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.1618 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.1607 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.2001 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.1186 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.2195 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.1345 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.1398 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.3096 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.2607 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.2305 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.2025 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.1899 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.6932 - accuracy: 0.1392 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6932 - accuracy: 0.0312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 33, 7, 3, 1, 1, 7, 6, 6, 1, 1, 60, 5, 2, 2, 2, 14, 3, 2, 2, 1, 11, 3, 6, 2, 2, 2, 4, 0.05, 19, 0.42, 13, 0.45]\n",
            "Model: \"sequential_91\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_270 (Conv2D)         (None, 87, 128, 33)       726       \n",
            "                                                                 \n",
            " max_pooling2d_270 (MaxPooli  (None, 87, 128, 33)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_270 (Ba  (None, 87, 128, 33)      132       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_271 (Conv2D)         (None, 87, 128, 7)        8323      \n",
            "                                                                 \n",
            " max_pooling2d_271 (MaxPooli  (None, 87, 128, 7)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_271 (Ba  (None, 87, 128, 7)       28        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_272 (Conv2D)         (None, 87, 128, 60)       4260      \n",
            "                                                                 \n",
            " max_pooling2d_272 (MaxPooli  (None, 44, 64, 60)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_272 (Ba  (None, 44, 64, 60)       240       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_273 (Conv2D)         (None, 44, 64, 14)        5054      \n",
            "                                                                 \n",
            " max_pooling2d_273 (MaxPooli  (None, 22, 64, 14)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_273 (Ba  (None, 22, 64, 14)       56        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_274 (Conv2D)         (None, 22, 64, 11)        2783      \n",
            "                                                                 \n",
            " max_pooling2d_274 (MaxPooli  (None, 11, 32, 11)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_274 (Ba  (None, 11, 32, 11)       44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_91 (Flatten)        (None, 3872)              0         \n",
            "                                                                 \n",
            " dense_273 (Dense)           (None, 4)                 15492     \n",
            "                                                                 \n",
            " dropout_182 (Dropout)       (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_274 (Dense)           (None, 19)                95        \n",
            "                                                                 \n",
            " dropout_183 (Dropout)       (None, 19)                0         \n",
            "                                                                 \n",
            " dense_275 (Dense)           (None, 5)                 100       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37,333\n",
            "Trainable params: 37,083\n",
            "Non-trainable params: 250\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 72s 93ms/step - loss: 0.6932 - accuracy: 0.1288 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.1993 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.1807 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.2859 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.2863 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.2095 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.2672 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.1519 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.1825 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 68s 90ms/step - loss: 0.6932 - accuracy: 0.1668 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.2721 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.1842 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 68s 90ms/step - loss: 0.6932 - accuracy: 0.3193 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.1702 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 67s 90ms/step - loss: 0.6932 - accuracy: 0.1701 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "500/500 [==============================] - 6s 10ms/step - loss: 0.6932 - accuracy: 0.5312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 44, 6, 7, 1, 1, 58, 6, 5, 1, 2, 49, 4, 3, 2, 2, 6, 5, 3, 2, 1, 54, 4, 7, 2, 1, 3, 41, 0.2, 5, 0.18, 21, 0.2]\n",
            "Model: \"sequential_92\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_275 (Conv2D)         (None, 87, 128, 44)       1892      \n",
            "                                                                 \n",
            " max_pooling2d_275 (MaxPooli  (None, 87, 128, 44)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_275 (Ba  (None, 87, 128, 44)      176       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_276 (Conv2D)         (None, 87, 128, 58)       76618     \n",
            "                                                                 \n",
            " max_pooling2d_276 (MaxPooli  (None, 87, 64, 58)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_276 (Ba  (None, 87, 64, 58)       232       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_277 (Conv2D)         (None, 87, 64, 49)        34153     \n",
            "                                                                 \n",
            " max_pooling2d_277 (MaxPooli  (None, 44, 32, 49)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_277 (Ba  (None, 44, 32, 49)       196       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_278 (Conv2D)         (None, 44, 32, 6)         4416      \n",
            "                                                                 \n",
            " max_pooling2d_278 (MaxPooli  (None, 22, 32, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_278 (Ba  (None, 22, 32, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_92 (Flatten)        (None, 4224)              0         \n",
            "                                                                 \n",
            " dense_276 (Dense)           (None, 41)                173225    \n",
            "                                                                 \n",
            " dropout_184 (Dropout)       (None, 41)                0         \n",
            "                                                                 \n",
            " dense_277 (Dense)           (None, 5)                 210       \n",
            "                                                                 \n",
            " dropout_185 (Dropout)       (None, 5)                 0         \n",
            "                                                                 \n",
            " dense_278 (Dense)           (None, 21)                126       \n",
            "                                                                 \n",
            " dropout_186 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_279 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 291,378\n",
            "Trainable params: 291,064\n",
            "Non-trainable params: 314\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 110s 144ms/step - loss: 0.5785 - accuracy: 0.2034 - val_loss: 0.7848 - val_accuracy: 0.2177\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 106s 141ms/step - loss: 0.4844 - accuracy: 0.3108 - val_loss: 0.4588 - val_accuracy: 0.3616\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 106s 141ms/step - loss: 0.4595 - accuracy: 0.3532 - val_loss: 0.4544 - val_accuracy: 0.3568\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 106s 141ms/step - loss: 0.4490 - accuracy: 0.3745 - val_loss: 0.6356 - val_accuracy: 0.2118\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 106s 141ms/step - loss: 0.4392 - accuracy: 0.3710 - val_loss: 0.4423 - val_accuracy: 0.3390\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 106s 141ms/step - loss: 0.4257 - accuracy: 0.3659 - val_loss: 0.7006 - val_accuracy: 0.3184\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 106s 141ms/step - loss: 0.4185 - accuracy: 0.3683 - val_loss: 0.4402 - val_accuracy: 0.3437\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 106s 141ms/step - loss: 0.4074 - accuracy: 0.3751 - val_loss: 0.4130 - val_accuracy: 0.3503\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 105s 141ms/step - loss: 0.4021 - accuracy: 0.3762 - val_loss: 0.4071 - val_accuracy: 0.3813\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 105s 141ms/step - loss: 0.3936 - accuracy: 0.3889 - val_loss: 0.3654 - val_accuracy: 0.3303\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 106s 141ms/step - loss: 0.3858 - accuracy: 0.4011 - val_loss: 0.3775 - val_accuracy: 0.3448\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 105s 141ms/step - loss: 0.3836 - accuracy: 0.4168 - val_loss: 0.4005 - val_accuracy: 0.5101\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 105s 141ms/step - loss: 0.3794 - accuracy: 0.4309 - val_loss: 0.3513 - val_accuracy: 0.4461\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 105s 140ms/step - loss: 0.3740 - accuracy: 0.4347 - val_loss: 0.7063 - val_accuracy: 0.5624\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 105s 140ms/step - loss: 0.3816 - accuracy: 0.4474 - val_loss: 0.9904 - val_accuracy: 0.1378\n",
            "500/500 [==============================] - 9s 18ms/step - loss: 0.9904 - accuracy: 0.1378\n",
            "sklearn_accuracy: 0.0985625\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 34, 6, 5, 1, 1, 64, 2, 5, 2, 1, 44, 7, 6, 2, 1, 55, 3, 2, 1, 2, 8, 3, 3, 2, 2, 1, 12, 0.17, 57, 0.29, 25, 0.42]\n",
            "Model: \"sequential_93\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_279 (Conv2D)         (None, 87, 128, 34)       1054      \n",
            "                                                                 \n",
            " max_pooling2d_279 (MaxPooli  (None, 87, 128, 34)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_279 (Ba  (None, 87, 128, 34)      136       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_280 (Conv2D)         (None, 87, 128, 64)       21824     \n",
            "                                                                 \n",
            " max_pooling2d_280 (MaxPooli  (None, 44, 128, 64)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_280 (Ba  (None, 44, 128, 64)      256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_93 (Flatten)        (None, 360448)            0         \n",
            "                                                                 \n",
            " dense_280 (Dense)           (None, 12)                4325388   \n",
            "                                                                 \n",
            " dropout_187 (Dropout)       (None, 12)                0         \n",
            "                                                                 \n",
            " dense_281 (Dense)           (None, 5)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,348,723\n",
            "Trainable params: 4,348,527\n",
            "Non-trainable params: 196\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 54s 70ms/step - loss: 0.7130 - accuracy: 0.2071 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.2221 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.3039 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.2635 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.1540 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.3890 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.0931 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.3250 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.2690 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.1526 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.1284 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.2595 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.1191 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.1601 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 51s 68ms/step - loss: 0.6932 - accuracy: 0.1768 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.6932 - accuracy: 0.0312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 40, 5, 3, 1, 2, 39, 3, 2, 2, 2, 24, 3, 4, 2, 1, 53, 2, 4, 1, 1, 17, 3, 3, 1, 2, 3, 47, 0.4, 23, 0.01, 45, 0.23]\n",
            "Model: \"sequential_94\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_281 (Conv2D)         (None, 87, 128, 40)       640       \n",
            "                                                                 \n",
            " max_pooling2d_281 (MaxPooli  (None, 87, 64, 40)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_281 (Ba  (None, 87, 64, 40)       160       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_282 (Conv2D)         (None, 87, 64, 39)        9399      \n",
            "                                                                 \n",
            " max_pooling2d_282 (MaxPooli  (None, 44, 32, 39)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_282 (Ba  (None, 44, 32, 39)       156       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_283 (Conv2D)         (None, 44, 32, 24)        11256     \n",
            "                                                                 \n",
            " max_pooling2d_283 (MaxPooli  (None, 22, 32, 24)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_283 (Ba  (None, 22, 32, 24)       96        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_94 (Flatten)        (None, 16896)             0         \n",
            "                                                                 \n",
            " dense_282 (Dense)           (None, 47)                794159    \n",
            "                                                                 \n",
            " dropout_188 (Dropout)       (None, 47)                0         \n",
            "                                                                 \n",
            " dense_283 (Dense)           (None, 23)                1104      \n",
            "                                                                 \n",
            " dropout_189 (Dropout)       (None, 23)                0         \n",
            "                                                                 \n",
            " dense_284 (Dense)           (None, 45)                1080      \n",
            "                                                                 \n",
            " dropout_190 (Dropout)       (None, 45)                0         \n",
            "                                                                 \n",
            " dense_285 (Dense)           (None, 5)                 230       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 818,280\n",
            "Trainable params: 818,074\n",
            "Non-trainable params: 206\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 36s 46ms/step - loss: 0.6135 - accuracy: 0.1184 - val_loss: 0.5398 - val_accuracy: 0.1386\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.5424 - accuracy: 0.1280 - val_loss: 0.4793 - val_accuracy: 0.2021\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.4937 - accuracy: 0.1422 - val_loss: 0.5042 - val_accuracy: 0.1817\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.4559 - accuracy: 0.1568 - val_loss: 0.4583 - val_accuracy: 0.1784\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.4032 - accuracy: 0.1859 - val_loss: 0.3666 - val_accuracy: 0.2339\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.3508 - accuracy: 0.2116 - val_loss: 0.2820 - val_accuracy: 0.2406\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.2861 - accuracy: 0.2494 - val_loss: 0.3301 - val_accuracy: 0.2559\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.2525 - accuracy: 0.2852 - val_loss: 0.3725 - val_accuracy: 0.2058\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.2333 - accuracy: 0.3085 - val_loss: 0.2499 - val_accuracy: 0.2874\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.2193 - accuracy: 0.3319 - val_loss: 0.2101 - val_accuracy: 0.3100\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.2077 - accuracy: 0.3307 - val_loss: 0.2391 - val_accuracy: 0.3428\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.1993 - accuracy: 0.3286 - val_loss: 0.2449 - val_accuracy: 0.2538\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.1957 - accuracy: 0.3394 - val_loss: 0.2337 - val_accuracy: 0.3778\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.1912 - accuracy: 0.3314 - val_loss: 0.1918 - val_accuracy: 0.3451\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 33s 44ms/step - loss: 0.1691 - accuracy: 0.3449 - val_loss: 0.1851 - val_accuracy: 0.2963\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.1851 - accuracy: 0.2963\n",
            "sklearn_accuracy: 0.683125\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 6, 3, 3, 2, 1, 8, 4, 2, 2, 2, 10, 4, 7, 2, 1, 17, 6, 3, 1, 2, 4, 4, 2, 2, 1, 3, 63, 0.24, 4, 0.15, 5, 0.33]\n",
            "Model: \"sequential_95\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_284 (Conv2D)         (None, 87, 128, 6)        60        \n",
            "                                                                 \n",
            " max_pooling2d_284 (MaxPooli  (None, 44, 128, 6)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_284 (Ba  (None, 44, 128, 6)       24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_95 (Flatten)        (None, 33792)             0         \n",
            "                                                                 \n",
            " dense_286 (Dense)           (None, 63)                2128959   \n",
            "                                                                 \n",
            " dropout_191 (Dropout)       (None, 63)                0         \n",
            "                                                                 \n",
            " dense_287 (Dense)           (None, 4)                 256       \n",
            "                                                                 \n",
            " dropout_192 (Dropout)       (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_288 (Dense)           (None, 5)                 25        \n",
            "                                                                 \n",
            " dropout_193 (Dropout)       (None, 5)                 0         \n",
            "                                                                 \n",
            " dense_289 (Dense)           (None, 5)                 30        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,129,354\n",
            "Trainable params: 2,129,342\n",
            "Non-trainable params: 12\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.6936 - accuracy: 0.2463 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.2281 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.1755 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.1321 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.1776 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.2068 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.0771 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.2384 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.1443 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.2577 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.1771 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.2233 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.1896 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.1796 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 5s 7ms/step - loss: 0.6932 - accuracy: 0.2073 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6932 - accuracy: 0.0625\n",
            "sklearn_accuracy: 0.03125\n",
            "(81.25 % )\n",
            "Creating individual 1 out of 8\n",
            "- working on # of filters' of conv layers  (index: 1, 6, 11, 16, 21)\n",
            "- working on x and y kernel dimensions     (index: 2, 3, 7, 8, 12, 13, 17, 18, 22, 23)\n",
            "- working on x and y MaxPooling size       (index: 4, 5, 9, 10, 14, 15, 19, 20, 24, 25)\n",
            "- working # of neurons in dense layers     (index: 27, 29, 31)\n",
            "- working dropout prob. after dense layers (index: 28, 30, 32)\n",
            "[3, 37, 4, 5, 1, 1, 42, 7, 5, 1, 2, 29, 3, 3, 1, 1, 4, 4, 4, 1, 1, 8, 7, 4, 1, 1, 3, 37, 0.4, 5, 0.29, 54, 0.14]\n",
            "\n",
            "Creating individual 2 out of 8\n",
            "[3, 6, 6, 7, 2, 2, 29, 7, 3, 2, 2, 59, 3, 2, 2, 2, 64, 7, 3, 1, 1, 10, 7, 5, 2, 1, 3, 8, 0.38, 28, 0.24, 36, 0.01]\n",
            "\n",
            "Creating individual 3 out of 8\n",
            "[4, 11, 3, 5, 2, 2, 2, 6, 5, 2, 1, 14, 2, 7, 2, 2, 62, 5, 3, 1, 1, 14, 4, 2, 2, 2, 3, 40, 0.49, 23, 0.12, 3, 0.0]\n",
            "\n",
            "Creating individual 4 out of 8\n",
            "[1, 26, 6, 4, 2, 2, 41, 6, 3, 2, 1, 8, 4, 3, 1, 2, 32, 3, 7, 2, 2, 62, 5, 4, 2, 2, 1, 60, 0.06, 31, 0.36, 22, 0.49]\n",
            "\n",
            "Creating individual 5 out of 8\n",
            "[2, 20, 3, 7, 2, 2, 20, 7, 6, 2, 1, 36, 3, 4, 1, 1, 45, 7, 2, 1, 2, 51, 4, 3, 2, 1, 3, 4, 0.25, 53, 0.3, 33, 0.06]\n",
            "\n",
            "Creating individual 6 out of 8\n",
            "[2, 2, 5, 6, 2, 1, 33, 4, 2, 2, 2, 63, 7, 7, 2, 1, 58, 6, 5, 1, 2, 57, 2, 4, 2, 1, 3, 6, 0.03, 50, 0.02, 62, 0.33]\n",
            "\n",
            "Creating individual 7 out of 8\n",
            "[5, 8, 7, 2, 1, 1, 32, 6, 5, 2, 1, 64, 2, 2, 2, 2, 60, 7, 5, 2, 2, 38, 5, 3, 1, 2, 3, 22, 0.13, 39, 0.35, 11, 0.06]\n",
            "\n",
            "Creating individual 8 out of 8\n",
            "[4, 54, 4, 5, 2, 1, 50, 2, 4, 1, 1, 58, 4, 4, 1, 2, 24, 3, 5, 2, 2, 13, 4, 3, 2, 2, 2, 63, 0.19, 41, 0.49, 16, 0.29]\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 37, 4, 5, 1, 1, 42, 7, 5, 1, 2, 29, 3, 3, 1, 1, 4, 4, 4, 1, 1, 8, 7, 4, 1, 1, 3, 37, 0.4, 5, 0.29, 54, 0.14]\n",
            "Model: \"sequential_96\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_285 (Conv2D)         (None, 87, 128, 37)       777       \n",
            "                                                                 \n",
            " max_pooling2d_285 (MaxPooli  (None, 87, 128, 37)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_285 (Ba  (None, 87, 128, 37)      148       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_286 (Conv2D)         (None, 87, 128, 42)       54432     \n",
            "                                                                 \n",
            " max_pooling2d_286 (MaxPooli  (None, 87, 64, 42)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_286 (Ba  (None, 87, 64, 42)       168       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_287 (Conv2D)         (None, 87, 64, 29)        10991     \n",
            "                                                                 \n",
            " max_pooling2d_287 (MaxPooli  (None, 87, 64, 29)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_287 (Ba  (None, 87, 64, 29)       116       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_96 (Flatten)        (None, 161472)            0         \n",
            "                                                                 \n",
            " dense_290 (Dense)           (None, 37)                5974501   \n",
            "                                                                 \n",
            " dropout_194 (Dropout)       (None, 37)                0         \n",
            "                                                                 \n",
            " dense_291 (Dense)           (None, 5)                 190       \n",
            "                                                                 \n",
            " dropout_195 (Dropout)       (None, 5)                 0         \n",
            "                                                                 \n",
            " dense_292 (Dense)           (None, 54)                324       \n",
            "                                                                 \n",
            " dropout_196 (Dropout)       (None, 54)                0         \n",
            "                                                                 \n",
            " dense_293 (Dense)           (None, 5)                 275       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,041,922\n",
            "Trainable params: 6,041,706\n",
            "Non-trainable params: 216\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 79s 103ms/step - loss: 0.6878 - accuracy: 0.1711 - val_loss: 0.6943 - val_accuracy: 0.1250\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 75s 100ms/step - loss: 0.6805 - accuracy: 0.1501 - val_loss: 0.6942 - val_accuracy: 0.2500\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 75s 100ms/step - loss: 0.6785 - accuracy: 0.1999 - val_loss: 0.6945 - val_accuracy: 0.1250\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 75s 100ms/step - loss: 0.6594 - accuracy: 0.1472 - val_loss: 0.6023 - val_accuracy: 0.0938\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 75s 100ms/step - loss: 0.6330 - accuracy: 0.1144 - val_loss: 0.5839 - val_accuracy: 0.0937\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 75s 99ms/step - loss: 0.6289 - accuracy: 0.1049 - val_loss: 0.6139 - val_accuracy: 0.1015\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 75s 100ms/step - loss: 0.6340 - accuracy: 0.1217 - val_loss: 0.6081 - val_accuracy: 0.0636\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 75s 100ms/step - loss: 0.6251 - accuracy: 0.1249 - val_loss: 0.5827 - val_accuracy: 0.1577\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 75s 100ms/step - loss: 0.6189 - accuracy: 0.1645 - val_loss: 0.5874 - val_accuracy: 0.1562\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 75s 100ms/step - loss: 0.6147 - accuracy: 0.1940 - val_loss: 0.5951 - val_accuracy: 0.1574\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 75s 99ms/step - loss: 0.6118 - accuracy: 0.1904 - val_loss: 0.6146 - val_accuracy: 0.3141\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 75s 99ms/step - loss: 0.6060 - accuracy: 0.2205 - val_loss: 0.5770 - val_accuracy: 0.0938\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 75s 100ms/step - loss: 0.6035 - accuracy: 0.2224 - val_loss: 0.6375 - val_accuracy: 0.0627\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 75s 100ms/step - loss: 0.6011 - accuracy: 0.2169 - val_loss: 0.6353 - val_accuracy: 0.3113\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 75s 100ms/step - loss: 0.5999 - accuracy: 0.2233 - val_loss: 0.6434 - val_accuracy: 0.3121\n",
            "500/500 [==============================] - 6s 12ms/step - loss: 0.6434 - accuracy: 0.3121\n",
            "sklearn_accuracy: 0.063\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 6, 6, 7, 2, 2, 29, 7, 3, 2, 2, 59, 3, 2, 2, 2, 64, 7, 3, 1, 1, 10, 7, 5, 2, 1, 3, 8, 0.38, 28, 0.24, 36, 0.01]\n",
            "Model: \"sequential_97\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_288 (Conv2D)         (None, 87, 128, 6)        258       \n",
            "                                                                 \n",
            " max_pooling2d_288 (MaxPooli  (None, 44, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_288 (Ba  (None, 44, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_289 (Conv2D)         (None, 44, 64, 29)        3683      \n",
            "                                                                 \n",
            " max_pooling2d_289 (MaxPooli  (None, 22, 32, 29)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_289 (Ba  (None, 22, 32, 29)       116       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_290 (Conv2D)         (None, 22, 32, 59)        10325     \n",
            "                                                                 \n",
            " max_pooling2d_290 (MaxPooli  (None, 11, 16, 59)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_290 (Ba  (None, 11, 16, 59)       236       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_97 (Flatten)        (None, 10384)             0         \n",
            "                                                                 \n",
            " dense_294 (Dense)           (None, 8)                 83080     \n",
            "                                                                 \n",
            " dropout_197 (Dropout)       (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_295 (Dense)           (None, 28)                252       \n",
            "                                                                 \n",
            " dropout_198 (Dropout)       (None, 28)                0         \n",
            "                                                                 \n",
            " dense_296 (Dense)           (None, 36)                1044      \n",
            "                                                                 \n",
            " dropout_199 (Dropout)       (None, 36)                0         \n",
            "                                                                 \n",
            " dense_297 (Dense)           (None, 5)                 185       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 99,203\n",
            "Trainable params: 99,015\n",
            "Non-trainable params: 188\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 12s 14ms/step - loss: 0.6285 - accuracy: 0.2414 - val_loss: 0.5725 - val_accuracy: 0.0961\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5749 - accuracy: 0.1295 - val_loss: 0.5528 - val_accuracy: 0.3080\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5521 - accuracy: 0.1606 - val_loss: 0.5213 - val_accuracy: 0.1552\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 9s 13ms/step - loss: 0.5429 - accuracy: 0.1638 - val_loss: 0.5439 - val_accuracy: 0.0944\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5367 - accuracy: 0.1716 - val_loss: 0.5142 - val_accuracy: 0.0949\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5156 - accuracy: 0.1831 - val_loss: 0.5183 - val_accuracy: 0.3157\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5011 - accuracy: 0.2073 - val_loss: 0.4979 - val_accuracy: 0.0678\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4914 - accuracy: 0.2073 - val_loss: 0.5133 - val_accuracy: 0.1631\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4781 - accuracy: 0.1972 - val_loss: 0.4924 - val_accuracy: 0.0793\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4686 - accuracy: 0.1957 - val_loss: 0.5064 - val_accuracy: 0.3318\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4634 - accuracy: 0.1929 - val_loss: 0.5568 - val_accuracy: 0.0967\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4583 - accuracy: 0.1874 - val_loss: 0.5747 - val_accuracy: 0.1702\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4552 - accuracy: 0.1728 - val_loss: 0.5874 - val_accuracy: 0.1781\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4544 - accuracy: 0.1825 - val_loss: 0.4957 - val_accuracy: 0.0693\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4537 - accuracy: 0.1862 - val_loss: 0.5673 - val_accuracy: 0.0991\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.0991\n",
            "sklearn_accuracy: 0.095875\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 11, 3, 5, 2, 2, 2, 6, 5, 2, 1, 14, 2, 7, 2, 2, 62, 5, 3, 1, 1, 14, 4, 2, 2, 2, 3, 40, 0.49, 23, 0.12, 3, 0.0]\n",
            "Model: \"sequential_98\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_291 (Conv2D)         (None, 87, 128, 11)       176       \n",
            "                                                                 \n",
            " max_pooling2d_291 (MaxPooli  (None, 44, 64, 11)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_291 (Ba  (None, 44, 64, 11)       44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_292 (Conv2D)         (None, 44, 64, 2)         662       \n",
            "                                                                 \n",
            " max_pooling2d_292 (MaxPooli  (None, 22, 64, 2)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_292 (Ba  (None, 22, 64, 2)        8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_293 (Conv2D)         (None, 22, 64, 14)        406       \n",
            "                                                                 \n",
            " max_pooling2d_293 (MaxPooli  (None, 11, 32, 14)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_293 (Ba  (None, 11, 32, 14)       56        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_294 (Conv2D)         (None, 11, 32, 62)        13082     \n",
            "                                                                 \n",
            " max_pooling2d_294 (MaxPooli  (None, 11, 32, 62)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_294 (Ba  (None, 11, 32, 62)       248       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_98 (Flatten)        (None, 21824)             0         \n",
            "                                                                 \n",
            " dense_298 (Dense)           (None, 40)                873000    \n",
            "                                                                 \n",
            " dropout_200 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_299 (Dense)           (None, 23)                943       \n",
            "                                                                 \n",
            " dropout_201 (Dropout)       (None, 23)                0         \n",
            "                                                                 \n",
            " dense_300 (Dense)           (None, 3)                 72        \n",
            "                                                                 \n",
            " dropout_202 (Dropout)       (None, 3)                 0         \n",
            "                                                                 \n",
            " dense_301 (Dense)           (None, 5)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 888,717\n",
            "Trainable params: 888,539\n",
            "Non-trainable params: 178\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.6621 - accuracy: 0.1106 - val_loss: 0.6195 - val_accuracy: 0.1506\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5943 - accuracy: 0.1181 - val_loss: 0.5605 - val_accuracy: 0.1084\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.5443 - accuracy: 0.1644 - val_loss: 0.4971 - val_accuracy: 0.2064\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4893 - accuracy: 0.2215 - val_loss: 0.4682 - val_accuracy: 0.2266\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4549 - accuracy: 0.2676 - val_loss: 0.4369 - val_accuracy: 0.2562\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4348 - accuracy: 0.3039 - val_loss: 0.4147 - val_accuracy: 0.2601\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4222 - accuracy: 0.3024 - val_loss: 0.4110 - val_accuracy: 0.2608\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4083 - accuracy: 0.2864 - val_loss: 0.3992 - val_accuracy: 0.2530\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.4016 - accuracy: 0.2754 - val_loss: 0.4002 - val_accuracy: 0.2384\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3947 - accuracy: 0.2663 - val_loss: 0.3881 - val_accuracy: 0.2603\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3838 - accuracy: 0.2686 - val_loss: 0.4326 - val_accuracy: 0.2710\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3751 - accuracy: 0.2833 - val_loss: 0.3660 - val_accuracy: 0.2743\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3656 - accuracy: 0.2956 - val_loss: 0.3676 - val_accuracy: 0.2503\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3556 - accuracy: 0.3121 - val_loss: 0.3833 - val_accuracy: 0.3200\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3403 - accuracy: 0.3572 - val_loss: 0.3357 - val_accuracy: 0.3080\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.3357 - accuracy: 0.3080\n",
            "sklearn_accuracy: 0.3126875\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 26, 6, 4, 2, 2, 41, 6, 3, 2, 1, 8, 4, 3, 1, 2, 32, 3, 7, 2, 2, 62, 5, 4, 2, 2, 1, 60, 0.06, 31, 0.36, 22, 0.49]\n",
            "Model: \"sequential_99\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_295 (Conv2D)         (None, 87, 128, 26)       650       \n",
            "                                                                 \n",
            " max_pooling2d_295 (MaxPooli  (None, 44, 64, 26)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_295 (Ba  (None, 44, 64, 26)       104       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_99 (Flatten)        (None, 73216)             0         \n",
            "                                                                 \n",
            " dense_302 (Dense)           (None, 60)                4393020   \n",
            "                                                                 \n",
            " dropout_203 (Dropout)       (None, 60)                0         \n",
            "                                                                 \n",
            " dense_303 (Dense)           (None, 5)                 305       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,394,079\n",
            "Trainable params: 4,394,027\n",
            "Non-trainable params: 52\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 11s 14ms/step - loss: 0.5076 - accuracy: 0.2450 - val_loss: 0.3757 - val_accuracy: 0.2582\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.3162 - accuracy: 0.2722 - val_loss: 0.2664 - val_accuracy: 0.2646\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.2195 - accuracy: 0.2774 - val_loss: 0.3137 - val_accuracy: 0.2683\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1694 - accuracy: 0.3001 - val_loss: 0.2857 - val_accuracy: 0.2736\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1458 - accuracy: 0.3205 - val_loss: 0.2484 - val_accuracy: 0.3536\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1338 - accuracy: 0.3295 - val_loss: 0.2925 - val_accuracy: 0.2791\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1304 - accuracy: 0.3354 - val_loss: 0.2792 - val_accuracy: 0.3496\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1271 - accuracy: 0.3398 - val_loss: 0.2696 - val_accuracy: 0.3088\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1249 - accuracy: 0.3359 - val_loss: 0.2660 - val_accuracy: 0.3287\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1241 - accuracy: 0.3353 - val_loss: 0.3253 - val_accuracy: 0.3434\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1215 - accuracy: 0.3516 - val_loss: 0.3522 - val_accuracy: 0.3594\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1223 - accuracy: 0.3519 - val_loss: 0.3503 - val_accuracy: 0.3523\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1177 - accuracy: 0.3536 - val_loss: 0.3709 - val_accuracy: 0.3894\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1201 - accuracy: 0.3576 - val_loss: 0.2791 - val_accuracy: 0.3587\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 9s 12ms/step - loss: 0.1171 - accuracy: 0.3555 - val_loss: 0.4689 - val_accuracy: 0.3288\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.4689 - accuracy: 0.3288\n",
            "sklearn_accuracy: 0.533125\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 20, 3, 7, 2, 2, 20, 7, 6, 2, 1, 36, 3, 4, 1, 1, 45, 7, 2, 1, 2, 51, 4, 3, 2, 1, 3, 4, 0.25, 53, 0.3, 33, 0.06]\n",
            "Model: \"sequential_100\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_296 (Conv2D)         (None, 87, 128, 20)       440       \n",
            "                                                                 \n",
            " max_pooling2d_296 (MaxPooli  (None, 44, 64, 20)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_296 (Ba  (None, 44, 64, 20)       80        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_297 (Conv2D)         (None, 44, 64, 20)        16820     \n",
            "                                                                 \n",
            " max_pooling2d_297 (MaxPooli  (None, 22, 64, 20)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_297 (Ba  (None, 22, 64, 20)       80        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_100 (Flatten)       (None, 28160)             0         \n",
            "                                                                 \n",
            " dense_304 (Dense)           (None, 4)                 112644    \n",
            "                                                                 \n",
            " dropout_204 (Dropout)       (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_305 (Dense)           (None, 53)                265       \n",
            "                                                                 \n",
            " dropout_205 (Dropout)       (None, 53)                0         \n",
            "                                                                 \n",
            " dense_306 (Dense)           (None, 33)                1782      \n",
            "                                                                 \n",
            " dropout_206 (Dropout)       (None, 33)                0         \n",
            "                                                                 \n",
            " dense_307 (Dense)           (None, 5)                 170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 132,281\n",
            "Trainable params: 132,201\n",
            "Non-trainable params: 80\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 15s 19ms/step - loss: 0.6932 - accuracy: 0.1912 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1530 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1591 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.3417 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1800 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1489 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2548 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1217 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.0927 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2636 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1181 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2722 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.3156 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.1337 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 13s 17ms/step - loss: 0.6932 - accuracy: 0.2383 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.2500\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 2, 5, 6, 2, 1, 33, 4, 2, 2, 2, 63, 7, 7, 2, 1, 58, 6, 5, 1, 2, 57, 2, 4, 2, 1, 3, 6, 0.03, 50, 0.02, 62, 0.33]\n",
            "Model: \"sequential_101\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_298 (Conv2D)         (None, 87, 128, 2)        62        \n",
            "                                                                 \n",
            " max_pooling2d_298 (MaxPooli  (None, 44, 128, 2)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_298 (Ba  (None, 44, 128, 2)       8         \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_299 (Conv2D)         (None, 44, 128, 33)       561       \n",
            "                                                                 \n",
            " max_pooling2d_299 (MaxPooli  (None, 22, 64, 33)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_299 (Ba  (None, 22, 64, 33)       132       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_101 (Flatten)       (None, 46464)             0         \n",
            "                                                                 \n",
            " dense_308 (Dense)           (None, 6)                 278790    \n",
            "                                                                 \n",
            " dropout_207 (Dropout)       (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_309 (Dense)           (None, 50)                350       \n",
            "                                                                 \n",
            " dropout_208 (Dropout)       (None, 50)                0         \n",
            "                                                                 \n",
            " dense_310 (Dense)           (None, 62)                3162      \n",
            "                                                                 \n",
            " dropout_209 (Dropout)       (None, 62)                0         \n",
            "                                                                 \n",
            " dense_311 (Dense)           (None, 5)                 315       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 283,380\n",
            "Trainable params: 283,310\n",
            "Non-trainable params: 70\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 11s 13ms/step - loss: 0.6937 - accuracy: 0.2015 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.2392 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.2506 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.1900 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.2571 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.2322 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.2131 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.2626 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.1685 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.1877 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.2775 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.2111 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.1608 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.1892 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 8s 11ms/step - loss: 0.6932 - accuracy: 0.1785 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.6932 - accuracy: 0.0312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 8, 7, 2, 1, 1, 32, 6, 5, 2, 1, 64, 2, 2, 2, 2, 60, 7, 5, 2, 2, 38, 5, 3, 1, 2, 3, 22, 0.13, 39, 0.35, 11, 0.06]\n",
            "Model: \"sequential_102\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_300 (Conv2D)         (None, 87, 128, 8)        120       \n",
            "                                                                 \n",
            " max_pooling2d_300 (MaxPooli  (None, 87, 128, 8)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_300 (Ba  (None, 87, 128, 8)       32        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_301 (Conv2D)         (None, 87, 128, 32)       7712      \n",
            "                                                                 \n",
            " max_pooling2d_301 (MaxPooli  (None, 44, 128, 32)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_301 (Ba  (None, 44, 128, 32)      128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_302 (Conv2D)         (None, 44, 128, 64)       8256      \n",
            "                                                                 \n",
            " max_pooling2d_302 (MaxPooli  (None, 22, 64, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_302 (Ba  (None, 22, 64, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_303 (Conv2D)         (None, 22, 64, 60)        134460    \n",
            "                                                                 \n",
            " max_pooling2d_303 (MaxPooli  (None, 11, 32, 60)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_303 (Ba  (None, 11, 32, 60)       240       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_304 (Conv2D)         (None, 11, 32, 38)        34238     \n",
            "                                                                 \n",
            " max_pooling2d_304 (MaxPooli  (None, 11, 16, 38)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_304 (Ba  (None, 11, 16, 38)       152       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_102 (Flatten)       (None, 6688)              0         \n",
            "                                                                 \n",
            " dense_312 (Dense)           (None, 22)                147158    \n",
            "                                                                 \n",
            " dropout_210 (Dropout)       (None, 22)                0         \n",
            "                                                                 \n",
            " dense_313 (Dense)           (None, 39)                897       \n",
            "                                                                 \n",
            " dropout_211 (Dropout)       (None, 39)                0         \n",
            "                                                                 \n",
            " dense_314 (Dense)           (None, 11)                440       \n",
            "                                                                 \n",
            " dropout_212 (Dropout)       (None, 11)                0         \n",
            "                                                                 \n",
            " dense_315 (Dense)           (None, 5)                 60        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 334,149\n",
            "Trainable params: 333,745\n",
            "Non-trainable params: 404\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 51s 65ms/step - loss: 0.4915 - accuracy: 0.2230 - val_loss: 0.4335 - val_accuracy: 0.2864\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.3569 - accuracy: 0.3130 - val_loss: 0.3342 - val_accuracy: 0.2504\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.3319 - accuracy: 0.3509 - val_loss: 0.3522 - val_accuracy: 0.2882\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.3241 - accuracy: 0.3657 - val_loss: 0.3392 - val_accuracy: 0.3163\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.3182 - accuracy: 0.3695 - val_loss: 0.3127 - val_accuracy: 0.3441\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.3128 - accuracy: 0.3807 - val_loss: 0.4388 - val_accuracy: 0.4130\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.3091 - accuracy: 0.3802 - val_loss: 0.3044 - val_accuracy: 0.3819\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.3075 - accuracy: 0.3995 - val_loss: 0.3829 - val_accuracy: 0.2649\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.3022 - accuracy: 0.3984 - val_loss: 0.3293 - val_accuracy: 0.4951\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.2850 - accuracy: 0.4146 - val_loss: 0.3061 - val_accuracy: 0.3226\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 46s 62ms/step - loss: 0.2590 - accuracy: 0.4155 - val_loss: 0.2207 - val_accuracy: 0.4387\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 46s 62ms/step - loss: 0.2366 - accuracy: 0.4289 - val_loss: 0.2290 - val_accuracy: 0.4432\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 46s 62ms/step - loss: 0.2215 - accuracy: 0.4276 - val_loss: 0.2308 - val_accuracy: 0.3501\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 46s 62ms/step - loss: 0.2072 - accuracy: 0.4621 - val_loss: 0.3161 - val_accuracy: 0.3776\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 46s 62ms/step - loss: 0.1979 - accuracy: 0.4856 - val_loss: 0.3503 - val_accuracy: 0.5269\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.3503 - accuracy: 0.5269\n",
            "sklearn_accuracy: 0.484875\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 54, 4, 5, 2, 1, 50, 2, 4, 1, 1, 58, 4, 4, 1, 2, 24, 3, 5, 2, 2, 13, 4, 3, 2, 2, 2, 63, 0.19, 41, 0.49, 16, 0.29]\n",
            "Model: \"sequential_103\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_305 (Conv2D)         (None, 87, 128, 54)       1134      \n",
            "                                                                 \n",
            " max_pooling2d_305 (MaxPooli  (None, 44, 128, 54)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_305 (Ba  (None, 44, 128, 54)      216       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_306 (Conv2D)         (None, 44, 128, 50)       21650     \n",
            "                                                                 \n",
            " max_pooling2d_306 (MaxPooli  (None, 44, 128, 50)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_306 (Ba  (None, 44, 128, 50)      200       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_307 (Conv2D)         (None, 44, 128, 58)       46458     \n",
            "                                                                 \n",
            " max_pooling2d_307 (MaxPooli  (None, 44, 64, 58)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_307 (Ba  (None, 44, 64, 58)       232       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_308 (Conv2D)         (None, 44, 64, 24)        20904     \n",
            "                                                                 \n",
            " max_pooling2d_308 (MaxPooli  (None, 22, 32, 24)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_308 (Ba  (None, 22, 32, 24)       96        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_103 (Flatten)       (None, 16896)             0         \n",
            "                                                                 \n",
            " dense_316 (Dense)           (None, 63)                1064511   \n",
            "                                                                 \n",
            " dropout_213 (Dropout)       (None, 63)                0         \n",
            "                                                                 \n",
            " dense_317 (Dense)           (None, 41)                2624      \n",
            "                                                                 \n",
            " dropout_214 (Dropout)       (None, 41)                0         \n",
            "                                                                 \n",
            " dense_318 (Dense)           (None, 5)                 210       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,158,235\n",
            "Trainable params: 1,157,863\n",
            "Non-trainable params: 372\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 82s 105ms/step - loss: 0.6357 - accuracy: 0.1039 - val_loss: 0.9076 - val_accuracy: 0.0997\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 77s 103ms/step - loss: 0.5695 - accuracy: 0.1152 - val_loss: 0.5248 - val_accuracy: 0.1170\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 77s 103ms/step - loss: 0.5382 - accuracy: 0.1116 - val_loss: 0.5795 - val_accuracy: 0.0959\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 77s 103ms/step - loss: 0.5087 - accuracy: 0.1272 - val_loss: 0.6465 - val_accuracy: 0.0813\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 77s 103ms/step - loss: 0.4941 - accuracy: 0.1313 - val_loss: 0.4689 - val_accuracy: 0.1314\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 77s 102ms/step - loss: 0.4885 - accuracy: 0.1338 - val_loss: 0.4533 - val_accuracy: 0.1029\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 77s 103ms/step - loss: 0.4837 - accuracy: 0.1375 - val_loss: 0.4682 - val_accuracy: 0.1542\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 77s 103ms/step - loss: 0.4662 - accuracy: 0.1386 - val_loss: 0.4882 - val_accuracy: 0.1967\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 77s 103ms/step - loss: 0.4596 - accuracy: 0.1413 - val_loss: 0.5107 - val_accuracy: 0.1298\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 77s 103ms/step - loss: 0.4516 - accuracy: 0.1450 - val_loss: 0.5410 - val_accuracy: 0.2062\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 77s 103ms/step - loss: 0.4423 - accuracy: 0.1587 - val_loss: 0.5221 - val_accuracy: 0.1539\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 77s 102ms/step - loss: 0.4278 - accuracy: 0.1900 - val_loss: 0.4258 - val_accuracy: 0.2158\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 77s 102ms/step - loss: 0.3951 - accuracy: 0.2084 - val_loss: 0.3950 - val_accuracy: 0.2483\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 77s 103ms/step - loss: 0.3542 - accuracy: 0.2259 - val_loss: 0.3287 - val_accuracy: 0.2077\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 77s 103ms/step - loss: 0.3140 - accuracy: 0.2462 - val_loss: 0.2859 - val_accuracy: 0.2464\n",
            "500/500 [==============================] - 7s 14ms/step - loss: 0.2859 - accuracy: 0.2464\n",
            "sklearn_accuracy: 0.3803125\n",
            "(87.5 % )\n",
            "Creating individual 1 out of 8\n",
            "- working on # of filters' of conv layers  (index: 1, 6, 11, 16, 21)\n",
            "- working on x and y kernel dimensions     (index: 2, 3, 7, 8, 12, 13, 17, 18, 22, 23)\n",
            "- working on x and y MaxPooling size       (index: 4, 5, 9, 10, 14, 15, 19, 20, 24, 25)\n",
            "- working # of neurons in dense layers     (index: 27, 29, 31)\n",
            "- working dropout prob. after dense layers (index: 28, 30, 32)\n",
            "[4, 23, 3, 2, 2, 2, 15, 5, 6, 1, 2, 7, 6, 7, 2, 1, 6, 5, 2, 2, 2, 18, 3, 4, 1, 2, 1, 3, 0.29, 27, 0.29, 61, 0.14]\n",
            "\n",
            "Creating individual 2 out of 8\n",
            "[4, 37, 2, 7, 2, 1, 16, 4, 4, 1, 1, 55, 7, 6, 2, 1, 42, 2, 5, 2, 2, 62, 4, 5, 1, 2, 1, 47, 0.35, 4, 0.28, 22, 0.21]\n",
            "\n",
            "Creating individual 3 out of 8\n",
            "[2, 35, 5, 7, 1, 2, 6, 6, 3, 1, 1, 21, 2, 7, 2, 1, 25, 4, 5, 2, 2, 26, 6, 4, 1, 1, 2, 46, 0.14, 35, 0.11, 24, 0.21]\n",
            "\n",
            "Creating individual 4 out of 8\n",
            "[1, 57, 7, 4, 2, 1, 14, 6, 2, 1, 2, 18, 4, 5, 2, 1, 40, 4, 6, 1, 2, 59, 4, 7, 1, 1, 1, 51, 0.16, 51, 0.36, 13, 0.36]\n",
            "\n",
            "Creating individual 5 out of 8\n",
            "[3, 62, 2, 2, 2, 2, 15, 7, 2, 2, 1, 52, 3, 2, 1, 1, 29, 3, 6, 2, 2, 51, 4, 6, 2, 1, 1, 18, 0.16, 21, 0.29, 50, 0.5]\n",
            "\n",
            "Creating individual 6 out of 8\n",
            "[5, 48, 5, 4, 2, 2, 54, 7, 4, 2, 1, 64, 5, 5, 1, 2, 11, 4, 5, 1, 2, 34, 4, 5, 1, 1, 3, 32, 0.19, 9, 0.34, 60, 0.07]\n",
            "\n",
            "Creating individual 7 out of 8\n",
            "[1, 61, 5, 5, 2, 2, 48, 5, 6, 2, 1, 54, 3, 3, 2, 2, 22, 3, 4, 2, 1, 9, 2, 3, 2, 1, 1, 42, 0.04, 36, 0.06, 29, 0.16]\n",
            "\n",
            "Creating individual 8 out of 8\n",
            "[4, 17, 2, 2, 1, 2, 26, 5, 7, 1, 1, 64, 7, 4, 2, 2, 3, 5, 7, 2, 2, 60, 2, 6, 1, 2, 2, 15, 0.24, 31, 0.11, 21, 0.04]\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 23, 3, 2, 2, 2, 15, 5, 6, 1, 2, 7, 6, 7, 2, 1, 6, 5, 2, 2, 2, 18, 3, 4, 1, 2, 1, 3, 0.29, 27, 0.29, 61, 0.14]\n",
            "Model: \"sequential_104\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_309 (Conv2D)         (None, 87, 128, 23)       161       \n",
            "                                                                 \n",
            " max_pooling2d_309 (MaxPooli  (None, 44, 64, 23)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_309 (Ba  (None, 44, 64, 23)       92        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_310 (Conv2D)         (None, 44, 64, 15)        10365     \n",
            "                                                                 \n",
            " max_pooling2d_310 (MaxPooli  (None, 44, 32, 15)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_310 (Ba  (None, 44, 32, 15)       60        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_311 (Conv2D)         (None, 44, 32, 7)         4417      \n",
            "                                                                 \n",
            " max_pooling2d_311 (MaxPooli  (None, 22, 32, 7)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_311 (Ba  (None, 22, 32, 7)        28        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_312 (Conv2D)         (None, 22, 32, 6)         426       \n",
            "                                                                 \n",
            " max_pooling2d_312 (MaxPooli  (None, 11, 16, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_312 (Ba  (None, 11, 16, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_104 (Flatten)       (None, 1056)              0         \n",
            "                                                                 \n",
            " dense_319 (Dense)           (None, 3)                 3171      \n",
            "                                                                 \n",
            " dropout_215 (Dropout)       (None, 3)                 0         \n",
            "                                                                 \n",
            " dense_320 (Dense)           (None, 5)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,764\n",
            "Trainable params: 18,662\n",
            "Non-trainable params: 102\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 17s 22ms/step - loss: 0.6651 - accuracy: 0.1628 - val_loss: 0.6143 - val_accuracy: 0.0948\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.6081 - accuracy: 0.1001 - val_loss: 0.5728 - val_accuracy: 0.0993\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5753 - accuracy: 0.1350 - val_loss: 0.5340 - val_accuracy: 0.1605\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5514 - accuracy: 0.1878 - val_loss: 0.5021 - val_accuracy: 0.1585\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5292 - accuracy: 0.1684 - val_loss: 0.5077 - val_accuracy: 0.1565\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5235 - accuracy: 0.1667 - val_loss: 0.4768 - val_accuracy: 0.1574\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5226 - accuracy: 0.1528 - val_loss: 0.5093 - val_accuracy: 0.1541\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5196 - accuracy: 0.1252 - val_loss: 0.4858 - val_accuracy: 0.1575\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5181 - accuracy: 0.1547 - val_loss: 0.5097 - val_accuracy: 0.0946\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5170 - accuracy: 0.1250 - val_loss: 0.4992 - val_accuracy: 0.1581\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5166 - accuracy: 0.1466 - val_loss: 0.4660 - val_accuracy: 0.1571\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5166 - accuracy: 0.1089 - val_loss: 0.4758 - val_accuracy: 0.0941\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5164 - accuracy: 0.1534 - val_loss: 0.4865 - val_accuracy: 0.0960\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5153 - accuracy: 0.1429 - val_loss: 0.4660 - val_accuracy: 0.1549\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 15s 20ms/step - loss: 0.5144 - accuracy: 0.1220 - val_loss: 0.4756 - val_accuracy: 0.1569\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.4756 - accuracy: 0.1569\n",
            "sklearn_accuracy: 0.145\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 37, 2, 7, 2, 1, 16, 4, 4, 1, 1, 55, 7, 6, 2, 1, 42, 2, 5, 2, 2, 62, 4, 5, 1, 2, 1, 47, 0.35, 4, 0.28, 22, 0.21]\n",
            "Model: \"sequential_105\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_313 (Conv2D)         (None, 87, 128, 37)       555       \n",
            "                                                                 \n",
            " max_pooling2d_313 (MaxPooli  (None, 44, 128, 37)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_313 (Ba  (None, 44, 128, 37)      148       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_314 (Conv2D)         (None, 44, 128, 16)       9488      \n",
            "                                                                 \n",
            " max_pooling2d_314 (MaxPooli  (None, 44, 128, 16)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_314 (Ba  (None, 44, 128, 16)      64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_315 (Conv2D)         (None, 44, 128, 55)       37015     \n",
            "                                                                 \n",
            " max_pooling2d_315 (MaxPooli  (None, 22, 128, 55)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_315 (Ba  (None, 22, 128, 55)      220       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_316 (Conv2D)         (None, 22, 128, 42)       23142     \n",
            "                                                                 \n",
            " max_pooling2d_316 (MaxPooli  (None, 11, 64, 42)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_316 (Ba  (None, 11, 64, 42)       168       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_105 (Flatten)       (None, 29568)             0         \n",
            "                                                                 \n",
            " dense_321 (Dense)           (None, 47)                1389743   \n",
            "                                                                 \n",
            " dropout_216 (Dropout)       (None, 47)                0         \n",
            "                                                                 \n",
            " dense_322 (Dense)           (None, 5)                 240       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,460,783\n",
            "Trainable params: 1,460,483\n",
            "Non-trainable params: 300\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 58s 74ms/step - loss: 0.6971 - accuracy: 0.1501 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 54s 71ms/step - loss: 0.6932 - accuracy: 0.3066 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 54s 71ms/step - loss: 0.6932 - accuracy: 0.1716 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 53s 71ms/step - loss: 0.6932 - accuracy: 0.2375 - val_loss: 0.6932 - val_accuracy: 0.2499\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 54s 71ms/step - loss: 0.6932 - accuracy: 0.2006 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 54s 71ms/step - loss: 0.6932 - accuracy: 0.1810 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 54s 72ms/step - loss: 0.6932 - accuracy: 0.1945 - val_loss: 0.6932 - val_accuracy: 0.2499\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 54s 71ms/step - loss: 0.6932 - accuracy: 0.2285 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 53s 71ms/step - loss: 0.6932 - accuracy: 0.2195 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 53s 71ms/step - loss: 0.6932 - accuracy: 0.1116 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 53s 71ms/step - loss: 0.6932 - accuracy: 0.0804 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 53s 71ms/step - loss: 0.6932 - accuracy: 0.1440 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 54s 71ms/step - loss: 0.6932 - accuracy: 0.2849 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 54s 71ms/step - loss: 0.6932 - accuracy: 0.3343 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 54s 71ms/step - loss: 0.6932 - accuracy: 0.1846 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 6s 11ms/step - loss: 0.6932 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.0311875\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 35, 5, 7, 1, 2, 6, 6, 3, 1, 1, 21, 2, 7, 2, 1, 25, 4, 5, 2, 2, 26, 6, 4, 1, 1, 2, 46, 0.14, 35, 0.11, 24, 0.21]\n",
            "Model: \"sequential_106\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_317 (Conv2D)         (None, 87, 128, 35)       1260      \n",
            "                                                                 \n",
            " max_pooling2d_317 (MaxPooli  (None, 87, 64, 35)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_317 (Ba  (None, 87, 64, 35)       140       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_318 (Conv2D)         (None, 87, 64, 6)         3786      \n",
            "                                                                 \n",
            " max_pooling2d_318 (MaxPooli  (None, 87, 64, 6)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_318 (Ba  (None, 87, 64, 6)        24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_106 (Flatten)       (None, 33408)             0         \n",
            "                                                                 \n",
            " dense_323 (Dense)           (None, 46)                1536814   \n",
            "                                                                 \n",
            " dropout_217 (Dropout)       (None, 46)                0         \n",
            "                                                                 \n",
            " dense_324 (Dense)           (None, 35)                1645      \n",
            "                                                                 \n",
            " dropout_218 (Dropout)       (None, 35)                0         \n",
            "                                                                 \n",
            " dense_325 (Dense)           (None, 5)                 180       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,543,849\n",
            "Trainable params: 1,543,767\n",
            "Non-trainable params: 82\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 29s 37ms/step - loss: 0.5664 - accuracy: 0.1870 - val_loss: 0.4007 - val_accuracy: 0.2216\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.4176 - accuracy: 0.2716 - val_loss: 0.3412 - val_accuracy: 0.3321\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3832 - accuracy: 0.2970 - val_loss: 0.4012 - val_accuracy: 0.2964\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3656 - accuracy: 0.3123 - val_loss: 0.3517 - val_accuracy: 0.3598\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3561 - accuracy: 0.3247 - val_loss: 0.3117 - val_accuracy: 0.3262\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3466 - accuracy: 0.3300 - val_loss: 0.3253 - val_accuracy: 0.3401\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3413 - accuracy: 0.3486 - val_loss: 0.2965 - val_accuracy: 0.3323\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3329 - accuracy: 0.3499 - val_loss: 0.3000 - val_accuracy: 0.3247\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3266 - accuracy: 0.3510 - val_loss: 0.2797 - val_accuracy: 0.3812\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3256 - accuracy: 0.3614 - val_loss: 0.3144 - val_accuracy: 0.3514\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3197 - accuracy: 0.3555 - val_loss: 0.2723 - val_accuracy: 0.3893\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3153 - accuracy: 0.3656 - val_loss: 0.2904 - val_accuracy: 0.2916\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3147 - accuracy: 0.3591 - val_loss: 0.2943 - val_accuracy: 0.3333\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3086 - accuracy: 0.3694 - val_loss: 0.2807 - val_accuracy: 0.3810\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.3061 - accuracy: 0.3615 - val_loss: 0.2866 - val_accuracy: 0.3882\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.2866 - accuracy: 0.3882\n",
            "sklearn_accuracy: 0.4495\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 57, 7, 4, 2, 1, 14, 6, 2, 1, 2, 18, 4, 5, 2, 1, 40, 4, 6, 1, 2, 59, 4, 7, 1, 1, 1, 51, 0.16, 51, 0.36, 13, 0.36]\n",
            "Model: \"sequential_107\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_319 (Conv2D)         (None, 87, 128, 57)       1653      \n",
            "                                                                 \n",
            " max_pooling2d_319 (MaxPooli  (None, 44, 128, 57)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_319 (Ba  (None, 44, 128, 57)      228       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_107 (Flatten)       (None, 321024)            0         \n",
            "                                                                 \n",
            " dense_326 (Dense)           (None, 51)                16372275  \n",
            "                                                                 \n",
            " dropout_219 (Dropout)       (None, 51)                0         \n",
            "                                                                 \n",
            " dense_327 (Dense)           (None, 5)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,374,416\n",
            "Trainable params: 16,374,302\n",
            "Non-trainable params: 114\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 23s 30ms/step - loss: 0.7517 - accuracy: 0.2454 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 21s 28ms/step - loss: 0.6932 - accuracy: 0.1707 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 21s 28ms/step - loss: 0.6932 - accuracy: 0.1747 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 21s 29ms/step - loss: 0.6932 - accuracy: 0.2647 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 21s 29ms/step - loss: 0.6932 - accuracy: 0.1047 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 21s 29ms/step - loss: 0.6932 - accuracy: 0.2772 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 21s 28ms/step - loss: 0.6932 - accuracy: 0.2596 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 21s 28ms/step - loss: 0.6932 - accuracy: 0.1083 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 21s 28ms/step - loss: 0.6932 - accuracy: 0.2298 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 21s 29ms/step - loss: 0.6932 - accuracy: 0.1568 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 21s 28ms/step - loss: 0.6932 - accuracy: 0.1128 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 21s 28ms/step - loss: 0.6932 - accuracy: 0.2916 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 21s 28ms/step - loss: 0.6932 - accuracy: 0.2111 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 21s 28ms/step - loss: 0.6932 - accuracy: 0.2075 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 21s 29ms/step - loss: 0.6932 - accuracy: 0.2835 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.6932 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 62, 2, 2, 2, 2, 15, 7, 2, 2, 1, 52, 3, 2, 1, 1, 29, 3, 6, 2, 2, 51, 4, 6, 2, 1, 1, 18, 0.16, 21, 0.29, 50, 0.5]\n",
            "Model: \"sequential_108\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_320 (Conv2D)         (None, 87, 128, 62)       310       \n",
            "                                                                 \n",
            " max_pooling2d_320 (MaxPooli  (None, 44, 64, 62)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_320 (Ba  (None, 44, 64, 62)       248       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_321 (Conv2D)         (None, 44, 64, 15)        13035     \n",
            "                                                                 \n",
            " max_pooling2d_321 (MaxPooli  (None, 22, 64, 15)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_321 (Ba  (None, 22, 64, 15)       60        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_322 (Conv2D)         (None, 22, 64, 52)        4732      \n",
            "                                                                 \n",
            " max_pooling2d_322 (MaxPooli  (None, 22, 64, 52)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_322 (Ba  (None, 22, 64, 52)       208       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_108 (Flatten)       (None, 73216)             0         \n",
            "                                                                 \n",
            " dense_328 (Dense)           (None, 18)                1317906   \n",
            "                                                                 \n",
            " dropout_220 (Dropout)       (None, 18)                0         \n",
            "                                                                 \n",
            " dense_329 (Dense)           (None, 5)                 95        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,336,594\n",
            "Trainable params: 1,336,336\n",
            "Non-trainable params: 258\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 30s 38ms/step - loss: 0.6981 - accuracy: 0.1497 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2126 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.1754 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.0935 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2514 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.1481 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.1251 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.1444 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.1096 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2084 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.1311 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.0684 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2593 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.6932 - accuracy: 0.2750 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 27s 37ms/step - loss: 0.6932 - accuracy: 0.2691 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6932 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 48, 5, 4, 2, 2, 54, 7, 4, 2, 1, 64, 5, 5, 1, 2, 11, 4, 5, 1, 2, 34, 4, 5, 1, 1, 3, 32, 0.19, 9, 0.34, 60, 0.07]\n",
            "Model: \"sequential_109\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_323 (Conv2D)         (None, 87, 128, 48)       1008      \n",
            "                                                                 \n",
            " max_pooling2d_323 (MaxPooli  (None, 44, 64, 48)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_323 (Ba  (None, 44, 64, 48)       192       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_324 (Conv2D)         (None, 44, 64, 54)        72630     \n",
            "                                                                 \n",
            " max_pooling2d_324 (MaxPooli  (None, 22, 64, 54)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_324 (Ba  (None, 22, 64, 54)       216       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_325 (Conv2D)         (None, 22, 64, 64)        86464     \n",
            "                                                                 \n",
            " max_pooling2d_325 (MaxPooli  (None, 22, 32, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_325 (Ba  (None, 22, 32, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_326 (Conv2D)         (None, 22, 32, 11)        14091     \n",
            "                                                                 \n",
            " max_pooling2d_326 (MaxPooli  (None, 22, 16, 11)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_326 (Ba  (None, 22, 16, 11)       44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_327 (Conv2D)         (None, 22, 16, 34)        7514      \n",
            "                                                                 \n",
            " max_pooling2d_327 (MaxPooli  (None, 22, 16, 34)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_327 (Ba  (None, 22, 16, 34)       136       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_109 (Flatten)       (None, 11968)             0         \n",
            "                                                                 \n",
            " dense_330 (Dense)           (None, 32)                383008    \n",
            "                                                                 \n",
            " dropout_221 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_331 (Dense)           (None, 9)                 297       \n",
            "                                                                 \n",
            " dropout_222 (Dropout)       (None, 9)                 0         \n",
            "                                                                 \n",
            " dense_332 (Dense)           (None, 60)                600       \n",
            "                                                                 \n",
            " dropout_223 (Dropout)       (None, 60)                0         \n",
            "                                                                 \n",
            " dense_333 (Dense)           (None, 5)                 305       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 566,761\n",
            "Trainable params: 566,339\n",
            "Non-trainable params: 422\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 42s 53ms/step - loss: 0.5861 - accuracy: 0.2584 - val_loss: 0.6203 - val_accuracy: 0.2911\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.5043 - accuracy: 0.3467 - val_loss: 0.4851 - val_accuracy: 0.3497\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.4667 - accuracy: 0.3777 - val_loss: 0.4423 - val_accuracy: 0.4582\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.4351 - accuracy: 0.3815 - val_loss: 0.4793 - val_accuracy: 0.5239\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.4082 - accuracy: 0.4116 - val_loss: 0.7950 - val_accuracy: 0.4954\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.3941 - accuracy: 0.4054 - val_loss: 0.4059 - val_accuracy: 0.3841\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.3828 - accuracy: 0.3808 - val_loss: 0.4548 - val_accuracy: 0.3701\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.3758 - accuracy: 0.4166 - val_loss: 0.3956 - val_accuracy: 0.4701\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.3712 - accuracy: 0.4230 - val_loss: 0.4889 - val_accuracy: 0.3771\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.3617 - accuracy: 0.4356 - val_loss: 0.3515 - val_accuracy: 0.4924\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.3614 - accuracy: 0.4287 - val_loss: 0.3804 - val_accuracy: 0.4812\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.3593 - accuracy: 0.4193 - val_loss: 0.3477 - val_accuracy: 0.4748\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.3545 - accuracy: 0.4115 - val_loss: 0.9517 - val_accuracy: 0.5839\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.3557 - accuracy: 0.4212 - val_loss: 0.3596 - val_accuracy: 0.4682\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 38s 51ms/step - loss: 0.3517 - accuracy: 0.4058 - val_loss: 0.4814 - val_accuracy: 0.4132\n",
            "500/500 [==============================] - 5s 8ms/step - loss: 0.4814 - accuracy: 0.4132\n",
            "sklearn_accuracy: 0.175875\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[1, 61, 5, 5, 2, 2, 48, 5, 6, 2, 1, 54, 3, 3, 2, 2, 22, 3, 4, 2, 1, 9, 2, 3, 2, 1, 1, 42, 0.04, 36, 0.06, 29, 0.16]\n",
            "Model: \"sequential_110\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_328 (Conv2D)         (None, 87, 128, 61)       1586      \n",
            "                                                                 \n",
            " max_pooling2d_328 (MaxPooli  (None, 44, 64, 61)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_328 (Ba  (None, 44, 64, 61)       244       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_110 (Flatten)       (None, 171776)            0         \n",
            "                                                                 \n",
            " dense_334 (Dense)           (None, 42)                7214634   \n",
            "                                                                 \n",
            " dropout_224 (Dropout)       (None, 42)                0         \n",
            "                                                                 \n",
            " dense_335 (Dense)           (None, 5)                 215       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,216,679\n",
            "Trainable params: 7,216,557\n",
            "Non-trainable params: 122\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 19s 25ms/step - loss: 0.7494 - accuracy: 0.1964 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2266 - val_loss: 0.6929 - val_accuracy: 0.5310\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6937 - accuracy: 0.1500 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2759 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2647 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.0754 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2952 - val_loss: 0.6931 - val_accuracy: 0.2499\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2141 - val_loss: 0.6931 - val_accuracy: 0.2499\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.1313 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2964 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.3380 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.1861 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2063 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2811 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 17s 23ms/step - loss: 0.6932 - accuracy: 0.2146 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 0.6931 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.0313125\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 17, 2, 2, 1, 2, 26, 5, 7, 1, 1, 64, 7, 4, 2, 2, 3, 5, 7, 2, 2, 60, 2, 6, 1, 2, 2, 15, 0.24, 31, 0.11, 21, 0.04]\n",
            "Model: \"sequential_111\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_329 (Conv2D)         (None, 87, 128, 17)       85        \n",
            "                                                                 \n",
            " max_pooling2d_329 (MaxPooli  (None, 87, 64, 17)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_329 (Ba  (None, 87, 64, 17)       68        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_330 (Conv2D)         (None, 87, 64, 26)        15496     \n",
            "                                                                 \n",
            " max_pooling2d_330 (MaxPooli  (None, 87, 64, 26)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_330 (Ba  (None, 87, 64, 26)       104       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_331 (Conv2D)         (None, 87, 64, 64)        46656     \n",
            "                                                                 \n",
            " max_pooling2d_331 (MaxPooli  (None, 44, 32, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_331 (Ba  (None, 44, 32, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_332 (Conv2D)         (None, 44, 32, 3)         6723      \n",
            "                                                                 \n",
            " max_pooling2d_332 (MaxPooli  (None, 22, 16, 3)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_332 (Ba  (None, 22, 16, 3)        12        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_111 (Flatten)       (None, 1056)              0         \n",
            "                                                                 \n",
            " dense_336 (Dense)           (None, 15)                15855     \n",
            "                                                                 \n",
            " dropout_225 (Dropout)       (None, 15)                0         \n",
            "                                                                 \n",
            " dense_337 (Dense)           (None, 31)                496       \n",
            "                                                                 \n",
            " dropout_226 (Dropout)       (None, 31)                0         \n",
            "                                                                 \n",
            " dense_338 (Dense)           (None, 5)                 160       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,911\n",
            "Trainable params: 85,691\n",
            "Non-trainable params: 220\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 48s 63ms/step - loss: 0.4527 - accuracy: 0.2040 - val_loss: 0.1682 - val_accuracy: 0.3165\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.1870 - accuracy: 0.4676 - val_loss: 0.0971 - val_accuracy: 0.4836\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.1241 - accuracy: 0.5713 - val_loss: 0.0857 - val_accuracy: 0.6651\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.1020 - accuracy: 0.5978 - val_loss: 0.0796 - val_accuracy: 0.6664\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.0905 - accuracy: 0.6055 - val_loss: 0.0985 - val_accuracy: 0.6406\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.0802 - accuracy: 0.6102 - val_loss: 0.0579 - val_accuracy: 0.5778\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.0775 - accuracy: 0.6078 - val_loss: 0.2052 - val_accuracy: 0.6573\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.0736 - accuracy: 0.6133 - val_loss: 0.1152 - val_accuracy: 0.5885\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.0668 - accuracy: 0.6079 - val_loss: 0.1616 - val_accuracy: 0.6008\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.0659 - accuracy: 0.6051 - val_loss: 0.0961 - val_accuracy: 0.6758\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.0628 - accuracy: 0.6024 - val_loss: 0.0893 - val_accuracy: 0.6507\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.0622 - accuracy: 0.5779 - val_loss: 0.1241 - val_accuracy: 0.6654\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.0591 - accuracy: 0.5733 - val_loss: 0.0918 - val_accuracy: 0.6532\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.0574 - accuracy: 0.5596 - val_loss: 0.0675 - val_accuracy: 0.6086\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.0563 - accuracy: 0.5663 - val_loss: 0.1465 - val_accuracy: 0.4792\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.1465 - accuracy: 0.4792\n",
            "sklearn_accuracy: 0.85925\n",
            "(93.75 % )\n",
            "Creating individual 1 out of 8\n",
            "- working on # of filters' of conv layers  (index: 1, 6, 11, 16, 21)\n",
            "- working on x and y kernel dimensions     (index: 2, 3, 7, 8, 12, 13, 17, 18, 22, 23)\n",
            "- working on x and y MaxPooling size       (index: 4, 5, 9, 10, 14, 15, 19, 20, 24, 25)\n",
            "- working # of neurons in dense layers     (index: 27, 29, 31)\n",
            "- working dropout prob. after dense layers (index: 28, 30, 32)\n",
            "[2, 9, 5, 2, 1, 2, 60, 6, 2, 2, 2, 2, 6, 5, 1, 2, 19, 7, 3, 1, 1, 39, 2, 2, 1, 1, 3, 53, 0.32, 28, 0.46, 3, 0.43]\n",
            "\n",
            "Creating individual 2 out of 8\n",
            "[2, 13, 7, 6, 2, 2, 20, 3, 7, 1, 2, 62, 4, 2, 1, 2, 59, 2, 3, 1, 1, 38, 6, 3, 1, 2, 2, 61, 0.02, 28, 0.45, 53, 0.31]\n",
            "\n",
            "Creating individual 3 out of 8\n",
            "[2, 28, 7, 2, 1, 1, 47, 6, 4, 2, 2, 31, 4, 6, 1, 1, 22, 3, 2, 1, 2, 64, 3, 4, 2, 1, 1, 13, 0.4, 19, 0.37, 28, 0.4]\n",
            "\n",
            "Creating individual 4 out of 8\n",
            "[3, 57, 5, 6, 2, 1, 32, 5, 5, 1, 2, 52, 7, 3, 2, 2, 50, 3, 6, 2, 1, 33, 3, 4, 2, 2, 1, 40, 0.29, 19, 0.38, 34, 0.01]\n",
            "\n",
            "Creating individual 5 out of 8\n",
            "[2, 23, 5, 4, 2, 1, 53, 6, 7, 2, 1, 49, 2, 5, 1, 1, 49, 6, 7, 1, 1, 4, 3, 7, 2, 2, 1, 51, 0.01, 44, 0.01, 18, 0.18]\n",
            "\n",
            "Creating individual 6 out of 8\n",
            "[3, 5, 6, 7, 2, 2, 45, 5, 6, 1, 2, 57, 7, 3, 1, 2, 29, 5, 2, 1, 1, 48, 2, 4, 2, 1, 3, 30, 0.07, 26, 0.21, 57, 0.47]\n",
            "\n",
            "Creating individual 7 out of 8\n",
            "[4, 28, 3, 5, 1, 1, 61, 4, 3, 1, 1, 63, 4, 6, 1, 1, 39, 5, 5, 2, 2, 63, 4, 2, 1, 1, 1, 61, 0.45, 20, 0.17, 22, 0.49]\n",
            "\n",
            "Creating individual 8 out of 8\n",
            "[4, 53, 6, 3, 1, 2, 35, 2, 2, 2, 2, 11, 3, 2, 1, 2, 7, 3, 6, 2, 2, 50, 5, 5, 2, 2, 2, 24, 0.39, 38, 0.16, 23, 0.07]\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 9, 5, 2, 1, 2, 60, 6, 2, 2, 2, 2, 6, 5, 1, 2, 19, 7, 3, 1, 1, 39, 2, 2, 1, 1, 3, 53, 0.32, 28, 0.46, 3, 0.43]\n",
            "Model: \"sequential_112\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_333 (Conv2D)         (None, 87, 128, 9)        99        \n",
            "                                                                 \n",
            " max_pooling2d_333 (MaxPooli  (None, 87, 64, 9)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_333 (Ba  (None, 87, 64, 9)        36        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_334 (Conv2D)         (None, 87, 64, 60)        6540      \n",
            "                                                                 \n",
            " max_pooling2d_334 (MaxPooli  (None, 44, 32, 60)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_334 (Ba  (None, 44, 32, 60)       240       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_112 (Flatten)       (None, 84480)             0         \n",
            "                                                                 \n",
            " dense_339 (Dense)           (None, 53)                4477493   \n",
            "                                                                 \n",
            " dropout_227 (Dropout)       (None, 53)                0         \n",
            "                                                                 \n",
            " dense_340 (Dense)           (None, 28)                1512      \n",
            "                                                                 \n",
            " dropout_228 (Dropout)       (None, 28)                0         \n",
            "                                                                 \n",
            " dense_341 (Dense)           (None, 3)                 87        \n",
            "                                                                 \n",
            " dropout_229 (Dropout)       (None, 3)                 0         \n",
            "                                                                 \n",
            " dense_342 (Dense)           (None, 5)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,486,027\n",
            "Trainable params: 4,485,889\n",
            "Non-trainable params: 138\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 18s 23ms/step - loss: 0.7029 - accuracy: 0.0970 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1445 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1411 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.3190 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.2168 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1862 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.2166 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1785 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.0735 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.2043 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.2050 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1774 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.1659 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.2367 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.6932 - accuracy: 0.2443 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.6932 - accuracy: 0.1250\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 13, 7, 6, 2, 2, 20, 3, 7, 1, 2, 62, 4, 2, 1, 2, 59, 2, 3, 1, 1, 38, 6, 3, 1, 2, 2, 61, 0.02, 28, 0.45, 53, 0.31]\n",
            "Model: \"sequential_113\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_335 (Conv2D)         (None, 87, 128, 13)       559       \n",
            "                                                                 \n",
            " max_pooling2d_335 (MaxPooli  (None, 44, 64, 13)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_335 (Ba  (None, 44, 64, 13)       52        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_336 (Conv2D)         (None, 44, 64, 20)        5480      \n",
            "                                                                 \n",
            " max_pooling2d_336 (MaxPooli  (None, 44, 32, 20)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_336 (Ba  (None, 44, 32, 20)       80        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_113 (Flatten)       (None, 28160)             0         \n",
            "                                                                 \n",
            " dense_343 (Dense)           (None, 61)                1717821   \n",
            "                                                                 \n",
            " dropout_230 (Dropout)       (None, 61)                0         \n",
            "                                                                 \n",
            " dense_344 (Dense)           (None, 28)                1736      \n",
            "                                                                 \n",
            " dropout_231 (Dropout)       (None, 28)                0         \n",
            "                                                                 \n",
            " dense_345 (Dense)           (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,725,873\n",
            "Trainable params: 1,725,807\n",
            "Non-trainable params: 66\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 12s 15ms/step - loss: 0.4238 - accuracy: 0.3064 - val_loss: 0.2686 - val_accuracy: 0.4558\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1985 - accuracy: 0.4572 - val_loss: 0.2355 - val_accuracy: 0.3830\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 10s 14ms/step - loss: 0.1442 - accuracy: 0.4876 - val_loss: 0.1455 - val_accuracy: 0.4822\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1280 - accuracy: 0.5167 - val_loss: 0.1925 - val_accuracy: 0.5133\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1242 - accuracy: 0.5168 - val_loss: 0.3192 - val_accuracy: 0.5210\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1137 - accuracy: 0.5285 - val_loss: 0.1280 - val_accuracy: 0.5299\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1102 - accuracy: 0.5369 - val_loss: 0.1388 - val_accuracy: 0.5460\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1036 - accuracy: 0.5377 - val_loss: 0.2534 - val_accuracy: 0.5107\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1055 - accuracy: 0.5395 - val_loss: 0.1827 - val_accuracy: 0.5240\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.1014 - accuracy: 0.5431 - val_loss: 0.1675 - val_accuracy: 0.5124\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0972 - accuracy: 0.5358 - val_loss: 0.2959 - val_accuracy: 0.5270\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0961 - accuracy: 0.5409 - val_loss: 0.2197 - val_accuracy: 0.5241\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0959 - accuracy: 0.5405 - val_loss: 0.1593 - val_accuracy: 0.5243\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0938 - accuracy: 0.5408 - val_loss: 0.1642 - val_accuracy: 0.5218\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 10s 13ms/step - loss: 0.0959 - accuracy: 0.5399 - val_loss: 0.2290 - val_accuracy: 0.5548\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 0.2290 - accuracy: 0.5548\n",
            "sklearn_accuracy: 0.709125\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 28, 7, 2, 1, 1, 47, 6, 4, 2, 2, 31, 4, 6, 1, 1, 22, 3, 2, 1, 2, 64, 3, 4, 2, 1, 1, 13, 0.4, 19, 0.37, 28, 0.4]\n",
            "Model: \"sequential_114\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_337 (Conv2D)         (None, 87, 128, 28)       420       \n",
            "                                                                 \n",
            " max_pooling2d_337 (MaxPooli  (None, 87, 128, 28)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_337 (Ba  (None, 87, 128, 28)      112       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_338 (Conv2D)         (None, 87, 128, 47)       31631     \n",
            "                                                                 \n",
            " max_pooling2d_338 (MaxPooli  (None, 44, 64, 47)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_338 (Ba  (None, 44, 64, 47)       188       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_114 (Flatten)       (None, 132352)            0         \n",
            "                                                                 \n",
            " dense_346 (Dense)           (None, 13)                1720589   \n",
            "                                                                 \n",
            " dropout_232 (Dropout)       (None, 13)                0         \n",
            "                                                                 \n",
            " dense_347 (Dense)           (None, 5)                 70        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,753,010\n",
            "Trainable params: 1,752,860\n",
            "Non-trainable params: 150\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 50s 65ms/step - loss: 0.7072 - accuracy: 0.2075 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 47s 63ms/step - loss: 0.6932 - accuracy: 0.1135 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.2075 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.2541 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.2512 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 47s 63ms/step - loss: 0.6932 - accuracy: 0.1858 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.2526 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.2441 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.2157 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.1928 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.2446 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.1405 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.1951 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.2371 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 47s 62ms/step - loss: 0.6932 - accuracy: 0.1149 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.6932 - accuracy: 0.0625\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 57, 5, 6, 2, 1, 32, 5, 5, 1, 2, 52, 7, 3, 2, 2, 50, 3, 6, 2, 1, 33, 3, 4, 2, 2, 1, 40, 0.29, 19, 0.38, 34, 0.01]\n",
            "Model: \"sequential_115\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_339 (Conv2D)         (None, 87, 128, 57)       1767      \n",
            "                                                                 \n",
            " max_pooling2d_339 (MaxPooli  (None, 44, 128, 57)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_339 (Ba  (None, 44, 128, 57)      228       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_340 (Conv2D)         (None, 44, 128, 32)       45632     \n",
            "                                                                 \n",
            " max_pooling2d_340 (MaxPooli  (None, 44, 64, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_340 (Ba  (None, 44, 64, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_341 (Conv2D)         (None, 44, 64, 52)        34996     \n",
            "                                                                 \n",
            " max_pooling2d_341 (MaxPooli  (None, 22, 32, 52)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_341 (Ba  (None, 22, 32, 52)       208       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_115 (Flatten)       (None, 36608)             0         \n",
            "                                                                 \n",
            " dense_348 (Dense)           (None, 40)                1464360   \n",
            "                                                                 \n",
            " dropout_233 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_349 (Dense)           (None, 5)                 205       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,547,524\n",
            "Trainable params: 1,547,242\n",
            "Non-trainable params: 282\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 46s 59ms/step - loss: 0.6687 - accuracy: 0.1129 - val_loss: 0.6185 - val_accuracy: 0.0922\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6289 - accuracy: 0.0979 - val_loss: 0.5946 - val_accuracy: 0.2064\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6242 - accuracy: 0.1034 - val_loss: 0.5886 - val_accuracy: 0.1548\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6231 - accuracy: 0.1039 - val_loss: 0.6171 - val_accuracy: 0.1321\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6205 - accuracy: 0.1104 - val_loss: 0.5767 - val_accuracy: 0.1321\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6155 - accuracy: 0.1166 - val_loss: 0.6220 - val_accuracy: 0.0866\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6169 - accuracy: 0.1130 - val_loss: 0.5763 - val_accuracy: 0.1959\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6117 - accuracy: 0.1140 - val_loss: 0.5660 - val_accuracy: 0.1231\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.6094 - accuracy: 0.1138 - val_loss: 0.5603 - val_accuracy: 0.2172\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.6102 - accuracy: 0.1164 - val_loss: 0.5656 - val_accuracy: 0.1057\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.6080 - accuracy: 0.1095 - val_loss: 0.5781 - val_accuracy: 0.0933\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.6065 - accuracy: 0.1078 - val_loss: 0.5608 - val_accuracy: 0.1290\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6068 - accuracy: 0.1043 - val_loss: 0.5604 - val_accuracy: 0.1249\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 43s 57ms/step - loss: 0.6063 - accuracy: 0.1023 - val_loss: 0.5615 - val_accuracy: 0.1294\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 42s 57ms/step - loss: 0.6068 - accuracy: 0.1099 - val_loss: 0.5576 - val_accuracy: 0.1006\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.5576 - accuracy: 0.1006\n",
            "sklearn_accuracy: 0.0915\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[2, 23, 5, 4, 2, 1, 53, 6, 7, 2, 1, 49, 2, 5, 1, 1, 49, 6, 7, 1, 1, 4, 3, 7, 2, 2, 1, 51, 0.01, 44, 0.01, 18, 0.18]\n",
            "Model: \"sequential_116\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_342 (Conv2D)         (None, 87, 128, 23)       483       \n",
            "                                                                 \n",
            " max_pooling2d_342 (MaxPooli  (None, 44, 128, 23)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_342 (Ba  (None, 44, 128, 23)      92        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_343 (Conv2D)         (None, 44, 128, 53)       51251     \n",
            "                                                                 \n",
            " max_pooling2d_343 (MaxPooli  (None, 22, 128, 53)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_343 (Ba  (None, 22, 128, 53)      212       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_116 (Flatten)       (None, 149248)            0         \n",
            "                                                                 \n",
            " dense_350 (Dense)           (None, 51)                7611699   \n",
            "                                                                 \n",
            " dropout_234 (Dropout)       (None, 51)                0         \n",
            "                                                                 \n",
            " dense_351 (Dense)           (None, 5)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,663,997\n",
            "Trainable params: 7,663,845\n",
            "Non-trainable params: 152\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 33s 42ms/step - loss: 0.7387 - accuracy: 0.2007 - val_loss: 0.6277 - val_accuracy: 0.0915\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.6067 - accuracy: 0.1245 - val_loss: 0.5902 - val_accuracy: 0.0936\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.5868 - accuracy: 0.1343 - val_loss: 0.5982 - val_accuracy: 0.1606\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.5815 - accuracy: 0.1381 - val_loss: 0.6491 - val_accuracy: 0.0985\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.5706 - accuracy: 0.1420 - val_loss: 0.5629 - val_accuracy: 0.1854\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.5639 - accuracy: 0.1500 - val_loss: 0.5607 - val_accuracy: 0.0936\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.5602 - accuracy: 0.1492 - val_loss: 0.5732 - val_accuracy: 0.1790\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 31s 42ms/step - loss: 0.5572 - accuracy: 0.1534 - val_loss: 0.5793 - val_accuracy: 0.0908\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.5542 - accuracy: 0.1454 - val_loss: 0.5660 - val_accuracy: 0.2437\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.5520 - accuracy: 0.1377 - val_loss: 0.5631 - val_accuracy: 0.0904\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.5484 - accuracy: 0.1430 - val_loss: 0.5584 - val_accuracy: 0.1107\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.5445 - accuracy: 0.1369 - val_loss: 0.5575 - val_accuracy: 0.1064\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.5435 - accuracy: 0.1304 - val_loss: 0.5634 - val_accuracy: 0.1423\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.5416 - accuracy: 0.1322 - val_loss: 0.5587 - val_accuracy: 0.1173\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 31s 41ms/step - loss: 0.5409 - accuracy: 0.1309 - val_loss: 0.5628 - val_accuracy: 0.2298\n",
            "500/500 [==============================] - 4s 6ms/step - loss: 0.5628 - accuracy: 0.2298\n",
            "sklearn_accuracy: 0.0835625\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 5, 6, 7, 2, 2, 45, 5, 6, 1, 2, 57, 7, 3, 1, 2, 29, 5, 2, 1, 1, 48, 2, 4, 2, 1, 3, 30, 0.07, 26, 0.21, 57, 0.47]\n",
            "Model: \"sequential_117\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_344 (Conv2D)         (None, 87, 128, 5)        215       \n",
            "                                                                 \n",
            " max_pooling2d_344 (MaxPooli  (None, 44, 64, 5)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_344 (Ba  (None, 44, 64, 5)        20        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_345 (Conv2D)         (None, 44, 64, 45)        6795      \n",
            "                                                                 \n",
            " max_pooling2d_345 (MaxPooli  (None, 44, 32, 45)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_345 (Ba  (None, 44, 32, 45)       180       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_346 (Conv2D)         (None, 44, 32, 57)        53922     \n",
            "                                                                 \n",
            " max_pooling2d_346 (MaxPooli  (None, 44, 16, 57)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_346 (Ba  (None, 44, 16, 57)       228       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_117 (Flatten)       (None, 40128)             0         \n",
            "                                                                 \n",
            " dense_352 (Dense)           (None, 30)                1203870   \n",
            "                                                                 \n",
            " dropout_235 (Dropout)       (None, 30)                0         \n",
            "                                                                 \n",
            " dense_353 (Dense)           (None, 26)                806       \n",
            "                                                                 \n",
            " dropout_236 (Dropout)       (None, 26)                0         \n",
            "                                                                 \n",
            " dense_354 (Dense)           (None, 57)                1539      \n",
            "                                                                 \n",
            " dropout_237 (Dropout)       (None, 57)                0         \n",
            "                                                                 \n",
            " dense_355 (Dense)           (None, 5)                 290       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,267,865\n",
            "Trainable params: 1,267,651\n",
            "Non-trainable params: 214\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 21s 26ms/step - loss: 0.6961 - accuracy: 0.2849 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.1914 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.2101 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.1980 - val_loss: 0.6931 - val_accuracy: 0.0626\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.2619 - val_loss: 0.6931 - val_accuracy: 0.0626\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.1645 - val_loss: 0.6931 - val_accuracy: 0.0626\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.2155 - val_loss: 0.6931 - val_accuracy: 0.0314\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.2226 - val_loss: 0.6931 - val_accuracy: 0.0626\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.2007 - val_loss: 0.6931 - val_accuracy: 0.0626\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.1797 - val_loss: 0.6931 - val_accuracy: 0.2498\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.1948 - val_loss: 0.6931 - val_accuracy: 0.0314\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.1789 - val_loss: 0.6931 - val_accuracy: 0.0314\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.1431 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.2436 - val_loss: 0.6931 - val_accuracy: 0.0626\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.6932 - accuracy: 0.2705 - val_loss: 0.6931 - val_accuracy: 0.0314\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 0.6931 - accuracy: 0.0314\n",
            "sklearn_accuracy: 0.031375\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 28, 3, 5, 1, 1, 61, 4, 3, 1, 1, 63, 4, 6, 1, 1, 39, 5, 5, 2, 2, 63, 4, 2, 1, 1, 1, 61, 0.45, 20, 0.17, 22, 0.49]\n",
            "Model: \"sequential_118\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_347 (Conv2D)         (None, 87, 128, 28)       448       \n",
            "                                                                 \n",
            " max_pooling2d_347 (MaxPooli  (None, 87, 128, 28)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_347 (Ba  (None, 87, 128, 28)      112       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_348 (Conv2D)         (None, 87, 128, 61)       20557     \n",
            "                                                                 \n",
            " max_pooling2d_348 (MaxPooli  (None, 87, 128, 61)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_348 (Ba  (None, 87, 128, 61)      244       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_349 (Conv2D)         (None, 87, 128, 63)       92295     \n",
            "                                                                 \n",
            " max_pooling2d_349 (MaxPooli  (None, 87, 128, 63)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_349 (Ba  (None, 87, 128, 63)      252       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_350 (Conv2D)         (None, 87, 128, 39)       61464     \n",
            "                                                                 \n",
            " max_pooling2d_350 (MaxPooli  (None, 44, 64, 39)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_350 (Ba  (None, 44, 64, 39)       156       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_118 (Flatten)       (None, 109824)            0         \n",
            "                                                                 \n",
            " dense_356 (Dense)           (None, 61)                6699325   \n",
            "                                                                 \n",
            " dropout_238 (Dropout)       (None, 61)                0         \n",
            "                                                                 \n",
            " dense_357 (Dense)           (None, 5)                 310       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,875,163\n",
            "Trainable params: 6,874,781\n",
            "Non-trainable params: 382\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 162s 210ms/step - loss: 0.7308 - accuracy: 0.1263 - val_loss: 0.6931 - val_accuracy: 0.1249\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 155s 206ms/step - loss: 0.6932 - accuracy: 0.1850 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 154s 206ms/step - loss: 0.6932 - accuracy: 0.2644 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 155s 206ms/step - loss: 0.6940 - accuracy: 0.1310 - val_loss: 0.6938 - val_accuracy: 0.5313\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 154s 205ms/step - loss: 0.6932 - accuracy: 0.3688 - val_loss: 0.6936 - val_accuracy: 0.0313\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 154s 205ms/step - loss: 0.6932 - accuracy: 0.2246 - val_loss: 0.6936 - val_accuracy: 0.2499\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 154s 205ms/step - loss: 0.6932 - accuracy: 0.1360 - val_loss: 0.6937 - val_accuracy: 0.2499\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 154s 206ms/step - loss: 0.6932 - accuracy: 0.2516 - val_loss: 0.6937 - val_accuracy: 0.5313\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 154s 205ms/step - loss: 0.6932 - accuracy: 0.2520 - val_loss: 0.6937 - val_accuracy: 0.0626\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 154s 206ms/step - loss: 0.6932 - accuracy: 0.2484 - val_loss: 0.6937 - val_accuracy: 0.5313\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 154s 206ms/step - loss: 0.6932 - accuracy: 0.1988 - val_loss: 0.6937 - val_accuracy: 0.5313\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 154s 206ms/step - loss: 0.6932 - accuracy: 0.1705 - val_loss: 0.6937 - val_accuracy: 0.0313\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 154s 206ms/step - loss: 0.6932 - accuracy: 0.1369 - val_loss: 0.6936 - val_accuracy: 0.0313\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 154s 205ms/step - loss: 0.6932 - accuracy: 0.1587 - val_loss: 0.6937 - val_accuracy: 0.0313\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 154s 205ms/step - loss: 0.6932 - accuracy: 0.3109 - val_loss: 0.6937 - val_accuracy: 0.0313\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.6937 - accuracy: 0.0313\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 53, 6, 3, 1, 2, 35, 2, 2, 2, 2, 11, 3, 2, 1, 2, 7, 3, 6, 2, 2, 50, 5, 5, 2, 2, 2, 24, 0.39, 38, 0.16, 23, 0.07]\n",
            "Model: \"sequential_119\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_351 (Conv2D)         (None, 87, 128, 53)       1007      \n",
            "                                                                 \n",
            " max_pooling2d_351 (MaxPooli  (None, 87, 64, 53)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_351 (Ba  (None, 87, 64, 53)       212       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_352 (Conv2D)         (None, 87, 64, 35)        7455      \n",
            "                                                                 \n",
            " max_pooling2d_352 (MaxPooli  (None, 44, 32, 35)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_352 (Ba  (None, 44, 32, 35)       140       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_353 (Conv2D)         (None, 44, 32, 11)        2321      \n",
            "                                                                 \n",
            " max_pooling2d_353 (MaxPooli  (None, 44, 16, 11)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_353 (Ba  (None, 44, 16, 11)       44        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_354 (Conv2D)         (None, 44, 16, 7)         1393      \n",
            "                                                                 \n",
            " max_pooling2d_354 (MaxPooli  (None, 22, 8, 7)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_354 (Ba  (None, 22, 8, 7)         28        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_119 (Flatten)       (None, 1232)              0         \n",
            "                                                                 \n",
            " dense_358 (Dense)           (None, 24)                29592     \n",
            "                                                                 \n",
            " dropout_239 (Dropout)       (None, 24)                0         \n",
            "                                                                 \n",
            " dense_359 (Dense)           (None, 38)                950       \n",
            "                                                                 \n",
            " dropout_240 (Dropout)       (None, 38)                0         \n",
            "                                                                 \n",
            " dense_360 (Dense)           (None, 5)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,337\n",
            "Trainable params: 43,125\n",
            "Non-trainable params: 212\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 35s 45ms/step - loss: 0.4728 - accuracy: 0.2442 - val_loss: 0.3786 - val_accuracy: 0.3574\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.2619 - accuracy: 0.3893 - val_loss: 0.2794 - val_accuracy: 0.4988\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1991 - accuracy: 0.4507 - val_loss: 0.1952 - val_accuracy: 0.5372\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1709 - accuracy: 0.4717 - val_loss: 0.1868 - val_accuracy: 0.4966\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1407 - accuracy: 0.4821 - val_loss: 0.1017 - val_accuracy: 0.4185\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1254 - accuracy: 0.4869 - val_loss: 0.0814 - val_accuracy: 0.4686\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.1070 - accuracy: 0.5003 - val_loss: 0.1380 - val_accuracy: 0.5456\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.0994 - accuracy: 0.4980 - val_loss: 0.1548 - val_accuracy: 0.4873\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.0928 - accuracy: 0.5030 - val_loss: 0.1654 - val_accuracy: 0.5264\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.0902 - accuracy: 0.5005 - val_loss: 0.1654 - val_accuracy: 0.3951\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.0852 - accuracy: 0.5011 - val_loss: 0.1097 - val_accuracy: 0.4512\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 32s 42ms/step - loss: 0.0816 - accuracy: 0.5088 - val_loss: 0.0973 - val_accuracy: 0.4464\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.0778 - accuracy: 0.5199 - val_loss: 0.1507 - val_accuracy: 0.5246\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.0776 - accuracy: 0.5129 - val_loss: 0.1739 - val_accuracy: 0.5312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 32s 43ms/step - loss: 0.0731 - accuracy: 0.5227 - val_loss: 0.4623 - val_accuracy: 0.5332\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.4623 - accuracy: 0.5332\n",
            "sklearn_accuracy: 0.64625\n",
            "(100.0 % )\n",
            "Creating individual 1 out of 8\n",
            "- working on # of filters' of conv layers  (index: 1, 6, 11, 16, 21)\n",
            "- working on x and y kernel dimensions     (index: 2, 3, 7, 8, 12, 13, 17, 18, 22, 23)\n",
            "- working on x and y MaxPooling size       (index: 4, 5, 9, 10, 14, 15, 19, 20, 24, 25)\n",
            "- working # of neurons in dense layers     (index: 27, 29, 31)\n",
            "- working dropout prob. after dense layers (index: 28, 30, 32)\n",
            "[3, 26, 2, 4, 2, 1, 47, 3, 6, 1, 2, 20, 2, 2, 1, 1, 35, 4, 6, 2, 1, 41, 4, 2, 1, 2, 2, 32, 0.37, 32, 0.18, 27, 0.48]\n",
            "\n",
            "Creating individual 2 out of 8\n",
            "[4, 10, 2, 4, 1, 2, 35, 7, 5, 2, 2, 56, 2, 7, 2, 1, 63, 2, 6, 1, 2, 10, 7, 6, 2, 1, 2, 19, 0.46, 34, 0.1, 20, 0.38]\n",
            "\n",
            "Creating individual 3 out of 8\n",
            "[3, 53, 2, 7, 2, 1, 58, 4, 3, 2, 2, 5, 7, 6, 2, 2, 21, 6, 2, 1, 2, 20, 2, 6, 1, 1, 2, 55, 0.34, 3, 0.45, 49, 0.3]\n",
            "\n",
            "Creating individual 4 out of 8\n",
            "[5, 52, 4, 3, 2, 1, 7, 4, 5, 2, 2, 57, 2, 3, 2, 1, 45, 4, 4, 1, 1, 36, 4, 5, 1, 2, 2, 5, 0.21, 21, 0.3, 47, 0.26]\n",
            "\n",
            "Creating individual 5 out of 8\n",
            "[4, 56, 2, 7, 2, 1, 31, 5, 4, 2, 1, 38, 5, 4, 2, 1, 6, 5, 6, 2, 2, 8, 5, 2, 1, 1, 1, 28, 0.49, 58, 0.47, 7, 0.26]\n",
            "\n",
            "Creating individual 6 out of 8\n",
            "[3, 32, 2, 6, 1, 2, 10, 6, 2, 1, 2, 53, 7, 7, 2, 2, 50, 2, 6, 2, 1, 7, 6, 5, 1, 2, 3, 8, 0.28, 3, 0.28, 6, 0.04]\n",
            "\n",
            "Creating individual 7 out of 8\n",
            "[4, 47, 4, 5, 1, 1, 27, 2, 3, 1, 2, 22, 2, 6, 2, 1, 30, 5, 7, 1, 1, 12, 4, 3, 2, 2, 3, 62, 0.42, 21, 0.07, 27, 0.24]\n",
            "\n",
            "Creating individual 8 out of 8\n",
            "[5, 60, 7, 7, 2, 2, 22, 2, 3, 1, 2, 4, 6, 4, 2, 2, 57, 3, 2, 1, 1, 9, 4, 6, 1, 1, 1, 10, 0.32, 34, 0.25, 45, 0.27]\n",
            "\n",
            "\n",
            "(1/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 26, 2, 4, 2, 1, 47, 3, 6, 1, 2, 20, 2, 2, 1, 1, 35, 4, 6, 2, 1, 41, 4, 2, 1, 2, 2, 32, 0.37, 32, 0.18, 27, 0.48]\n",
            "Model: \"sequential_120\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_355 (Conv2D)         (None, 87, 128, 26)       234       \n",
            "                                                                 \n",
            " max_pooling2d_355 (MaxPooli  (None, 44, 128, 26)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_355 (Ba  (None, 44, 128, 26)      104       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_356 (Conv2D)         (None, 44, 128, 47)       22043     \n",
            "                                                                 \n",
            " max_pooling2d_356 (MaxPooli  (None, 44, 64, 47)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_356 (Ba  (None, 44, 64, 47)       188       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_357 (Conv2D)         (None, 44, 64, 20)        3780      \n",
            "                                                                 \n",
            " max_pooling2d_357 (MaxPooli  (None, 44, 64, 20)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_357 (Ba  (None, 44, 64, 20)       80        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_120 (Flatten)       (None, 56320)             0         \n",
            "                                                                 \n",
            " dense_361 (Dense)           (None, 32)                1802272   \n",
            "                                                                 \n",
            " dropout_241 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_362 (Dense)           (None, 32)                1056      \n",
            "                                                                 \n",
            " dropout_242 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_363 (Dense)           (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,829,922\n",
            "Trainable params: 1,829,736\n",
            "Non-trainable params: 186\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 33s 42ms/step - loss: 0.6945 - accuracy: 0.1671 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 30s 40ms/step - loss: 0.6932 - accuracy: 0.3557 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.1309 - val_loss: 0.6932 - val_accuracy: 0.2499\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.2629 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 30s 40ms/step - loss: 0.6932 - accuracy: 0.1968 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.0926 - val_loss: 0.6932 - val_accuracy: 0.2499\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.1362 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.1542 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.2731 - val_loss: 0.6932 - val_accuracy: 0.2499\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.2965 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.1726 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.2292 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.1182 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.3048 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6932 - accuracy: 0.0995 - val_loss: 0.6932 - val_accuracy: 0.2499\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6932 - accuracy: 0.2499\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(2/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 10, 2, 4, 1, 2, 35, 7, 5, 2, 2, 56, 2, 7, 2, 1, 63, 2, 6, 1, 2, 10, 7, 6, 2, 1, 2, 19, 0.46, 34, 0.1, 20, 0.38]\n",
            "Model: \"sequential_121\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_358 (Conv2D)         (None, 87, 128, 10)       90        \n",
            "                                                                 \n",
            " max_pooling2d_358 (MaxPooli  (None, 87, 64, 10)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_358 (Ba  (None, 87, 64, 10)       40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_359 (Conv2D)         (None, 87, 64, 35)        12285     \n",
            "                                                                 \n",
            " max_pooling2d_359 (MaxPooli  (None, 44, 32, 35)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_359 (Ba  (None, 44, 32, 35)       140       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_360 (Conv2D)         (None, 44, 32, 56)        27496     \n",
            "                                                                 \n",
            " max_pooling2d_360 (MaxPooli  (None, 22, 32, 56)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_360 (Ba  (None, 22, 32, 56)       224       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_361 (Conv2D)         (None, 22, 32, 63)        42399     \n",
            "                                                                 \n",
            " max_pooling2d_361 (MaxPooli  (None, 22, 16, 63)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_361 (Ba  (None, 22, 16, 63)       252       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_121 (Flatten)       (None, 22176)             0         \n",
            "                                                                 \n",
            " dense_364 (Dense)           (None, 19)                421363    \n",
            "                                                                 \n",
            " dropout_243 (Dropout)       (None, 19)                0         \n",
            "                                                                 \n",
            " dense_365 (Dense)           (None, 34)                680       \n",
            "                                                                 \n",
            " dropout_244 (Dropout)       (None, 34)                0         \n",
            "                                                                 \n",
            " dense_366 (Dense)           (None, 5)                 175       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 505,144\n",
            "Trainable params: 504,816\n",
            "Non-trainable params: 328\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 28s 35ms/step - loss: 0.6939 - accuracy: 0.2187 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 0.6932 - accuracy: 0.1382 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6936 - accuracy: 0.2206 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.2768 - val_loss: 0.6931 - val_accuracy: 0.0624\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.1851 - val_loss: 0.6931 - val_accuracy: 0.2499\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.2016 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.1431 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.2408 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.2061 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.1966 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.3044 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.0799 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.1444 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.3228 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.6932 - accuracy: 0.1275 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 0.6932 - accuracy: 0.0625\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(3/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 53, 2, 7, 2, 1, 58, 4, 3, 2, 2, 5, 7, 6, 2, 2, 21, 6, 2, 1, 2, 20, 2, 6, 1, 1, 2, 55, 0.34, 3, 0.45, 49, 0.3]\n",
            "Model: \"sequential_122\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_362 (Conv2D)         (None, 87, 128, 53)       795       \n",
            "                                                                 \n",
            " max_pooling2d_362 (MaxPooli  (None, 44, 128, 53)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_362 (Ba  (None, 44, 128, 53)      212       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_363 (Conv2D)         (None, 44, 128, 58)       36946     \n",
            "                                                                 \n",
            " max_pooling2d_363 (MaxPooli  (None, 22, 64, 58)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_363 (Ba  (None, 22, 64, 58)       232       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_364 (Conv2D)         (None, 22, 64, 5)         12185     \n",
            "                                                                 \n",
            " max_pooling2d_364 (MaxPooli  (None, 11, 32, 5)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_364 (Ba  (None, 11, 32, 5)        20        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_122 (Flatten)       (None, 1760)              0         \n",
            "                                                                 \n",
            " dense_367 (Dense)           (None, 55)                96855     \n",
            "                                                                 \n",
            " dropout_245 (Dropout)       (None, 55)                0         \n",
            "                                                                 \n",
            " dense_368 (Dense)           (None, 3)                 168       \n",
            "                                                                 \n",
            " dropout_246 (Dropout)       (None, 3)                 0         \n",
            "                                                                 \n",
            " dense_369 (Dense)           (None, 5)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 147,433\n",
            "Trainable params: 147,201\n",
            "Non-trainable params: 232\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 49s 62ms/step - loss: 0.6936 - accuracy: 0.1828 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.1816 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.2323 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.1355 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.2495 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.2512 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.0899 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.2304 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.1886 - val_loss: 0.6931 - val_accuracy: 0.0312\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.0905 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.3324 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.1218 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.1383 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.1480 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 45s 60ms/step - loss: 0.6932 - accuracy: 0.2377 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.6932 - accuracy: 0.5312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(4/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 52, 4, 3, 2, 1, 7, 4, 5, 2, 2, 57, 2, 3, 2, 1, 45, 4, 4, 1, 1, 36, 4, 5, 1, 2, 2, 5, 0.21, 21, 0.3, 47, 0.26]\n",
            "Model: \"sequential_123\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_365 (Conv2D)         (None, 87, 128, 52)       676       \n",
            "                                                                 \n",
            " max_pooling2d_365 (MaxPooli  (None, 44, 128, 52)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_365 (Ba  (None, 44, 128, 52)      208       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_366 (Conv2D)         (None, 44, 128, 7)        7287      \n",
            "                                                                 \n",
            " max_pooling2d_366 (MaxPooli  (None, 22, 64, 7)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_366 (Ba  (None, 22, 64, 7)        28        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_367 (Conv2D)         (None, 22, 64, 57)        2451      \n",
            "                                                                 \n",
            " max_pooling2d_367 (MaxPooli  (None, 11, 64, 57)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_367 (Ba  (None, 11, 64, 57)       228       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_368 (Conv2D)         (None, 11, 64, 45)        41085     \n",
            "                                                                 \n",
            " max_pooling2d_368 (MaxPooli  (None, 11, 64, 45)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_368 (Ba  (None, 11, 64, 45)       180       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_369 (Conv2D)         (None, 11, 64, 36)        32436     \n",
            "                                                                 \n",
            " max_pooling2d_369 (MaxPooli  (None, 11, 32, 36)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_369 (Ba  (None, 11, 32, 36)       144       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_123 (Flatten)       (None, 12672)             0         \n",
            "                                                                 \n",
            " dense_370 (Dense)           (None, 5)                 63365     \n",
            "                                                                 \n",
            " dropout_247 (Dropout)       (None, 5)                 0         \n",
            "                                                                 \n",
            " dense_371 (Dense)           (None, 21)                126       \n",
            "                                                                 \n",
            " dropout_248 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_372 (Dense)           (None, 5)                 110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 148,324\n",
            "Trainable params: 147,930\n",
            "Non-trainable params: 394\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 44s 56ms/step - loss: 0.6934 - accuracy: 0.2452 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.2869 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.2399 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.1549 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.2958 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.2148 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.2090 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.1782 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.1574 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.3248 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.0753 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.2824 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.0995 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.3051 - val_loss: 0.6931 - val_accuracy: 0.0625\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 40s 54ms/step - loss: 0.6932 - accuracy: 0.1577 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 0.6932 - accuracy: 0.0312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(5/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 56, 2, 7, 2, 1, 31, 5, 4, 2, 1, 38, 5, 4, 2, 1, 6, 5, 6, 2, 2, 8, 5, 2, 1, 1, 1, 28, 0.49, 58, 0.47, 7, 0.26]\n",
            "Model: \"sequential_124\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_370 (Conv2D)         (None, 87, 128, 56)       840       \n",
            "                                                                 \n",
            " max_pooling2d_370 (MaxPooli  (None, 44, 128, 56)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_370 (Ba  (None, 44, 128, 56)      224       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_371 (Conv2D)         (None, 44, 128, 31)       34751     \n",
            "                                                                 \n",
            " max_pooling2d_371 (MaxPooli  (None, 22, 128, 31)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_371 (Ba  (None, 22, 128, 31)      124       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_372 (Conv2D)         (None, 22, 128, 38)       23598     \n",
            "                                                                 \n",
            " max_pooling2d_372 (MaxPooli  (None, 11, 128, 38)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_372 (Ba  (None, 11, 128, 38)      152       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_373 (Conv2D)         (None, 11, 128, 6)        6846      \n",
            "                                                                 \n",
            " max_pooling2d_373 (MaxPooli  (None, 6, 64, 6)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_373 (Ba  (None, 6, 64, 6)         24        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_124 (Flatten)       (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_373 (Dense)           (None, 28)                64540     \n",
            "                                                                 \n",
            " dropout_249 (Dropout)       (None, 28)                0         \n",
            "                                                                 \n",
            " dense_374 (Dense)           (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131,244\n",
            "Trainable params: 130,982\n",
            "Non-trainable params: 262\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 56s 72ms/step - loss: 0.4956 - accuracy: 0.2118 - val_loss: 0.3840 - val_accuracy: 0.3845\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.2328 - accuracy: 0.3298 - val_loss: 0.1385 - val_accuracy: 0.2071\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.1446 - accuracy: 0.3458 - val_loss: 0.4951 - val_accuracy: 0.2648\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.1196 - accuracy: 0.3232 - val_loss: 0.1580 - val_accuracy: 0.2922\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.1098 - accuracy: 0.3096 - val_loss: 0.2774 - val_accuracy: 0.2339\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.1076 - accuracy: 0.3076 - val_loss: 0.0971 - val_accuracy: 0.3022\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.0996 - accuracy: 0.3064 - val_loss: 0.5540 - val_accuracy: 0.2578\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.0964 - accuracy: 0.3143 - val_loss: 0.1716 - val_accuracy: 0.2589\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.0937 - accuracy: 0.3097 - val_loss: 0.0439 - val_accuracy: 0.2319\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.0926 - accuracy: 0.3166 - val_loss: 0.0547 - val_accuracy: 0.2986\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.0916 - accuracy: 0.3109 - val_loss: 0.0845 - val_accuracy: 0.2331\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.0921 - accuracy: 0.3128 - val_loss: 0.0826 - val_accuracy: 0.3255\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.0906 - accuracy: 0.3140 - val_loss: 0.2670 - val_accuracy: 0.2746\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.0887 - accuracy: 0.3186 - val_loss: 0.2033 - val_accuracy: 0.2628\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 52s 69ms/step - loss: 0.0883 - accuracy: 0.3130 - val_loss: 0.0516 - val_accuracy: 0.2977\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 0.0516 - accuracy: 0.2977\n",
            "sklearn_accuracy: 0.9443125\n",
            "\n",
            "(6/8) - fitness_evaluation function. Individual considered:\n",
            "[3, 32, 2, 6, 1, 2, 10, 6, 2, 1, 2, 53, 7, 7, 2, 2, 50, 2, 6, 2, 1, 7, 6, 5, 1, 2, 3, 8, 0.28, 3, 0.28, 6, 0.04]\n",
            "Model: \"sequential_125\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_374 (Conv2D)         (None, 87, 128, 32)       416       \n",
            "                                                                 \n",
            " max_pooling2d_374 (MaxPooli  (None, 87, 64, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_374 (Ba  (None, 87, 64, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_375 (Conv2D)         (None, 87, 64, 10)        3850      \n",
            "                                                                 \n",
            " max_pooling2d_375 (MaxPooli  (None, 87, 32, 10)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_375 (Ba  (None, 87, 32, 10)       40        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_376 (Conv2D)         (None, 87, 32, 53)        26023     \n",
            "                                                                 \n",
            " max_pooling2d_376 (MaxPooli  (None, 44, 16, 53)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_376 (Ba  (None, 44, 16, 53)       212       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_125 (Flatten)       (None, 37312)             0         \n",
            "                                                                 \n",
            " dense_375 (Dense)           (None, 8)                 298504    \n",
            "                                                                 \n",
            " dropout_250 (Dropout)       (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_376 (Dense)           (None, 3)                 27        \n",
            "                                                                 \n",
            " dropout_251 (Dropout)       (None, 3)                 0         \n",
            "                                                                 \n",
            " dense_377 (Dense)           (None, 6)                 24        \n",
            "                                                                 \n",
            " dropout_252 (Dropout)       (None, 6)                 0         \n",
            "                                                                 \n",
            " dense_378 (Dense)           (None, 5)                 35        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 329,259\n",
            "Trainable params: 329,069\n",
            "Non-trainable params: 190\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 30s 39ms/step - loss: 0.6940 - accuracy: 0.2284 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.2227 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 27s 37ms/step - loss: 0.6932 - accuracy: 0.1151 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 27s 37ms/step - loss: 0.6932 - accuracy: 0.2929 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 27s 37ms/step - loss: 0.6932 - accuracy: 0.1275 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 27s 37ms/step - loss: 0.6932 - accuracy: 0.3255 - val_loss: 0.6931 - val_accuracy: 0.1250\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.2569 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1905 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1703 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1553 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1225 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.2517 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.2714 - val_loss: 0.6932 - val_accuracy: 0.1250\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1498 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.6932 - accuracy: 0.1699 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 0.6932 - accuracy: 0.0625\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(7/8) - fitness_evaluation function. Individual considered:\n",
            "[4, 47, 4, 5, 1, 1, 27, 2, 3, 1, 2, 22, 2, 6, 2, 1, 30, 5, 7, 1, 1, 12, 4, 3, 2, 2, 3, 62, 0.42, 21, 0.07, 27, 0.24]\n",
            "Model: \"sequential_126\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_377 (Conv2D)         (None, 87, 128, 47)       987       \n",
            "                                                                 \n",
            " max_pooling2d_377 (MaxPooli  (None, 87, 128, 47)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_377 (Ba  (None, 87, 128, 47)      188       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_378 (Conv2D)         (None, 87, 128, 27)       7641      \n",
            "                                                                 \n",
            " max_pooling2d_378 (MaxPooli  (None, 87, 64, 27)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_378 (Ba  (None, 87, 64, 27)       108       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_379 (Conv2D)         (None, 87, 64, 22)        7150      \n",
            "                                                                 \n",
            " max_pooling2d_379 (MaxPooli  (None, 44, 64, 22)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_379 (Ba  (None, 44, 64, 22)       88        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_380 (Conv2D)         (None, 44, 64, 30)        23130     \n",
            "                                                                 \n",
            " max_pooling2d_380 (MaxPooli  (None, 44, 64, 30)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_380 (Ba  (None, 44, 64, 30)       120       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_126 (Flatten)       (None, 84480)             0         \n",
            "                                                                 \n",
            " dense_379 (Dense)           (None, 62)                5237822   \n",
            "                                                                 \n",
            " dropout_253 (Dropout)       (None, 62)                0         \n",
            "                                                                 \n",
            " dense_380 (Dense)           (None, 21)                1323      \n",
            "                                                                 \n",
            " dropout_254 (Dropout)       (None, 21)                0         \n",
            "                                                                 \n",
            " dense_381 (Dense)           (None, 27)                594       \n",
            "                                                                 \n",
            " dropout_255 (Dropout)       (None, 27)                0         \n",
            "                                                                 \n",
            " dense_382 (Dense)           (None, 5)                 140       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,279,291\n",
            "Trainable params: 5,279,039\n",
            "Non-trainable params: 252\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 59s 77ms/step - loss: 0.6975 - accuracy: 0.2149 - val_loss: 0.6931 - val_accuracy: 0.5316\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 56s 74ms/step - loss: 0.6932 - accuracy: 0.2301 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 56s 75ms/step - loss: 0.6932 - accuracy: 0.2546 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 56s 75ms/step - loss: 0.6932 - accuracy: 0.0855 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 56s 75ms/step - loss: 0.6932 - accuracy: 0.2831 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 56s 75ms/step - loss: 0.6932 - accuracy: 0.2588 - val_loss: 0.6932 - val_accuracy: 0.0312\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 56s 75ms/step - loss: 0.6932 - accuracy: 0.0972 - val_loss: 0.6931 - val_accuracy: 0.5312\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 56s 75ms/step - loss: 0.6932 - accuracy: 0.1985 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 56s 75ms/step - loss: 0.6932 - accuracy: 0.1149 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 56s 75ms/step - loss: 0.6932 - accuracy: 0.2116 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 56s 74ms/step - loss: 0.6932 - accuracy: 0.1447 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 56s 74ms/step - loss: 0.6932 - accuracy: 0.3274 - val_loss: 0.6931 - val_accuracy: 0.2500\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 56s 74ms/step - loss: 0.6932 - accuracy: 0.1838 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 56s 74ms/step - loss: 0.6932 - accuracy: 0.2215 - val_loss: 0.6932 - val_accuracy: 0.0625\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 56s 75ms/step - loss: 0.6932 - accuracy: 0.2196 - val_loss: 0.6932 - val_accuracy: 0.5312\n",
            "500/500 [==============================] - 6s 10ms/step - loss: 0.6932 - accuracy: 0.5312\n",
            "sklearn_accuracy: 0.03125\n",
            "\n",
            "(8/8) - fitness_evaluation function. Individual considered:\n",
            "[5, 60, 7, 7, 2, 2, 22, 2, 3, 1, 2, 4, 6, 4, 2, 2, 57, 3, 2, 1, 1, 9, 4, 6, 1, 1, 1, 10, 0.32, 34, 0.25, 45, 0.27]\n",
            "Model: \"sequential_127\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_381 (Conv2D)         (None, 87, 128, 60)       3000      \n",
            "                                                                 \n",
            " max_pooling2d_381 (MaxPooli  (None, 44, 64, 60)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_381 (Ba  (None, 44, 64, 60)       240       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_382 (Conv2D)         (None, 44, 64, 22)        7942      \n",
            "                                                                 \n",
            " max_pooling2d_382 (MaxPooli  (None, 44, 32, 22)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_382 (Ba  (None, 44, 32, 22)       88        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_383 (Conv2D)         (None, 44, 32, 4)         2116      \n",
            "                                                                 \n",
            " max_pooling2d_383 (MaxPooli  (None, 22, 16, 4)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_383 (Ba  (None, 22, 16, 4)        16        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_384 (Conv2D)         (None, 22, 16, 57)        1425      \n",
            "                                                                 \n",
            " max_pooling2d_384 (MaxPooli  (None, 22, 16, 57)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_384 (Ba  (None, 22, 16, 57)       228       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_385 (Conv2D)         (None, 22, 16, 9)         12321     \n",
            "                                                                 \n",
            " max_pooling2d_385 (MaxPooli  (None, 22, 16, 9)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_385 (Ba  (None, 22, 16, 9)        36        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_127 (Flatten)       (None, 3168)              0         \n",
            "                                                                 \n",
            " dense_383 (Dense)           (None, 10)                31690     \n",
            "                                                                 \n",
            " dropout_256 (Dropout)       (None, 10)                0         \n",
            "                                                                 \n",
            " dense_384 (Dense)           (None, 5)                 55        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59,157\n",
            "Trainable params: 58,853\n",
            "Non-trainable params: 304\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 28s 36ms/step - loss: 0.5685 - accuracy: 0.1670 - val_loss: 0.4634 - val_accuracy: 0.2448\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 0.4960 - accuracy: 0.1756 - val_loss: 0.4718 - val_accuracy: 0.2059\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.4722 - accuracy: 0.1835 - val_loss: 0.4512 - val_accuracy: 0.2127\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.4638 - accuracy: 0.1790 - val_loss: 0.4114 - val_accuracy: 0.2440\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.4589 - accuracy: 0.1978 - val_loss: 0.4067 - val_accuracy: 0.2427\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.4561 - accuracy: 0.1993 - val_loss: 0.3798 - val_accuracy: 0.1964\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.4555 - accuracy: 0.1984 - val_loss: 0.4942 - val_accuracy: 0.2282\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.4333 - accuracy: 0.2077 - val_loss: 0.3371 - val_accuracy: 0.2296\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.4122 - accuracy: 0.2165 - val_loss: 0.3367 - val_accuracy: 0.2661\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3657 - accuracy: 0.2297 - val_loss: 0.3250 - val_accuracy: 0.2665\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3352 - accuracy: 0.2662 - val_loss: 0.2826 - val_accuracy: 0.2619\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.3127 - accuracy: 0.2651 - val_loss: 0.2163 - val_accuracy: 0.2517\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.2965 - accuracy: 0.2619 - val_loss: 0.2027 - val_accuracy: 0.2233\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.2890 - accuracy: 0.2593 - val_loss: 0.1877 - val_accuracy: 0.2277\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 25s 33ms/step - loss: 0.2806 - accuracy: 0.2616 - val_loss: 0.1672 - val_accuracy: 0.2450\n",
            "500/500 [==============================] - 4s 6ms/step - loss: 0.1672 - accuracy: 0.2450\n",
            "sklearn_accuracy: 0.7663125\n"
          ]
        }
      ],
      "source": [
        "MEL_SPEC_DATASET = DATASET_PATH_MEL_SPEC_FIXED\n",
        "dataset_considered = 1\n",
        "\n",
        "# main\n",
        "import os\n",
        "\n",
        "NUM_GENERATIONS_RS = 16\n",
        "POPULATION_SIZE_RS = 8\n",
        "PARAMETERS = 'not-bounded'\n",
        "\n",
        "# STATISTICS PATH\n",
        "date_string = time.asctime(time.localtime(time.time()))                     # ex. Wed Nov 16 10:40:52 2022\n",
        "date_month_year = date_string[8:10] + date_string[4:7] + date_string[-4:]   # ex. 6Nov2022\n",
        "path_part_1 = f'/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/3__random_search'\n",
        "path_part_2 = f'1__{PARAMETERS}_{date_month_year}_P{POPULATION_SIZE_RS}_G{NUM_GENERATIONS_RS}_dataset_{dataset_considered}.json'\n",
        "STATISTICS_RANDOM_SEARCH_PATH = os.path.join(path_part_1, path_part_2)  \n",
        "\n",
        "# load entire dataset\n",
        "data_complete = load_data_pickle(MEL_SPEC_DATASET)\n",
        "X_train, X_test, y_train, y_test, N_train, N_test = prepare_dataset_for_guitar_cross_validation(data_complete, 'strato')\n",
        "data = (X_train, y_train), (X_test, y_test)\n",
        "del data_complete\n",
        "\n",
        "# save statistics\n",
        "statistics_dict = {\n",
        "      \"best_individuals\":[],\n",
        "      \"min\":[],\n",
        "      \"max\":[],\n",
        "      \"average\":[]\n",
        "}\n",
        "\n",
        "for index in range(NUM_GENERATIONS_RS):\n",
        "\n",
        "  print(f\"({ 100 * (index+1) / NUM_GENERATIONS_RS} % )\")\n",
        "\n",
        "  # create population with random parameters\n",
        "  population = initialize_first_population(population_size=POPULATION_SIZE_RS, verbose=True, start_with_low_values=False)\n",
        "\n",
        "  # perform train and test\n",
        "  population_eval  = population_evaluation(population, data, POPULATION_SIZE_RS)\n",
        "\n",
        "  # save statistics\n",
        "  statistics_dict[\"best_individuals\"].append(population_eval['best_individual'][0])\n",
        "  statistics_dict[\"min\"].append(population_eval['statistics'][\"min\"])\n",
        "  statistics_dict[\"max\"].append(population_eval['statistics'][\"max\"])\n",
        "  statistics_dict[\"average\"].append(population_eval['statistics'][\"average\"])\n",
        "\n",
        "with open(STATISTICS_RANDOM_SEARCH_PATH, 'w') as f:\n",
        "  json.dump(statistics_dict, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ2C3xWnYHu8"
      },
      "source": [
        "### not used anymore - (IMPLEM. BEST MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdX5cuyXSpw-"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "\n",
        "\n",
        "def load_data_pickle(data_path):\n",
        "  with open(data_path, \"rb\") as fp:\n",
        "      data = pickle.load(fp)\n",
        "  return data\n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "\n",
        "    fig, axs = plt.subplots(2)\n",
        "\n",
        "    # create accuracy sublpot\n",
        "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
        "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy eval\")\n",
        "\n",
        "    # create error sublpot\n",
        "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
        "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
        "    axs[1].set_ylabel(\"Error\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Error eval\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# build and compile the model\n",
        "def build_and_compile_model(indiv, input_shape, print_model=True):\n",
        "\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # create first conv layer + pooling layer\n",
        "  model.add(keras.layers.Conv2D(filters=indiv[1], kernel_size=(indiv[2], indiv[3]), input_shape=input_shape, activation='relu', padding='same'))\n",
        "  model.add(keras.layers.MaxPool2D(pool_size=(indiv[4], indiv[5]), padding='same'))\n",
        "  model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "  # create other conv layers + pooling layers\n",
        "  remain_conv_layer = indiv[0] - 1\n",
        "  for i in range(6, 6 + remain_conv_layer * 4, 5):\n",
        "    model.add(keras.layers.Conv2D(filters=indiv[i], kernel_size=(indiv[i+1], indiv[i+2]), activation='relu', padding='same'))\n",
        "    model.add(keras.layers.MaxPool2D(pool_size=(indiv[i+3], indiv[i+4]), padding='same'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    \n",
        "  # flatten\n",
        "  model.add(keras.layers.Flatten())\n",
        "\n",
        "  # create dense layers + dropout\n",
        "  dense_layers = indiv[26]  # how many dense layers we have\n",
        "  for j in range(27, 27 + dense_layers * 2, 2):\n",
        "    model.add(keras.layers.Dense(units=indiv[j], activation='relu'))\n",
        "    model.add(keras.layers.Dropout(indiv[j+1]))\n",
        "\n",
        "  # add final layer\n",
        "  model.add(keras.layers.Dense(units=5, activation='sigmoid'))\n",
        "\n",
        "  # compile the model\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.00005)\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  if print_model:\n",
        "    print(model.summary())\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "def prepare_dataset_for_guitar_cross_validation(data, test_guitar = 'tele'):\n",
        "\n",
        "    # 64000 segments in total\n",
        "\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "    N_test = []\n",
        "\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    N_train = []\n",
        "    \n",
        "    count_test = 0\n",
        "    count_train = 0\n",
        "    \n",
        "    # i goes from 0 to 63999\n",
        "    for i, name in enumerate(data['names']):\n",
        "      if name[:3] == test_guitar[:3]:   \n",
        "        \n",
        "        X_test.append(data['spectrograms'][i])\n",
        "        y_test.append(data['labels'][i])\n",
        "        N_test.append(data['names'][i])\n",
        "        count_test += 1\n",
        "\n",
        "      else:\n",
        "\n",
        "        X_train.append(data['spectrograms'][i])\n",
        "        y_train.append(data['labels'][i])\n",
        "        N_train.append(data['names'][i])\n",
        "        count_train += 1\n",
        "\n",
        "    print(f'train set: {count_train}')\n",
        "    print(f'test set: {count_test} (guitar: {test_guitar})')\n",
        "\n",
        "    # from list to numpy array \n",
        "    X_train = np.array(X_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_train = np.array(y_train)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    # add 3rd dimension\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, N_train, N_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nAHo8VeZJdM",
        "outputId": "d05c9dfd-19a4-43aa-f936-8f14168c1eb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     [4, 8, 7, 7, 1, 2, 5, 4, 3, 2] ...    0.13175\n",
            "1     [4, 8, 7, 7, 1, 2, 5, 4, 3, 2] ...    0.2419375\n",
            "2     [4, 8, 7, 7, 1, 2, 5, 4, 3, 2] ...    0.322875\n",
            "3     [4, 8, 7, 7, 1, 2, 5, 4, 6, 2] ...    0.2141875\n",
            "4     [3, 27, 6, 6, 1, 2, 17, 7, 6, 2] ...    0.23325\n",
            "5     [4, 15, 3, 7, 1, 1, 10, 4, 3, 2] ...    0.2346875\n",
            "6     [5, 19, 5, 4, 1, 2, 23, 2, 3, 1] ...    0.2764375\n",
            "7     [5, 15, 5, 7, 2, 1, 17, 3, 3, 1] ...    0.288875\n",
            "8     [5, 19, 3, 4, 1, 2, 30, 6, 5, 1] ...    0.414125\n",
            "9     [5, 27, 4, 4, 2, 2, 33, 4, 5, 1] ...    0.7365\n",
            "10     [5, 19, 3, 5, 1, 2, 30, 4, 5, 1] ...    0.802875\n",
            "11     [5, 24, 2, 3, 1, 2, 16, 4, 3, 1] ...    0.7876875\n",
            "12     [5, 24, 2, 3, 1, 1, 14, 4, 7, 2] ...    0.7589375\n",
            "13     [5, 24, 2, 3, 1, 1, 14, 4, 7, 2] ...    0.8000625\n",
            "14     [4, 44, 2, 7, 2, 1, 37, 2, 2, 1] ...    0.8269375\n",
            "15     [4, 44, 2, 7, 2, 1, 37, 2, 2, 1] ...    0.7591875\n",
            "16     [4, 40, 4, 4, 2, 2, 41, 6, 2, 2] ...    0.81575\n",
            "17     [4, 52, 3, 3, 2, 1, 37, 5, 4, 1] ...    0.8090625\n",
            "18     [4, 40, 4, 4, 1, 2, 41, 6, 2, 2] ...    0.7795\n",
            "19     [4, 60, 3, 4, 2, 1, 37, 5, 3, 1] ...    0.793625\n",
            "20     [4, 60, 3, 4, 2, 1, 37, 5, 3, 1] ...    0.815375\n",
            "21     [5, 44, 7, 7, 2, 2, 57, 3, 4, 1] ...    0.8493125\n",
            "\n",
            "individuals selected\n",
            "[4, 44, 2, 7, 2, 1, 37, 2, 2, 1, 2, 38, 3, 5, 2, 2, 21, 4, 6, 2, 1, 27, 4, 3, 2, 1, 1, 37, 0.16, 32, 0.1, 35, 0.11]\n",
            "[4, 40, 4, 4, 2, 2, 41, 6, 2, 2, 1, 27, 2, 6, 2, 1, 21, 5, 7, 2, 2, 30, 5, 5, 2, 2, 1, 44, 0.07, 20, 0.16, 21, 0.14]\n",
            "[4, 60, 3, 4, 2, 1, 37, 5, 3, 1, 2, 36, 4, 6, 2, 2, 21, 6, 2, 1, 2, 33, 4, 4, 2, 2, 2, 48, 0.04, 39, 0.09, 32, 0.2]\n",
            "[5, 44, 7, 7, 2, 2, 57, 3, 4, 1, 2, 42, 2, 3, 2, 1, 27, 5, 3, 1, 1, 30, 6, 5, 1, 2, 2, 56, 0.09, 45, 0.09, 35, 0.27]\n",
            "\n",
            "model: [4, 44, 2, 7, 2, 1, 37, 2, 2, 1, 2, 38, 3, 5, 2, 2, 21, 4, 6, 2, 1, 27, 4, 3, 2, 1, 1, 37, 0.16, 32, 0.1, 35, 0.11] \n",
            "params: 321521 \n",
            "accuracy: 0.8269375\n",
            "\n",
            "model: [4, 40, 4, 4, 2, 2, 41, 6, 2, 2, 1, 27, 2, 6, 2, 1, 21, 5, 7, 2, 2, 30, 5, 5, 2, 2, 1, 44, 0.07, 20, 0.16, 21, 0.14] \n",
            "params: 231513 \n",
            "accuracy: 0.81575\n",
            "\n",
            "model: [4, 60, 3, 4, 2, 1, 37, 5, 3, 1, 2, 36, 4, 6, 2, 2, 21, 6, 2, 1, 2, 33, 4, 4, 2, 2, 2, 48, 0.04, 39, 0.09, 32, 0.2] \n",
            "params: 432497 \n",
            "accuracy: 0.815375\n",
            "\n",
            "model: [5, 44, 7, 7, 2, 2, 57, 3, 4, 1, 2, 42, 2, 3, 2, 1, 27, 5, 3, 1, 1, 30, 6, 5, 1, 2, 2, 56, 0.09, 45, 0.09, 35, 0.27] \n",
            "params: 682737 \n",
            "accuracy: 0.8493125\n"
          ]
        }
      ],
      "source": [
        "# SELECT THE MODEL TO BE IMPLEMENTED\n",
        "\n",
        "# load genetic algorithm statistics\n",
        "statistics_path = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/1__gen_algorithm_optimization/statistics_21Jan2023position.json'\n",
        "\n",
        "with open(statistics_path, \"r\") as fp:\n",
        "    stat_genetic = json.load(fp)\n",
        "\n",
        "# select best models with accuracy > threshold and keep the one with less parameters\n",
        "threshold = 0.81\n",
        "best_individuals = []\n",
        "best_individuals_indeces = []\n",
        "\n",
        "# print the best individual of each generation and its accuracy\n",
        "for i, max_value in enumerate(stat_genetic['max']):\n",
        "  print(i,  \"   \" , stat_genetic['best_individuals'][i][:10], \"...   \", max_value)\n",
        "\n",
        "# save best individuals in a list\n",
        "for i, max_value in enumerate(stat_genetic['max']):\n",
        "  if max_value > threshold:\n",
        "    best_individuals.append(stat_genetic['best_individuals'][i])\n",
        "    best_individuals_indeces.append(i)\n",
        "\n",
        "# print selected individuals\n",
        "print('\\nindividuals selected')\n",
        "for individual in best_individuals:\n",
        "  print(individual)\n",
        "\n",
        "# store best models and trainable parameters in a dictionary\n",
        "final_models_dict = {\n",
        "    'models': [],\n",
        "    'accuracy': [],\n",
        "    'trainable_params': []\n",
        "}\n",
        "\n",
        "# save accuracy values for best individuals selected\n",
        "for index in best_individuals_indeces:\n",
        "  final_models_dict['accuracy'].append(stat_genetic['max'][index])\n",
        "\n",
        "# create he associated CNN model to calculate the number of trainable parameters\n",
        "input_shape = (87, 128, 1)\n",
        "for selected_individual in best_individuals:\n",
        "  current_model = build_and_compile_model(selected_individual, input_shape, print_model=False)\n",
        "  trainable_parameters = np.sum([np.prod(v.get_shape()) for v in current_model.trainable_weights])\n",
        "  \n",
        "  final_models_dict['models'].append(selected_individual)\n",
        "  final_models_dict['trainable_params'].append(trainable_parameters)\n",
        "\n",
        "# print the dictionary\n",
        "for i in range(len(final_models_dict['models'])):\n",
        "  print('\\nmodel:', final_models_dict['models'][i], \n",
        "        '\\nparams:', final_models_dict['trainable_params'][i],\n",
        "        '\\naccuracy:', final_models_dict['accuracy'][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mntnQ8AbGAU",
        "outputId": "950add21-2cad-4606-b656-3b456947e31a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set: 48000\n",
            "test set: 16000 (guitar: les)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 87, 128, 10)       250       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 87, 128, 10)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 87, 128, 10)      40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 87, 128, 10)       2010      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 44, 128, 10)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 44, 128, 10)      40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 44, 128, 25)       3775      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 22, 64, 25)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 22, 64, 25)       100       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 22, 64, 5)         5255      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 22, 64, 5)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 22, 64, 5)        20        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 22, 64, 8)         488       \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 11, 32, 8)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 11, 32, 8)        32        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2816)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                56340     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 105       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,455\n",
            "Trainable params: 68,339\n",
            "Non-trainable params: 116\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 28s 37ms/step - loss: 0.4977 - accuracy: 0.3157 - val_loss: 0.2512 - val_accuracy: 0.3244\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.2435 - accuracy: 0.4139 - val_loss: 0.0972 - val_accuracy: 0.4798\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 25s 34ms/step - loss: 0.1679 - accuracy: 0.4222 - val_loss: 0.1455 - val_accuracy: 0.2613\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.1333 - accuracy: 0.3802 - val_loss: 0.1083 - val_accuracy: 0.2944\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.1138 - accuracy: 0.3630 - val_loss: 0.0999 - val_accuracy: 0.3453\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.1072 - accuracy: 0.3353 - val_loss: 0.0575 - val_accuracy: 0.2980\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0973 - accuracy: 0.3179 - val_loss: 0.0768 - val_accuracy: 0.2891\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0942 - accuracy: 0.3019 - val_loss: 0.0594 - val_accuracy: 0.2506\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0895 - accuracy: 0.3040 - val_loss: 0.0842 - val_accuracy: 0.2618\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 26s 35ms/step - loss: 0.0876 - accuracy: 0.3057 - val_loss: 0.1235 - val_accuracy: 0.2747\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.0855 - accuracy: 0.3041 - val_loss: 0.1106 - val_accuracy: 0.3181\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.0812 - accuracy: 0.3032 - val_loss: 0.2251 - val_accuracy: 0.3131\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.0803 - accuracy: 0.2954 - val_loss: 0.1017 - val_accuracy: 0.2788\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.0787 - accuracy: 0.2977 - val_loss: 0.0605 - val_accuracy: 0.2941\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.0798 - accuracy: 0.2978 - val_loss: 0.0721 - val_accuracy: 0.3109\n",
            "sklearn accuracy:  0.914125\n"
          ]
        }
      ],
      "source": [
        "# select model with less train. parameters\n",
        "\n",
        "# selected_model_index = np.argmin(final_models_dict['trainable_params'])\n",
        "# selected_model = final_models_dict['models'][selected_model_index]\n",
        "# number_of_parameters = final_models_dict['trainable_params'][selected_model_index]\n",
        "# print('\\nselected model:', selected_model, '\\nnumber of parameters:', number_of_parameters)\n",
        "\n",
        "\n",
        "# try another model (best performance)\n",
        "selected_model = [5, 44, 7, 7, 2, 2, 57, 3, 4, 1, 2, 42, 2, 3, 2, 1, 27, 5, 3, 1, 1, 30, 6, 5, 1, 2, 2, 56, 0.09, 45, 0.09, 35, 0.27]\n",
        "fixed_model = [5, 10, 6, 4, 1, 1, 10, 4, 5, 2, 1, 25, 3, 5, 2, 2, 5, 6, 7, 1, 1, 8, 4, 3, 2, 2, 1, 20, 0.38, 9, 0.06, 20, 0.1]\n",
        "selected_model = fixed_model\n",
        "\n",
        "# destroy previous data to free space\n",
        "gc.collect()\n",
        "\n",
        "# load entire dataset\n",
        "data_complete = load_data_pickle(DATASET_PATH_MEL_SPEC_FIXED_PROVA)\n",
        "\n",
        "# new - test with 1 guitar as test set (ex: tele)\n",
        "X_train, X_test, y_train, y_test, N_train, N_test = prepare_dataset_for_guitar_cross_validation(data_complete, 'les')\n",
        "del data_complete\n",
        "\n",
        "# good_indiv_fixed_params = [5, 4, 5, 6, 2, 1, 14, 5, 6, 1, 2, 19, 3, 6, 2, 1, 29, 6, 4, 1, 1, 6, 4, 6, 2, 1, 1, 13, 0.08, 10, 0.43, 13, 0.21]\n",
        "\n",
        "# build the model\n",
        "input_shape = np.shape(X_train[1])\n",
        "best_model = build_and_compile_model(selected_model, input_shape)\n",
        "history = best_model.fit(X_train, y_train, epochs = 15, batch_size=64, validation_data = (X_test, y_test))\n",
        "#plot_history(history)\n",
        "\n",
        "# manual accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred = y_pred.round()\n",
        "sklearn_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"sklearn accuracy: \", sklearn_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdS5tRXYyRcs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "DECIMALS_CONFUSION_MATRIX = 3\n",
        "\n",
        "\n",
        "# --- STATISTICS considering segments as separate entities ---\n",
        "\n",
        "# accuracy considering the entire effects chain\n",
        "sklearn_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"ENTIRE CHAIN ACCURACY considering segments as separate entities\", sklearn_accuracy)\n",
        "\n",
        "\n",
        "# print precision recall and f1-score\n",
        "print('\\nCLASSIFICATION REPORT considering segments as separate entities\\n', classification_report(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    output_dict=False,\n",
        "    target_names=['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "))\n",
        "\n",
        "# plot confusion matrix for each effect\n",
        "def normalize_confusion_matrix(matrix):\n",
        "  return normalize(matrix, axis=1, norm='l1')\n",
        "\n",
        "\n",
        "def plot_confusio_matrix_multilabel(y_test, y_pred, normalize=True):\n",
        "  # get confusion matrix for each label and normalize\n",
        "  multilabel_cm = multilabel_confusion_matrix(y_test, y_pred)\n",
        "  if normalize:\n",
        "    multilabel_cm = np.array(list(map(normalize_confusion_matrix, multilabel_cm)))\n",
        "    multilabel_cm = np.around(multilabel_cm, decimals=DECIMALS_CONFUSION_MATRIX)\n",
        "  # create subplots\n",
        "  fig, ax = plt.subplots(2, 3, figsize=(13, 9))\n",
        "  # position of each spectrgram in the figure\n",
        "  indeces_config = [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1)]\n",
        "  labels = ['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "\n",
        "  for numeration, (index, confusion_matrix) in enumerate(zip(indeces_config, multilabel_cm)):\n",
        "    ax[index].matshow(confusion_matrix, cmap=plt.cm.Blues, alpha=0.5)\n",
        "    for i in range(confusion_matrix.shape[0]):\n",
        "      for j in range(confusion_matrix.shape[1]):\n",
        "          ax[index].text(x=j, y=i, s=confusion_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        "          ax[index].set_title(labels[numeration], size='xx-large')\n",
        "          ax[index].set_xlabel('predicted label')\n",
        "          ax[index].set_ylabel('true label')\n",
        "  plt.show()\n",
        "\n",
        "print('CONFUSION MATRICES considering segments as separate entities')\n",
        "plot_confusio_matrix_multilabel(y_test, y_pred, normalize=True)\n",
        "\n",
        "\n",
        "# --- STATISTICS considering fusing the output of each segment ---\n",
        "\n",
        "\n",
        "# verify that the segments order is correct\n",
        "count_correct_audio_files=0\n",
        "for index in range(len(y_test)):\n",
        "  if N_test[index][-5:] == 'segm1':\n",
        "    if N_test[index+1][-5:] == 'segm2':\n",
        "      if N_test[index+2][-5:] == 'segm3':\n",
        "        if N_test[index+3][-5:] == 'segm4':\n",
        "          if N_test[index+4][-5:] == 'segm5':\n",
        "            count_correct_audio_files +=1      \n",
        "print(\"correct segment sequence (should be 3200):\", count_correct_audio_files)\n",
        "\n",
        "# verify that the y_test and N_names correspond\n",
        "correct_correspondecies = 0\n",
        "for index in range(len(y_test)):\n",
        "  if N_test[index][-12:-7] == '{}{}{}{}{}'.format(*y_test[index]):\n",
        "    correct_correspondecies+=1\n",
        "print(\"correct correspondance of names and labels (should be 16000):\", correct_correspondecies)\n",
        "\n",
        "\n",
        "def get_correct_answer_for_5_segments(y_pred, index):\n",
        "  y_majority_vote = []  \n",
        "  # consider the vote for each label (0, 1, 2, 3, 4)\n",
        "  for label in range(5):    \n",
        "    # create a vector with the answer of each of the 5 segments for a single class\n",
        "    answer_of_each_segment = [y_pred[index+s][label] for s in range(5)]    \n",
        "    # get the mean to get the most voted answer\n",
        "    result = np.mean(answer_of_each_segment)\n",
        "    if result > 0.5:\n",
        "      y_majority_vote.append(1)\n",
        "    else:\n",
        "      y_majority_vote.append(0)\n",
        "  return y_majority_vote\n",
        "  \n",
        "\n",
        "def get_y_pred_fusing_segment_results(y_pred, N_test):\n",
        "  y_pred_audio = []\n",
        "  for index in range(len(y_pred)):\n",
        "    if N_test[index][-5:] == 'segm1':      \n",
        "      y_pred_audio.append(get_correct_answer_for_5_segments(y_pred, index))  \n",
        "  return y_pred_audio\n",
        "\n",
        "\n",
        "def get_y_true_fusing_segment_resuls(y_test, N_test):\n",
        "  y_test_audio = []\n",
        "  for index in range(len(y_test)):\n",
        "    # consider only the value of segm1 (which is the same if segm2, 3, 4, 4)\n",
        "    if N_test[index][-5:] == 'segm1':\n",
        "      y_test_audio.append(y_test[index]) \n",
        "  return y_test_audio\n",
        "\n",
        "# compute the majority vote\n",
        "y_pred_audio = get_y_pred_fusing_segment_results(y_pred, N_test)\n",
        "y_test_audio = get_y_pred_fusing_segment_results(y_test, N_test)\n",
        "\n",
        "# accuracy considering the entire effects chain\n",
        "sklearn_accuracy_audio = accuracy_score(y_test_audio, y_pred_audio)\n",
        "print(\"\\n\\nENTIRE CHAIN ACCURACY after majority vote\", sklearn_accuracy_audio)\n",
        "\n",
        "print('\\nCLASSIFICATION REPORT after majority vote\\n', classification_report(\n",
        "    y_test_audio,\n",
        "    y_pred_audio,\n",
        "    output_dict=False,\n",
        "    target_names=['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "))\n",
        "\n",
        "# plot confusion matrix for each effect\n",
        "print('CONFUSION MATRICES after majority vote')\n",
        "plot_confusio_matrix_multilabel(y_test_audio, y_pred_audio, normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Faco9bZ5TDVZ"
      },
      "source": [
        "### CLASSIFICATION, STATISTICS AND PLOTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zk3PuFVTOa5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import json\n",
        "import os\n",
        "from pprint import pprint\n",
        "\n",
        "# output path\n",
        "ROOTH = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/'\n",
        "EFFECTS = ['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "GUITARS = ['les', 'prs','str', 'tele']\n",
        "\n",
        "# dataset \n",
        "dataset_1 = DATASET_PATH_MEL_SPEC_FIXED\n",
        "dataset_2 = DATASET_PATH_MEL_SPEC_PARAM\n",
        "dataset_3 = DATASET_PATH_MEL_SPEC_POSITION\n",
        "\n",
        "DATASET_PATH = dataset_1\n",
        "dataset_number = 1\n",
        "\n",
        "# individual \n",
        "#individual_fixed_old = [5, 10, 6, 4, 1, 1, 10, 4, 5, 2, 1, 25, 3, 5, 2, 2, 5, 6, 7, 1, 1, 8, 4, 3, 2, 2, 1, 20, 0.38, 9, 0.06, 20, 0.1]\n",
        "#ind_pos_old = [5, 16, 4, 4, 1, 1, 22, 3, 6, 2, 2, 28, 7, 4, 2, 2, 22, 2, 5, 1, 2, 28, 3, 5, 2, 2, 2, 28, 0.21, 13, 0.03, 38, 0.43]\n",
        "\n",
        "individual_fixed =    [5, 20, 5, 2, 2, 1,  9, 6, 6, 2, 1, 22, 3, 3, 2, 1, 19, 4, 5, 2, 2,  4, 7, 7, 2, 1, 2, 14, 0.02, 28, 0.11, 32, 0.01]\n",
        "individual_params =   [5, 26, 3, 2, 2, 2, 18, 6, 3, 1, 1, 42, 4, 6, 2, 1, 38, 2, 7, 1, 2, 12, 6, 3, 2, 2, 2, 39, 0.19, 43, 0.01, 40, 0.07]\n",
        "individual_position = [5, 51, 7, 3, 2, 2, 19, 2, 3, 1, 2, 27, 2, 3, 2, 1, 16, 6, 7, 2, 2, 16, 2, 3, 1, 2, 1, 27, 0.05, 22, 0.26, 33, 0.22]\n",
        "\n",
        "\n",
        "INDIVIDUAL = individual_fixed\n",
        "\n",
        "# FUNCTIONS NECESSARY FOR COMPUTING MAYORITY VOTE\n",
        "\n",
        "def get_correct_answer_for_5_segments(y_pred, index):\n",
        "  y_majority_vote = []  \n",
        "  # consider the vote for each label (0, 1, 2, 3, 4)\n",
        "  for label in range(5):    \n",
        "    # create a vector with the answer of each of the 5 segments for a single class\n",
        "    answer_of_each_segment = [y_pred[index+s][label] for s in range(5)]    \n",
        "    # get the mean to get the most voted answer\n",
        "    result = np.mean(answer_of_each_segment)\n",
        "    if result > 0.5:\n",
        "      y_majority_vote.append(1)\n",
        "    else:\n",
        "      y_majority_vote.append(0)\n",
        "  return y_majority_vote\n",
        "  \n",
        "def get_y_pred_fusing_segment_results(y_pred, N_test):\n",
        "  y_pred_audio = []\n",
        "  for index in range(len(y_pred)):\n",
        "    if N_test[index][-5:] == 'segm1':      \n",
        "      y_pred_audio.append(get_correct_answer_for_5_segments(y_pred, index))  \n",
        "  return y_pred_audio\n",
        "\n",
        "def get_y_true_fusing_segment_resuls(y_test, N_test):\n",
        "  y_test_audio = []\n",
        "  for index in range(len(y_test)):\n",
        "    # consider only the value of segm1 (which is the same if segm2, 3, 4, 5)\n",
        "    if N_test[index][-5:] == 'segm1':\n",
        "      y_test_audio.append(y_test[index]) \n",
        "  return y_test_audio\n",
        "\n",
        "\n",
        "def evaluate_model_with_one_guitar_as_test(best_individual, test_guitar, dataset_path, dataset_number, repetitions=3):\n",
        "  # load dataset and divide train (3 guitars) and test (test_guitar)\n",
        "  data_complete = load_data_pickle(dataset_path)\n",
        "  X_train, X_test, y_train, y_test, N_train, N_test = prepare_dataset_for_guitar_cross_validation(data_complete, test_guitar)\n",
        "  del data_complete\n",
        "  # get input shape for model creation: (87, 128, 1)\n",
        "  input_shape = np.shape(X_train[0])\n",
        "  # store classification_reports\n",
        "  classification_reports = []\n",
        "\n",
        "  for i in range(repetitions):\n",
        "    print(f\"({i+1}/{repetitions})\")\n",
        "    # build and train the model\n",
        "    model = build_and_compile_model(best_individual, input_shape)\n",
        "    history = history = model.fit(X_train, y_train, epochs = 15, batch_size=64, validation_data=(X_test, y_test))\n",
        "    # get accuracy. sample correct iff all elements are corrects 10111 -> 10111 (ok)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = y_pred.round()\n",
        "    # NEW - include majority vote\n",
        "    y_pred_audio = get_y_pred_fusing_segment_results(y_pred, N_test)\n",
        "    y_test_audio = get_y_pred_fusing_segment_results(y_test, N_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test_audio, y_pred_audio)\n",
        "    print('accuracy:', accuracy)\n",
        "    # get classification_report\n",
        "    class_report = classification_report(y_test_audio,\n",
        "                                         y_pred_audio,\n",
        "                                         output_dict=True,\n",
        "                                         target_names=['overdrive', 'chorus', 'tremolo', 'delay', 'reverb'])\n",
        "    print(class_report)\n",
        "    classification_reports.append(class_report)\n",
        "\n",
        "  # save statistics\n",
        "  save_path = ROOTH + f'statistics__dataset_{dataset_number}__guitar_{test_guitar}__runs_{repetitions}.json'\n",
        "  with open(save_path, 'w') as f:\n",
        "    json.dump(classification_reports, f, indent=4)\n",
        "\n",
        "  return classification_reports\n",
        "\n",
        "# from statistics extract only f1-scores for each effect\n",
        "def get_f1_value_for_each_effect_single_guitar(classification_reports):\n",
        "  f1_scores = {'overdrive':[], 'chorus':[], 'tremolo':[], 'delay':[], 'reverb':[]}\n",
        "  for run in classification_reports:\n",
        "    for effect in EFFECTS:      \n",
        "      effect_value = run[effect]['f1-score']\n",
        "      f1_scores[effect].append(effect_value)\n",
        "  return f1_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAVKTc7-rFO9",
        "outputId": "50d30d1d-1c29-4760-8048-37312a932ac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set: 48000\n",
            "test set: 16000 (guitar: les)\n",
            "(1/3)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 44, 128, 20)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 44, 128, 20)      80        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 22, 128, 9)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 22, 128, 9)       36        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 11, 128, 22)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 11, 128, 22)      88        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 64, 19)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 6, 64, 19)        76        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 3, 64, 4)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 3, 64, 4)         16        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 768)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 14)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 28)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 35s 34ms/step - loss: 0.3691 - accuracy: 0.2882 - val_loss: 0.2373 - val_accuracy: 0.4229\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1704 - accuracy: 0.4533 - val_loss: 0.3176 - val_accuracy: 0.5722\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0630 - accuracy: 0.4897 - val_loss: 0.2528 - val_accuracy: 0.7103\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0391 - accuracy: 0.5137 - val_loss: 0.6283 - val_accuracy: 0.6000\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0304 - accuracy: 0.5429 - val_loss: 0.1121 - val_accuracy: 0.3596\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0257 - accuracy: 0.5550 - val_loss: 0.4431 - val_accuracy: 0.6212\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0222 - accuracy: 0.5672 - val_loss: 0.1400 - val_accuracy: 0.6564\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0197 - accuracy: 0.5726 - val_loss: 0.4155 - val_accuracy: 0.6862\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0169 - accuracy: 0.5664 - val_loss: 0.1345 - val_accuracy: 0.6518\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0172 - accuracy: 0.5760 - val_loss: 0.0896 - val_accuracy: 0.4894\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0155 - accuracy: 0.5666 - val_loss: 0.3074 - val_accuracy: 0.7319\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0140 - accuracy: 0.6033 - val_loss: 0.4169 - val_accuracy: 0.4324\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0138 - accuracy: 0.5964 - val_loss: 0.1366 - val_accuracy: 0.7133\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0125 - accuracy: 0.6249 - val_loss: 0.2204 - val_accuracy: 0.7089\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0131 - accuracy: 0.5888 - val_loss: 0.0791 - val_accuracy: 0.6568\n",
            "accuracy: 0.9734375\n",
            "{'overdrive': {'precision': 0.9710591133004927, 'recall': 0.985625, 'f1-score': 0.978287841191067, 'support': 1600}, 'chorus': {'precision': 0.9987515605493134, 'recall': 1.0, 'f1-score': 0.9993753903810119, 'support': 1600}, 'tremolo': {'precision': 0.9993753903810119, 'recall': 1.0, 'f1-score': 0.999687597625742, 'support': 1600}, 'delay': {'precision': 0.9987429289754871, 'recall': 0.993125, 'f1-score': 0.9959260419931056, 'support': 1600}, 'reverb': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1600}, 'micro avg': {'precision': 0.9935145921676228, 'recall': 0.99575, 'f1-score': 0.9946310400799102, 'support': 8000}, 'macro avg': {'precision': 0.9935857986412611, 'recall': 0.9957499999999999, 'f1-score': 0.9946553742381854, 'support': 8000}, 'weighted avg': {'precision': 0.993585798641261, 'recall': 0.99575, 'f1-score': 0.9946553742381853, 'support': 8000}, 'samples avg': {'precision': 0.9628072916666668, 'recall': 0.96375, 'f1-score': 0.9622958829365079, 'support': 8000}}\n",
            "(2/3)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 44, 128, 20)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 44, 128, 20)      80        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 22, 128, 9)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 22, 128, 9)       36        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 11, 128, 22)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 11, 128, 22)      88        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 6, 64, 19)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 6, 64, 19)        76        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 3, 64, 4)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 3, 64, 4)         16        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 14)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 28)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.3604 - accuracy: 0.3388 - val_loss: 0.2562 - val_accuracy: 0.5133\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1965 - accuracy: 0.4612 - val_loss: 0.2185 - val_accuracy: 0.5591\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1369 - accuracy: 0.4872 - val_loss: 0.1364 - val_accuracy: 0.4277\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0622 - accuracy: 0.4811 - val_loss: 0.1016 - val_accuracy: 0.5219\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0416 - accuracy: 0.4716 - val_loss: 0.1036 - val_accuracy: 0.5365\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0312 - accuracy: 0.4731 - val_loss: 0.2411 - val_accuracy: 0.6569\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0282 - accuracy: 0.4764 - val_loss: 0.0853 - val_accuracy: 0.5661\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0257 - accuracy: 0.4680 - val_loss: 0.1420 - val_accuracy: 0.3474\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0226 - accuracy: 0.4704 - val_loss: 0.1397 - val_accuracy: 0.4922\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0203 - accuracy: 0.4655 - val_loss: 0.1407 - val_accuracy: 0.5237\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0189 - accuracy: 0.4612 - val_loss: 1.0926 - val_accuracy: 0.2706\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0174 - accuracy: 0.4588 - val_loss: 0.1982 - val_accuracy: 0.5478\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0159 - accuracy: 0.4601 - val_loss: 0.1233 - val_accuracy: 0.3912\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0154 - accuracy: 0.4654 - val_loss: 0.0907 - val_accuracy: 0.3879\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0152 - accuracy: 0.4385 - val_loss: 0.1422 - val_accuracy: 0.4627\n",
            "accuracy: 0.8953125\n",
            "{'overdrive': {'precision': 0.8436671966083731, 'recall': 0.995, 'f1-score': 0.9131058216231717, 'support': 1600}, 'chorus': {'precision': 0.9975062344139651, 'recall': 1.0, 'f1-score': 0.9987515605493134, 'support': 1600}, 'tremolo': {'precision': 0.9968827930174564, 'recall': 0.999375, 'f1-score': 0.99812734082397, 'support': 1600}, 'delay': {'precision': 0.9846153846153847, 'recall': 1.0, 'f1-score': 0.9922480620155039, 'support': 1600}, 'reverb': {'precision': 1.0, 'recall': 0.99875, 'f1-score': 0.9993746091307067, 'support': 1600}, 'micro avg': {'precision': 0.9604472228901179, 'recall': 0.998625, 'f1-score': 0.9791641132491726, 'support': 8000}, 'macro avg': {'precision': 0.9645343217310358, 'recall': 0.998625, 'f1-score': 0.980321478828533, 'support': 8000}, 'weighted avg': {'precision': 0.9645343217310358, 'recall': 0.998625, 'f1-score': 0.9803214788285332, 'support': 8000}, 'samples avg': {'precision': 0.9367656249999999, 'recall': 0.9671614583333334, 'f1-score': 0.9482127976190478, 'support': 8000}}\n",
            "(3/3)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 44, 128, 20)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 44, 128, 20)      80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 22, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 22, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 11, 128, 22)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 11, 128, 22)      88        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 6, 64, 19)        0         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 6, 64, 19)        76        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 3, 64, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 3, 64, 4)         16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 14)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 28)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.3622 - accuracy: 0.2799 - val_loss: 0.2946 - val_accuracy: 0.4773\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1886 - accuracy: 0.3590 - val_loss: 0.2069 - val_accuracy: 0.2904\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.1672 - accuracy: 0.3969 - val_loss: 0.5426 - val_accuracy: 0.6378\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.1596 - accuracy: 0.4210 - val_loss: 0.1810 - val_accuracy: 0.3800\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.1465 - accuracy: 0.4490 - val_loss: 0.2250 - val_accuracy: 0.4904\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0889 - accuracy: 0.4569 - val_loss: 0.1099 - val_accuracy: 0.4782\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0383 - accuracy: 0.4849 - val_loss: 0.1393 - val_accuracy: 0.4614\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0272 - accuracy: 0.5230 - val_loss: 0.1668 - val_accuracy: 0.5680\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0235 - accuracy: 0.5082 - val_loss: 0.1508 - val_accuracy: 0.5835\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0211 - accuracy: 0.5227 - val_loss: 0.1665 - val_accuracy: 0.4301\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0200 - accuracy: 0.5123 - val_loss: 0.1245 - val_accuracy: 0.5754\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0182 - accuracy: 0.5216 - val_loss: 0.1119 - val_accuracy: 0.4446\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0169 - accuracy: 0.5232 - val_loss: 0.0983 - val_accuracy: 0.6496\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0168 - accuracy: 0.5206 - val_loss: 0.2999 - val_accuracy: 0.6271\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0153 - accuracy: 0.5374 - val_loss: 0.1472 - val_accuracy: 0.5977\n",
            "accuracy: 0.9403125\n",
            "{'overdrive': {'precision': 0.93935790725327, 'recall': 0.9875, 'f1-score': 0.9628275441803779, 'support': 1600}, 'chorus': {'precision': 0.9987515605493134, 'recall': 1.0, 'f1-score': 0.9993753903810119, 'support': 1600}, 'tremolo': {'precision': 1.0, 'recall': 0.99875, 'f1-score': 0.9993746091307067, 'support': 1600}, 'delay': {'precision': 0.963275135460566, 'recall': 1.0, 'f1-score': 0.9812940815700706, 'support': 1600}, 'reverb': {'precision': 1.0, 'recall': 0.99, 'f1-score': 0.9949748743718593, 'support': 1600}, 'micro avg': {'precision': 0.9796973052787006, 'recall': 0.99525, 'f1-score': 0.9874124139641595, 'support': 8000}, 'macro avg': {'precision': 0.9802769206526298, 'recall': 0.9952500000000001, 'f1-score': 0.9875692999268052, 'support': 8000}, 'weighted avg': {'precision': 0.9802769206526298, 'recall': 0.99525, 'f1-score': 0.9875692999268053, 'support': 8000}, 'samples avg': {'precision': 0.9514427083333333, 'recall': 0.9643437499999998, 'f1-score': 0.9554756944444444, 'support': 8000}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set: 48000\n",
            "test set: 16000 (guitar: prs)\n",
            "(1/3)\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 44, 128, 20)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 44, 128, 20)      80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 22, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 22, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 11, 128, 22)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 11, 128, 22)      88        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 6, 64, 19)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 6, 64, 19)        76        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 3, 64, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 3, 64, 4)         16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 14)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 28)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 0.3868 - accuracy: 0.2478 - val_loss: 0.2592 - val_accuracy: 0.3408\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1939 - accuracy: 0.3832 - val_loss: 0.1777 - val_accuracy: 0.4199\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.1681 - accuracy: 0.3908 - val_loss: 0.1727 - val_accuracy: 0.4476\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1597 - accuracy: 0.3867 - val_loss: 0.1756 - val_accuracy: 0.3964\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1563 - accuracy: 0.3945 - val_loss: 0.1744 - val_accuracy: 0.4266\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1520 - accuracy: 0.4147 - val_loss: 0.1836 - val_accuracy: 0.4731\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1505 - accuracy: 0.3947 - val_loss: 0.1788 - val_accuracy: 0.2956\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1499 - accuracy: 0.3951 - val_loss: 0.1757 - val_accuracy: 0.3769\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1492 - accuracy: 0.3939 - val_loss: 0.1709 - val_accuracy: 0.2934\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1474 - accuracy: 0.3956 - val_loss: 0.1780 - val_accuracy: 0.3788\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1360 - accuracy: 0.4197 - val_loss: 0.1153 - val_accuracy: 0.4904\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0618 - accuracy: 0.4449 - val_loss: 0.0573 - val_accuracy: 0.4526\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0309 - accuracy: 0.4304 - val_loss: 0.0523 - val_accuracy: 0.3906\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0223 - accuracy: 0.3945 - val_loss: 0.0404 - val_accuracy: 0.3959\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0190 - accuracy: 0.3639 - val_loss: 0.0593 - val_accuracy: 0.2500\n",
            "accuracy: 0.98625\n",
            "{'overdrive': {'precision': 1.0, 'recall': 0.985, 'f1-score': 0.9924433249370278, 'support': 1600}, 'chorus': {'precision': 0.9975062344139651, 'recall': 1.0, 'f1-score': 0.9987515605493134, 'support': 1600}, 'tremolo': {'precision': 1.0, 'recall': 0.9975, 'f1-score': 0.9987484355444306, 'support': 1600}, 'delay': {'precision': 0.9919404835709857, 'recall': 1.0, 'f1-score': 0.9959539371304077, 'support': 1600}, 'reverb': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1600}, 'micro avg': {'precision': 0.99787207410189, 'recall': 0.9965, 'f1-score': 0.9971855650759898, 'support': 8000}, 'macro avg': {'precision': 0.9978893435969901, 'recall': 0.9964999999999999, 'f1-score': 0.9971794516322359, 'support': 8000}, 'weighted avg': {'precision': 0.9978893435969901, 'recall': 0.9965, 'f1-score': 0.997179451632236, 'support': 8000}, 'samples avg': {'precision': 0.96515625, 'recall': 0.9644947916666666, 'f1-score': 0.9642524801587302, 'support': 8000}}\n",
            "(2/3)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 44, 128, 20)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 44, 128, 20)      80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 22, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 22, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 11, 128, 22)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 11, 128, 22)      88        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 6, 64, 19)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 6, 64, 19)        76        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 3, 64, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 3, 64, 4)         16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 14)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 28)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.3880 - accuracy: 0.2582 - val_loss: 0.2352 - val_accuracy: 0.2834\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1853 - accuracy: 0.4283 - val_loss: 0.2409 - val_accuracy: 0.3866\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0758 - accuracy: 0.4420 - val_loss: 0.0642 - val_accuracy: 0.4773\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0458 - accuracy: 0.4730 - val_loss: 0.0756 - val_accuracy: 0.4846\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0345 - accuracy: 0.4942 - val_loss: 0.0529 - val_accuracy: 0.5156\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0282 - accuracy: 0.5068 - val_loss: 0.0884 - val_accuracy: 0.4297\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0252 - accuracy: 0.5094 - val_loss: 0.0600 - val_accuracy: 0.5074\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0219 - accuracy: 0.5128 - val_loss: 0.0508 - val_accuracy: 0.5205\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0191 - accuracy: 0.5167 - val_loss: 0.0779 - val_accuracy: 0.4586\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0175 - accuracy: 0.5036 - val_loss: 0.0506 - val_accuracy: 0.5182\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0159 - accuracy: 0.4915 - val_loss: 0.0603 - val_accuracy: 0.4821\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0145 - accuracy: 0.4858 - val_loss: 0.0473 - val_accuracy: 0.5219\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0137 - accuracy: 0.4824 - val_loss: 0.0471 - val_accuracy: 0.4841\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0131 - accuracy: 0.4815 - val_loss: 0.0667 - val_accuracy: 0.4723\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0120 - accuracy: 0.4741 - val_loss: 0.0584 - val_accuracy: 0.4774\n",
            "accuracy: 0.989375\n",
            "{'overdrive': {'precision': 0.9943538268506901, 'recall': 0.990625, 'f1-score': 0.9924859110832811, 'support': 1600}, 'chorus': {'precision': 0.9981285090455396, 'recall': 1.0, 'f1-score': 0.9990633780830471, 'support': 1600}, 'tremolo': {'precision': 1.0, 'recall': 0.998125, 'f1-score': 0.9990616202690022, 'support': 1600}, 'delay': {'precision': 0.99812734082397, 'recall': 0.999375, 'f1-score': 0.9987507807620237, 'support': 1600}, 'reverb': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1600}, 'micro avg': {'precision': 0.9981240620310156, 'recall': 0.997625, 'f1-score': 0.9978744686171543, 'support': 8000}, 'macro avg': {'precision': 0.99812193534404, 'recall': 0.997625, 'f1-score': 0.9978723380394708, 'support': 8000}, 'weighted avg': {'precision': 0.9981219353440399, 'recall': 0.997625, 'f1-score': 0.9978723380394708, 'support': 8000}, 'samples avg': {'precision': 0.9670885416666667, 'recall': 0.9668541666666667, 'f1-score': 0.9665634920634922, 'support': 8000}}\n",
            "(3/3)\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_25 (Conv2D)          (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 44, 128, 20)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 44, 128, 20)      80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 22, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 22, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 11, 128, 22)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 11, 128, 22)      88        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 6, 64, 19)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 6, 64, 19)        76        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 3, 64, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 3, 64, 4)         16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 14)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 28)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.3641 - accuracy: 0.2861 - val_loss: 0.2451 - val_accuracy: 0.3575\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1890 - accuracy: 0.4472 - val_loss: 0.1947 - val_accuracy: 0.3338\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1681 - accuracy: 0.4817 - val_loss: 0.1784 - val_accuracy: 0.4376\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1604 - accuracy: 0.4985 - val_loss: 0.1784 - val_accuracy: 0.4804\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1556 - accuracy: 0.5091 - val_loss: 0.2607 - val_accuracy: 0.5521\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1547 - accuracy: 0.5284 - val_loss: 0.1726 - val_accuracy: 0.5706\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1311 - accuracy: 0.5131 - val_loss: 0.1312 - val_accuracy: 0.3552\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0453 - accuracy: 0.5093 - val_loss: 0.1014 - val_accuracy: 0.4163\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0284 - accuracy: 0.5337 - val_loss: 0.0400 - val_accuracy: 0.5585\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0226 - accuracy: 0.5514 - val_loss: 0.0471 - val_accuracy: 0.5752\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0193 - accuracy: 0.5677 - val_loss: 0.0648 - val_accuracy: 0.5964\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0173 - accuracy: 0.5671 - val_loss: 0.0443 - val_accuracy: 0.5814\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0166 - accuracy: 0.5696 - val_loss: 0.0656 - val_accuracy: 0.4705\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0155 - accuracy: 0.5724 - val_loss: 0.0765 - val_accuracy: 0.6075\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0141 - accuracy: 0.5736 - val_loss: 0.0360 - val_accuracy: 0.6268\n",
            "accuracy: 0.9971875\n",
            "{'overdrive': {'precision': 0.999375, 'recall': 0.999375, 'f1-score': 0.999375, 'support': 1600}, 'chorus': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1600}, 'tremolo': {'precision': 1.0, 'recall': 0.999375, 'f1-score': 0.9996874023132228, 'support': 1600}, 'delay': {'precision': 0.9968847352024922, 'recall': 1.0, 'f1-score': 0.9984399375975038, 'support': 1600}, 'reverb': {'precision': 0.9993753903810119, 'recall': 1.0, 'f1-score': 0.999687597625742, 'support': 1600}, 'micro avg': {'precision': 0.9991255465334166, 'recall': 0.99975, 'f1-score': 0.9994376757263355, 'support': 8000}, 'macro avg': {'precision': 0.9991270251167009, 'recall': 0.99975, 'f1-score': 0.9994379875072937, 'support': 8000}, 'weighted avg': {'precision': 0.9991270251167008, 'recall': 0.99975, 'f1-score': 0.9994379875072936, 'support': 8000}, 'samples avg': {'precision': 0.9680208333333333, 'recall': 0.9685833333333334, 'f1-score': 0.9681944444444445, 'support': 8000}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set: 48000\n",
            "test set: 16000 (guitar: str)\n",
            "(1/3)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 44, 128, 20)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 44, 128, 20)      80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 22, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 22, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 11, 128, 22)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 11, 128, 22)      88        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 6, 64, 19)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 6, 64, 19)        76        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPoolin  (None, 3, 64, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 3, 64, 4)         16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 14)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 28)                0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 0.3679 - accuracy: 0.3500 - val_loss: 0.2210 - val_accuracy: 0.5210\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1728 - accuracy: 0.4660 - val_loss: 0.1210 - val_accuracy: 0.5429\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0697 - accuracy: 0.4329 - val_loss: 0.1194 - val_accuracy: 0.3069\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0438 - accuracy: 0.4184 - val_loss: 0.1081 - val_accuracy: 0.3068\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0346 - accuracy: 0.4157 - val_loss: 0.3580 - val_accuracy: 0.6134\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0276 - accuracy: 0.3950 - val_loss: 0.1128 - val_accuracy: 0.3087\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0259 - accuracy: 0.3950 - val_loss: 0.1054 - val_accuracy: 0.4836\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0212 - accuracy: 0.3910 - val_loss: 0.0638 - val_accuracy: 0.3780\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0199 - accuracy: 0.3969 - val_loss: 0.0802 - val_accuracy: 0.3429\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0186 - accuracy: 0.3810 - val_loss: 0.1349 - val_accuracy: 0.3489\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0159 - accuracy: 0.3617 - val_loss: 0.1485 - val_accuracy: 0.4161\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0161 - accuracy: 0.3584 - val_loss: 0.0881 - val_accuracy: 0.3211\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0142 - accuracy: 0.3596 - val_loss: 0.1206 - val_accuracy: 0.2914\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0132 - accuracy: 0.3424 - val_loss: 0.0778 - val_accuracy: 0.2756\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0132 - accuracy: 0.3425 - val_loss: 0.1177 - val_accuracy: 0.2358\n",
            "accuracy: 0.9525\n",
            "{'overdrive': {'precision': 1.0, 'recall': 0.9325, 'f1-score': 0.9650711513583441, 'support': 1600}, 'chorus': {'precision': 0.9993753903810119, 'recall': 1.0, 'f1-score': 0.999687597625742, 'support': 1600}, 'tremolo': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1600}, 'delay': {'precision': 0.9864364981504316, 'recall': 1.0, 'f1-score': 0.9931719428926133, 'support': 1600}, 'reverb': {'precision': 0.9791921664626683, 'recall': 1.0, 'f1-score': 0.989486703772418, 'support': 1600}, 'micro avg': {'precision': 0.9928292867027299, 'recall': 0.9865, 'f1-score': 0.9896545237945953, 'support': 8000}, 'macro avg': {'precision': 0.9930008109988222, 'recall': 0.9865, 'f1-score': 0.9894834791298234, 'support': 8000}, 'weighted avg': {'precision': 0.9930008109988223, 'recall': 0.9865, 'f1-score': 0.9894834791298235, 'support': 8000}, 'samples avg': {'precision': 0.9624322916666667, 'recall': 0.9570104166666666, 'f1-score': 0.9581121031746034, 'support': 8000}}\n",
            "(2/3)\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_35 (Conv2D)          (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPoolin  (None, 44, 128, 20)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 44, 128, 20)      80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (None, 22, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, 22, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPoolin  (None, 11, 128, 22)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_37 (Bat  (None, 11, 128, 22)      88        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPoolin  (None, 6, 64, 19)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_38 (Bat  (None, 6, 64, 19)        76        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (None, 3, 64, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_39 (Bat  (None, 3, 64, 4)         16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 14)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 28)                0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.3100 - accuracy: 0.2951 - val_loss: 0.1219 - val_accuracy: 0.4301\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0822 - accuracy: 0.4079 - val_loss: 0.0613 - val_accuracy: 0.3910\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0526 - accuracy: 0.4395 - val_loss: 0.0862 - val_accuracy: 0.3808\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0382 - accuracy: 0.4544 - val_loss: 0.0476 - val_accuracy: 0.3966\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0312 - accuracy: 0.4516 - val_loss: 0.0706 - val_accuracy: 0.4431\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0275 - accuracy: 0.4337 - val_loss: 0.0605 - val_accuracy: 0.4469\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0218 - accuracy: 0.4429 - val_loss: 0.0665 - val_accuracy: 0.3809\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0209 - accuracy: 0.4268 - val_loss: 0.0599 - val_accuracy: 0.4002\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0196 - accuracy: 0.4369 - val_loss: 0.0853 - val_accuracy: 0.4327\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0191 - accuracy: 0.4523 - val_loss: 0.3093 - val_accuracy: 0.3319\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0163 - accuracy: 0.4622 - val_loss: 0.0741 - val_accuracy: 0.4489\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0149 - accuracy: 0.4683 - val_loss: 0.0736 - val_accuracy: 0.4336\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0145 - accuracy: 0.4654 - val_loss: 0.0644 - val_accuracy: 0.4774\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0136 - accuracy: 0.4552 - val_loss: 0.0603 - val_accuracy: 0.5176\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0133 - accuracy: 0.4809 - val_loss: 0.0775 - val_accuracy: 0.4105\n",
            "accuracy: 0.9815625\n",
            "{'overdrive': {'precision': 0.990642545227698, 'recall': 0.9925, 'f1-score': 0.9915704027474243, 'support': 1600}, 'chorus': {'precision': 0.9950217797137524, 'recall': 0.999375, 'f1-score': 0.9971936389148739, 'support': 1600}, 'tremolo': {'precision': 0.9993753903810119, 'recall': 1.0, 'f1-score': 0.999687597625742, 'support': 1600}, 'delay': {'precision': 0.9864364981504316, 'recall': 1.0, 'f1-score': 0.9931719428926133, 'support': 1600}, 'reverb': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1600}, 'micro avg': {'precision': 0.9942736213120876, 'recall': 0.998375, 'f1-score': 0.9963200898147571, 'support': 8000}, 'macro avg': {'precision': 0.9942952426945787, 'recall': 0.998375, 'f1-score': 0.9963247164361307, 'support': 8000}, 'weighted avg': {'precision': 0.9942952426945787, 'recall': 0.998375, 'f1-score': 0.9963247164361307, 'support': 8000}, 'samples avg': {'precision': 0.9640520833333334, 'recall': 0.9673333333333335, 'f1-score': 0.9649722222222222, 'support': 8000}}\n",
            "(3/3)\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 44, 128, 20)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_40 (Bat  (None, 44, 128, 20)      80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 22, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_41 (Bat  (None, 22, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_42 (MaxPoolin  (None, 11, 128, 22)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_42 (Bat  (None, 11, 128, 22)      88        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_43 (MaxPoolin  (None, 6, 64, 19)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_43 (Bat  (None, 6, 64, 19)        76        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_44 (MaxPoolin  (None, 3, 64, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_44 (Bat  (None, 3, 64, 4)         16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 14)                0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 28)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.3789 - accuracy: 0.2868 - val_loss: 0.3014 - val_accuracy: 0.4495\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1814 - accuracy: 0.3933 - val_loss: 0.1783 - val_accuracy: 0.3519\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0806 - accuracy: 0.3900 - val_loss: 0.0842 - val_accuracy: 0.2616\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0470 - accuracy: 0.3618 - val_loss: 0.1591 - val_accuracy: 0.3499\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0364 - accuracy: 0.3440 - val_loss: 0.1069 - val_accuracy: 0.2367\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0307 - accuracy: 0.3285 - val_loss: 0.1051 - val_accuracy: 0.3096\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0259 - accuracy: 0.3197 - val_loss: 0.2685 - val_accuracy: 0.3805\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0234 - accuracy: 0.3060 - val_loss: 0.2054 - val_accuracy: 0.2784\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0217 - accuracy: 0.3029 - val_loss: 0.0726 - val_accuracy: 0.3311\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0185 - accuracy: 0.3044 - val_loss: 0.7301 - val_accuracy: 0.2596\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0186 - accuracy: 0.3027 - val_loss: 0.2028 - val_accuracy: 0.2711\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0171 - accuracy: 0.3059 - val_loss: 0.1219 - val_accuracy: 0.2478\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0153 - accuracy: 0.3075 - val_loss: 0.0897 - val_accuracy: 0.2636\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0149 - accuracy: 0.2912 - val_loss: 0.0958 - val_accuracy: 0.2319\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0142 - accuracy: 0.2889 - val_loss: 0.1449 - val_accuracy: 0.2456\n",
            "accuracy: 0.96625\n",
            "{'overdrive': {'precision': 1.0, 'recall': 0.950625, 'f1-score': 0.9746876001281641, 'support': 1600}, 'chorus': {'precision': 0.9925558312655087, 'recall': 1.0, 'f1-score': 0.9962640099626401, 'support': 1600}, 'tremolo': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1600}, 'delay': {'precision': 0.9907120743034056, 'recall': 1.0, 'f1-score': 0.995334370139969, 'support': 1600}, 'reverb': {'precision': 0.9968847352024922, 'recall': 1.0, 'f1-score': 0.9984399375975038, 'support': 1600}, 'micro avg': {'precision': 0.9959763611215894, 'recall': 0.990125, 'f1-score': 0.9930420610543471, 'support': 8000}, 'macro avg': {'precision': 0.9960305281542812, 'recall': 0.9901250000000001, 'f1-score': 0.9929451835656554, 'support': 8000}, 'weighted avg': {'precision': 0.9960305281542813, 'recall': 0.990125, 'f1-score': 0.9929451835656554, 'support': 8000}, 'samples avg': {'precision': 0.9637916666666666, 'recall': 0.9587447916666667, 'f1-score': 0.9600017361111111, 'support': 8000}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set: 48000\n",
            "test set: 16000 (guitar: tele)\n",
            "(1/3)\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_45 (Conv2D)          (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d_45 (MaxPoolin  (None, 44, 128, 20)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_45 (Bat  (None, 44, 128, 20)      80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_46 (MaxPoolin  (None, 22, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_46 (Bat  (None, 22, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_47 (MaxPoolin  (None, 11, 128, 22)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_47 (Bat  (None, 11, 128, 22)      88        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_48 (MaxPoolin  (None, 6, 64, 19)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_48 (Bat  (None, 6, 64, 19)        76        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_49 (MaxPoolin  (None, 3, 64, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_49 (Bat  (None, 3, 64, 4)         16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 768)               0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 14)                0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 28)                0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 27s 35ms/step - loss: 0.3920 - accuracy: 0.2909 - val_loss: 0.6752 - val_accuracy: 0.1513\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1206 - accuracy: 0.4401 - val_loss: 0.0693 - val_accuracy: 0.4140\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0534 - accuracy: 0.4242 - val_loss: 0.0491 - val_accuracy: 0.3965\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0385 - accuracy: 0.4341 - val_loss: 0.0579 - val_accuracy: 0.3507\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0314 - accuracy: 0.4516 - val_loss: 0.0493 - val_accuracy: 0.5129\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0247 - accuracy: 0.4643 - val_loss: 0.0489 - val_accuracy: 0.4036\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0233 - accuracy: 0.4719 - val_loss: 0.0797 - val_accuracy: 0.5715\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0198 - accuracy: 0.4954 - val_loss: 0.1072 - val_accuracy: 0.5070\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0197 - accuracy: 0.5148 - val_loss: 0.0459 - val_accuracy: 0.4827\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0181 - accuracy: 0.5207 - val_loss: 0.5102 - val_accuracy: 0.2371\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0152 - accuracy: 0.5161 - val_loss: 0.1716 - val_accuracy: 0.2330\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0152 - accuracy: 0.5208 - val_loss: 0.3178 - val_accuracy: 0.2713\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0136 - accuracy: 0.5403 - val_loss: 0.1337 - val_accuracy: 0.3692\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0131 - accuracy: 0.5483 - val_loss: 1.3327 - val_accuracy: 0.1754\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0124 - accuracy: 0.5313 - val_loss: 0.0630 - val_accuracy: 0.4078\n",
            "accuracy: 0.986875\n",
            "{'overdrive': {'precision': 1.0, 'recall': 0.9925, 'f1-score': 0.9962358845671266, 'support': 1600}, 'chorus': {'precision': 0.9987515605493134, 'recall': 1.0, 'f1-score': 0.9993753903810119, 'support': 1600}, 'tremolo': {'precision': 0.9968827930174564, 'recall': 0.999375, 'f1-score': 0.99812734082397, 'support': 1600}, 'delay': {'precision': 0.9919404835709857, 'recall': 1.0, 'f1-score': 0.9959539371304077, 'support': 1600}, 'reverb': {'precision': 0.9937888198757764, 'recall': 1.0, 'f1-score': 0.9968847352024921, 'support': 1600}, 'micro avg': {'precision': 0.9962579518523138, 'recall': 0.998375, 'f1-score': 0.9973153524380345, 'support': 8000}, 'macro avg': {'precision': 0.9962727314027063, 'recall': 0.998375, 'f1-score': 0.9973154576210016, 'support': 8000}, 'weighted avg': {'precision': 0.9962727314027063, 'recall': 0.998375, 'f1-score': 0.9973154576210017, 'support': 8000}, 'samples avg': {'precision': 0.9654739583333334, 'recall': 0.9669791666666666, 'f1-score': 0.9656746031746033, 'support': 8000}}\n",
            "(2/3)\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_50 (Conv2D)          (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 44, 128, 20)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_50 (Bat  (None, 44, 128, 20)      80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_51 (MaxPoolin  (None, 22, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_51 (Bat  (None, 22, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_52 (MaxPoolin  (None, 11, 128, 22)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_52 (Bat  (None, 11, 128, 22)      88        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_53 (MaxPoolin  (None, 6, 64, 19)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_53 (Bat  (None, 6, 64, 19)        76        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_54 (MaxPoolin  (None, 3, 64, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_54 (Bat  (None, 3, 64, 4)         16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 768)               0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 14)                0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 28)                0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.3625 - accuracy: 0.3517 - val_loss: 0.2538 - val_accuracy: 0.6190\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1893 - accuracy: 0.5451 - val_loss: 0.1881 - val_accuracy: 0.6504\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1675 - accuracy: 0.6130 - val_loss: 0.1847 - val_accuracy: 0.6152\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1587 - accuracy: 0.6620 - val_loss: 0.1744 - val_accuracy: 0.7013\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1523 - accuracy: 0.6850 - val_loss: 0.1971 - val_accuracy: 0.6012\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1207 - accuracy: 0.6749 - val_loss: 0.1383 - val_accuracy: 0.5412\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0477 - accuracy: 0.6822 - val_loss: 0.1005 - val_accuracy: 0.7574\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0351 - accuracy: 0.6882 - val_loss: 0.0630 - val_accuracy: 0.7594\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0255 - accuracy: 0.7113 - val_loss: 0.0731 - val_accuracy: 0.7859\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0231 - accuracy: 0.7182 - val_loss: 0.4695 - val_accuracy: 0.4158\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0193 - accuracy: 0.7386 - val_loss: 0.0672 - val_accuracy: 0.7374\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0191 - accuracy: 0.7551 - val_loss: 0.0777 - val_accuracy: 0.7986\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0166 - accuracy: 0.7501 - val_loss: 0.0846 - val_accuracy: 0.6890\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0140 - accuracy: 0.7491 - val_loss: 0.1032 - val_accuracy: 0.7645\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0129 - accuracy: 0.7423 - val_loss: 0.0556 - val_accuracy: 0.8204\n",
            "accuracy: 0.9925\n",
            "{'overdrive': {'precision': 0.9937888198757764, 'recall': 1.0, 'f1-score': 0.9968847352024921, 'support': 1600}, 'chorus': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1600}, 'tremolo': {'precision': 0.9981285090455396, 'recall': 1.0, 'f1-score': 0.9990633780830471, 'support': 1600}, 'delay': {'precision': 0.9987507807620237, 'recall': 0.999375, 'f1-score': 0.9990627928772258, 'support': 1600}, 'reverb': {'precision': 0.9950248756218906, 'recall': 1.0, 'f1-score': 0.9975062344139651, 'support': 1600}, 'micro avg': {'precision': 0.9971328845674395, 'recall': 0.999875, 'f1-score': 0.9985020596679565, 'support': 8000}, 'macro avg': {'precision': 0.9971385970610461, 'recall': 0.9998750000000001, 'f1-score': 0.998503428115346, 'support': 8000}, 'weighted avg': {'precision': 0.9971385970610461, 'recall': 0.999875, 'f1-score': 0.9985034281153461, 'support': 8000}, 'samples avg': {'precision': 0.9666562500000001, 'recall': 0.96859375, 'f1-score': 0.9673789682539683, 'support': 8000}}\n",
            "(3/3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_55 (Conv2D)          (None, 87, 128, 20)       220       \n",
            "                                                                 \n",
            " max_pooling2d_55 (MaxPoolin  (None, 44, 128, 20)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_55 (Bat  (None, 44, 128, 20)      80        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (None, 44, 128, 9)        6489      \n",
            "                                                                 \n",
            " max_pooling2d_56 (MaxPoolin  (None, 22, 128, 9)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_56 (Bat  (None, 22, 128, 9)       36        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (None, 22, 128, 22)       1804      \n",
            "                                                                 \n",
            " max_pooling2d_57 (MaxPoolin  (None, 11, 128, 22)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_57 (Bat  (None, 11, 128, 22)      88        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (None, 11, 128, 19)       8379      \n",
            "                                                                 \n",
            " max_pooling2d_58 (MaxPoolin  (None, 6, 64, 19)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_58 (Bat  (None, 6, 64, 19)        76        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (None, 6, 64, 4)          3728      \n",
            "                                                                 \n",
            " max_pooling2d_59 (MaxPoolin  (None, 3, 64, 4)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_59 (Bat  (None, 3, 64, 4)         16        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 768)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 14)                10766     \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 14)                0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 28)                420       \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 28)                0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 5)                 145       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,247\n",
            "Trainable params: 32,099\n",
            "Non-trainable params: 148\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/15\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.3555 - accuracy: 0.2990 - val_loss: 0.2220 - val_accuracy: 0.3919\n",
            "Epoch 2/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1899 - accuracy: 0.4013 - val_loss: 0.3130 - val_accuracy: 0.2949\n",
            "Epoch 3/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.1684 - accuracy: 0.4143 - val_loss: 0.1913 - val_accuracy: 0.4972\n",
            "Epoch 4/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.1591 - accuracy: 0.4266 - val_loss: 0.2113 - val_accuracy: 0.3961\n",
            "Epoch 5/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1558 - accuracy: 0.4313 - val_loss: 0.2544 - val_accuracy: 0.5395\n",
            "Epoch 6/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.1546 - accuracy: 0.4371 - val_loss: 0.1728 - val_accuracy: 0.4322\n",
            "Epoch 7/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.1500 - accuracy: 0.4389 - val_loss: 0.2394 - val_accuracy: 0.4404\n",
            "Epoch 8/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.1496 - accuracy: 0.4224 - val_loss: 0.1819 - val_accuracy: 0.4239\n",
            "Epoch 9/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.1470 - accuracy: 0.4380 - val_loss: 0.1997 - val_accuracy: 0.4955\n",
            "Epoch 10/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0729 - accuracy: 0.4174 - val_loss: 0.0964 - val_accuracy: 0.3621\n",
            "Epoch 11/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0343 - accuracy: 0.3972 - val_loss: 0.1477 - val_accuracy: 0.4510\n",
            "Epoch 12/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0252 - accuracy: 0.3840 - val_loss: 0.0473 - val_accuracy: 0.3438\n",
            "Epoch 13/15\n",
            "750/750 [==============================] - 24s 31ms/step - loss: 0.0202 - accuracy: 0.3850 - val_loss: 0.0523 - val_accuracy: 0.3843\n",
            "Epoch 14/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0177 - accuracy: 0.3797 - val_loss: 0.0707 - val_accuracy: 0.4460\n",
            "Epoch 15/15\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0159 - accuracy: 0.3656 - val_loss: 0.0426 - val_accuracy: 0.3802\n",
            "accuracy: 0.99375\n",
            "{'overdrive': {'precision': 0.9925465838509316, 'recall': 0.99875, 'f1-score': 0.995638629283489, 'support': 1600}, 'chorus': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1600}, 'tremolo': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1600}, 'delay': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1600}, 'reverb': {'precision': 0.9962640099626401, 'recall': 1.0, 'f1-score': 0.9981285090455396, 'support': 1600}, 'micro avg': {'precision': 0.9977544910179641, 'recall': 0.99975, 'f1-score': 0.9987512487512487, 'support': 8000}, 'macro avg': {'precision': 0.9977621187627144, 'recall': 0.99975, 'f1-score': 0.9987534276658057, 'support': 8000}, 'weighted avg': {'precision': 0.9977621187627144, 'recall': 0.99975, 'f1-score': 0.9987534276658057, 'support': 8000}, 'samples avg': {'precision': 0.9665416666666666, 'recall': 0.96828125, 'f1-score': 0.9671686507936508, 'support': 8000}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# execute 3 run for each guitar\n",
        "for guitar in GUITARS:\n",
        "  class_reps = evaluate_model_with_one_guitar_as_test(INDIVIDUAL, guitar, DATASET_PATH, dataset_number, repetitions=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIfo04nUR29R",
        "outputId": "6c0b6b1b-004f-4225-f6e8-4218fab03d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'overdrive': {'precision': [0.9710591133004927,\n",
            "                             0.8436671966083731,\n",
            "                             0.93935790725327,\n",
            "                             1.0,\n",
            "                             0.9943538268506901,\n",
            "                             0.999375,\n",
            "                             1.0,\n",
            "                             0.990642545227698,\n",
            "                             1.0,\n",
            "                             1.0,\n",
            "                             0.9937888198757764,\n",
            "                             0.9925465838509316],\n",
            "               'recall': [0.985625,\n",
            "                          0.995,\n",
            "                          0.9875,\n",
            "                          0.985,\n",
            "                          0.990625,\n",
            "                          0.999375,\n",
            "                          0.9325,\n",
            "                          0.9925,\n",
            "                          0.950625,\n",
            "                          0.9925,\n",
            "                          1.0,\n",
            "                          0.99875],\n",
            "               'f1-score': [0.978287841191067,\n",
            "                            0.9131058216231717,\n",
            "                            0.9628275441803779,\n",
            "                            0.9924433249370278,\n",
            "                            0.9924859110832811,\n",
            "                            0.999375,\n",
            "                            0.9650711513583441,\n",
            "                            0.9915704027474243,\n",
            "                            0.9746876001281641,\n",
            "                            0.9962358845671266,\n",
            "                            0.9968847352024921,\n",
            "                            0.995638629283489],\n",
            "               'support': [1600,\n",
            "                           1600,\n",
            "                           1600,\n",
            "                           1600,\n",
            "                           1600,\n",
            "                           1600,\n",
            "                           1600,\n",
            "                           1600,\n",
            "                           1600,\n",
            "                           1600,\n",
            "                           1600,\n",
            "                           1600]},\n",
            " 'chorus': {'precision': [0.9987515605493134,\n",
            "                          0.9975062344139651,\n",
            "                          0.9987515605493134,\n",
            "                          0.9975062344139651,\n",
            "                          0.9981285090455396,\n",
            "                          1.0,\n",
            "                          0.9993753903810119,\n",
            "                          0.9950217797137524,\n",
            "                          0.9925558312655087,\n",
            "                          0.9987515605493134,\n",
            "                          1.0,\n",
            "                          1.0],\n",
            "            'recall': [1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       0.999375,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0],\n",
            "            'f1-score': [0.9993753903810119,\n",
            "                         0.9987515605493134,\n",
            "                         0.9993753903810119,\n",
            "                         0.9987515605493134,\n",
            "                         0.9990633780830471,\n",
            "                         1.0,\n",
            "                         0.999687597625742,\n",
            "                         0.9971936389148739,\n",
            "                         0.9962640099626401,\n",
            "                         0.9993753903810119,\n",
            "                         1.0,\n",
            "                         1.0],\n",
            "            'support': [1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600]},\n",
            " 'tremolo': {'precision': [0.9993753903810119,\n",
            "                           0.9968827930174564,\n",
            "                           1.0,\n",
            "                           1.0,\n",
            "                           1.0,\n",
            "                           1.0,\n",
            "                           1.0,\n",
            "                           0.9993753903810119,\n",
            "                           1.0,\n",
            "                           0.9968827930174564,\n",
            "                           0.9981285090455396,\n",
            "                           1.0],\n",
            "             'recall': [1.0,\n",
            "                        0.999375,\n",
            "                        0.99875,\n",
            "                        0.9975,\n",
            "                        0.998125,\n",
            "                        0.999375,\n",
            "                        1.0,\n",
            "                        1.0,\n",
            "                        1.0,\n",
            "                        0.999375,\n",
            "                        1.0,\n",
            "                        1.0],\n",
            "             'f1-score': [0.999687597625742,\n",
            "                          0.99812734082397,\n",
            "                          0.9993746091307067,\n",
            "                          0.9987484355444306,\n",
            "                          0.9990616202690022,\n",
            "                          0.9996874023132228,\n",
            "                          1.0,\n",
            "                          0.999687597625742,\n",
            "                          1.0,\n",
            "                          0.99812734082397,\n",
            "                          0.9990633780830471,\n",
            "                          1.0],\n",
            "             'support': [1600,\n",
            "                         1600,\n",
            "                         1600,\n",
            "                         1600,\n",
            "                         1600,\n",
            "                         1600,\n",
            "                         1600,\n",
            "                         1600,\n",
            "                         1600,\n",
            "                         1600,\n",
            "                         1600,\n",
            "                         1600]},\n",
            " 'delay': {'precision': [0.9987429289754871,\n",
            "                         0.9846153846153847,\n",
            "                         0.963275135460566,\n",
            "                         0.9919404835709857,\n",
            "                         0.99812734082397,\n",
            "                         0.9968847352024922,\n",
            "                         0.9864364981504316,\n",
            "                         0.9864364981504316,\n",
            "                         0.9907120743034056,\n",
            "                         0.9919404835709857,\n",
            "                         0.9987507807620237,\n",
            "                         1.0],\n",
            "           'recall': [0.993125,\n",
            "                      1.0,\n",
            "                      1.0,\n",
            "                      1.0,\n",
            "                      0.999375,\n",
            "                      1.0,\n",
            "                      1.0,\n",
            "                      1.0,\n",
            "                      1.0,\n",
            "                      1.0,\n",
            "                      0.999375,\n",
            "                      1.0],\n",
            "           'f1-score': [0.9959260419931056,\n",
            "                        0.9922480620155039,\n",
            "                        0.9812940815700706,\n",
            "                        0.9959539371304077,\n",
            "                        0.9987507807620237,\n",
            "                        0.9984399375975038,\n",
            "                        0.9931719428926133,\n",
            "                        0.9931719428926133,\n",
            "                        0.995334370139969,\n",
            "                        0.9959539371304077,\n",
            "                        0.9990627928772258,\n",
            "                        1.0],\n",
            "           'support': [1600,\n",
            "                       1600,\n",
            "                       1600,\n",
            "                       1600,\n",
            "                       1600,\n",
            "                       1600,\n",
            "                       1600,\n",
            "                       1600,\n",
            "                       1600,\n",
            "                       1600,\n",
            "                       1600,\n",
            "                       1600]},\n",
            " 'reverb': {'precision': [1.0,\n",
            "                          1.0,\n",
            "                          1.0,\n",
            "                          1.0,\n",
            "                          1.0,\n",
            "                          0.9993753903810119,\n",
            "                          0.9791921664626683,\n",
            "                          1.0,\n",
            "                          0.9968847352024922,\n",
            "                          0.9937888198757764,\n",
            "                          0.9950248756218906,\n",
            "                          0.9962640099626401],\n",
            "            'recall': [1.0,\n",
            "                       0.99875,\n",
            "                       0.99,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0,\n",
            "                       1.0],\n",
            "            'f1-score': [1.0,\n",
            "                         0.9993746091307067,\n",
            "                         0.9949748743718593,\n",
            "                         1.0,\n",
            "                         1.0,\n",
            "                         0.999687597625742,\n",
            "                         0.989486703772418,\n",
            "                         1.0,\n",
            "                         0.9984399375975038,\n",
            "                         0.9968847352024921,\n",
            "                         0.9975062344139651,\n",
            "                         0.9981285090455396],\n",
            "            'support': [1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600,\n",
            "                        1600]}}\n"
          ]
        }
      ],
      "source": [
        "# save for each effect 4 lists: precision, recall, f1, support  (all guitars together)\n",
        "\n",
        "ROOTH_1 = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/1__dataset_1_fixed'\n",
        "ROOTH_2 = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/2__dataset_2_params'\n",
        "ROOTH_3 = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/3__dataset_3_position'\n",
        "\n",
        "ROOTH_DEF = ROOTH_1\n",
        "dataset_number = 1\n",
        "\n",
        "EFFECTS = ['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "STATISTICS = ['precision', 'recall', 'f1-score', 'support']\n",
        "\n",
        "statistics_file_names = []\n",
        "for guitar in GUITARS:\n",
        "  name = f'statistics__dataset_{dataset_number}__guitar_{guitar}__runs_3.json'\n",
        "  statistics_file_names.append(name)\n",
        "  \n",
        "\n",
        "dict_effects_all_guitars = {'overdrive':{}, 'chorus':{}, 'tremolo':{}, 'delay':{}, 'reverb':{}}\n",
        "\n",
        "# create the structure of the dictionary\n",
        "for effect in EFFECTS:\n",
        "  for statistic in STATISTICS:\n",
        "    dict_effects_all_guitars[effect][statistic] = []\n",
        "\n",
        "for i in range(4):\n",
        "  # load statistic for a single guitar\n",
        "  path = os.path.join(ROOTH_DEF, statistics_file_names[i])\n",
        "  with open(path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  # populate the dictionary with statistics for each effect\n",
        "  for run in data:\n",
        "    for effect in EFFECTS:\n",
        "      for statistic in STATISTICS:\n",
        "        statistic_value = run[effect][statistic]\n",
        "        dict_effects_all_guitars[effect][statistic].append(statistic_value)\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(dict_effects_all_guitars, sort_dicts=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxEUMJZmXXyT"
      },
      "outputs": [],
      "source": [
        "# store\n",
        "joint_guitar_stats_path = os.path.join(ROOTH_DEF, f'joint_guit_all_stats_dataset_{dataset_number}.json')\n",
        "\n",
        "with open(joint_guitar_stats_path, 'w') as f:\n",
        "  json.dump(dict_effects_all_guitars, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eaJIC7ncHDK",
        "outputId": "96ea6827-a256-4ebf-b3c1-1193a0351463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'overdrive': {'precision': {'mean': 0.9770659160806026,\n",
            "                             'std': 0.04364371023426772},\n",
            "               'recall': {'mean': 0.9841666666666665,\n",
            "                          'std': 0.02000217002116409},\n",
            "               'f1-score': {'mean': 0.9798844871918303,\n",
            "                            'std': 0.023517461482977117},\n",
            "               'support': {'mean': 1600.0, 'std': 0.0}},\n",
            " 'chorus': {'precision': {'mean': 0.9980290550734736,\n",
            "                          'std': 0.0021328578417274093},\n",
            "            'recall': {'mean': 0.9999479166666667,\n",
            "                       'std': 0.00017274087449767336},\n",
            "            'f1-score': {'mean': 0.9989864930689971,\n",
            "                         'std': 0.0011094066740188085},\n",
            "            'support': {'mean': 1600.0, 'std': 0.0}},\n",
            " 'tremolo': {'precision': {'mean': 0.9992204063202061,\n",
            "                           'std': 0.0011698830362490127},\n",
            "             'recall': {'mean': 0.9993750000000001,\n",
            "                        'std': 0.0008068715304598613},\n",
            "             'f1-score': {'mean': 0.9992971101866529,\n",
            "                          'std': 0.0006514923870121745},\n",
            "             'support': {'mean': 1600.0, 'std': 0.0}},\n",
            " 'delay': {'precision': {'mean': 0.990655195298847,\n",
            "                         'std': 0.009738088490066719},\n",
            "           'recall': {'mean': 0.9993229166666667, 'std': 0.0018829403627630343},\n",
            "           'f1-score': {'mean': 0.9949423189167869,\n",
            "                        'std': 0.004763281302400345},\n",
            "           'support': {'mean': 1600.0, 'std': 0.0}},\n",
            " 'reverb': {'precision': {'mean': 0.99671083312554,\n",
            "                          'std': 0.005704718561477193},\n",
            "            'recall': {'mean': 0.9990625, 'std': 0.002754021680500478},\n",
            "            'f1-score': {'mean': 0.9978736000966855,\n",
            "                         'std': 0.002942095202877381},\n",
            "            'support': {'mean': 1600.0, 'std': 0.0}}}\n"
          ]
        }
      ],
      "source": [
        "# get precision, recall, f1-score, support for each effect -> mean and std\n",
        "mean_std_each_effect = {'overdrive':{}, 'chorus':{}, 'tremolo':{}, 'delay':{}, 'reverb':{}}\n",
        "for effect in EFFECTS:\n",
        "  for statistic in STATISTICS:\n",
        "    mean_std_each_effect[effect][statistic] = {'mean':0, 'std':0}\n",
        "\n",
        "for effect in EFFECTS:\n",
        "  for statistic in STATISTICS:\n",
        "    mean_value = np.mean(dict_effects_all_guitars[effect][statistic])\n",
        "    std_value =   np.std(dict_effects_all_guitars[effect][statistic])\n",
        "    mean_std_each_effect[effect][statistic]['mean'] = mean_value\n",
        "    mean_std_each_effect[effect][statistic]['std'] = std_value\n",
        "  \n",
        "pprint(mean_std_each_effect, sort_dicts=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEy_JBCnjyVE"
      },
      "outputs": [],
      "source": [
        "# store dictionary with mean and std for all statistics with guitars not distinguished\n",
        "joint_guitar_mean_std_path = os.path.join(ROOTH_DEF, f'joint_guit_mean_std_dataset_{dataset_number}.json')\n",
        "\n",
        "with open(joint_guitar_mean_std_path, 'w') as f:\n",
        "  json.dump(mean_std_each_effect, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhJCoteeffUf",
        "outputId": "acb36f95-e432-42b5-ed2f-1a884ac33464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[1563.0387910538557, 36.961208946144424],\n",
            "  [25.333333333333485, 1574.6666666666665]],\n",
            " [[1596.840425014681, 3.159574985318968],\n",
            "  [0.08333333333325754, 1599.9166666666667]],\n",
            " [[1598.7524571294725, 1.2475428705275098],\n",
            "  [0.9999999999997726, 1599.0000000000002]],\n",
            " [[1584.9174929336427, 15.082507066357346],\n",
            "  [1.0833333333332575, 1598.9166666666667]],\n",
            " [[1594.7249161200177, 5.275083879982369], [1.5, 1598.5]]]\n"
          ]
        }
      ],
      "source": [
        "# EXAMPLE\n",
        "\n",
        "# precision = mean_std_each_effect['overdrive']['precision']['mean']  # 0.9802102530436262\n",
        "# recall = mean_std_each_effect['overdrive']['recall']['mean']        # 0.9972395833333333\n",
        "# support = mean_std_each_effect['overdrive']['support']['mean']      # 1600.0\n",
        "# print(f'precision: {precision}, recall: {recall}, support: {support}')\n",
        "# TP = support * recall \n",
        "# FN = support - TP \n",
        "# FP = TP * ( (1-precision) / precision )\n",
        "# TN = support - FP\n",
        "# print(f'TP: {TP}, FN:{FN}, FP:{FP}, TN:{TN}\\n\\n')\n",
        "\n",
        "\n",
        "# compute confusion matrices starting from precision, recall, support\n",
        "confusion_matrices = {'overdrive':[], 'chorus':[], 'tremolo':[], 'delay':[], 'reverb':[]}\n",
        "\n",
        "SUPPORT = 1600\n",
        "for effect in EFFECTS:\n",
        "  precision = mean_std_each_effect[effect]['precision']['mean']\n",
        "  recall = mean_std_each_effect[effect]['recall']['mean']\n",
        "  # get elements of confusion matrix\n",
        "  TP = SUPPORT * recall \n",
        "  FN = SUPPORT - TP \n",
        "  FP = TP * ( (1-precision) / precision )\n",
        "  TN = SUPPORT - FP\n",
        "  conf_matrix = [[TN, FP], [FN, TP]]\n",
        "  # save conf matrix in dict\n",
        "  confusion_matrices[effect] = conf_matrix\n",
        "\n",
        "# save confusion matrices in a list\n",
        "confusion_matrices_list = []\n",
        "for effect in EFFECTS:\n",
        "  confusion_matrices_list.append(confusion_matrices[effect])\n",
        "\n",
        "pprint(confusion_matrices_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "2-u6chJtm5Gy",
        "outputId": "d6f02e5c-e31b-4953-cd17-a625ba198416"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x360 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot confusion matrices\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "\n",
        "def normalize_confusion_matrix(matrix):\n",
        "  return normalize(matrix, axis=1, norm='l1')\n",
        "\n",
        "def plot_confusion_matrices_from_list(confusion_matrices_array, normalize=False, decimals=2, save=False, name=None):\n",
        "\n",
        "  confusion_matrices_array = np.array(confusion_matrices_list)\n",
        "  if normalize:\n",
        "    confusion_matrices_array = np.array(list(map(normalize_confusion_matrix, confusion_matrices_array)))\n",
        "    confusion_matrices_array = np.around(confusion_matrices_array, decimals=decimals)\n",
        "  else:\n",
        "    confusion_matrices_array = np.around(confusion_matrices_array, decimals=decimals)\n",
        "\n",
        "  # plot matrices\n",
        "  fig, ax = plt.subplots(1, 5, figsize=(20, 5))\n",
        "  labels = ['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "  for index, confusion_matrix in enumerate(confusion_matrices_array):\n",
        "    ax[index].matshow(confusion_matrix, cmap=plt.cm.Blues, alpha=0.5)\n",
        "    for i in range(confusion_matrix.shape[0]):\n",
        "      for j in range(confusion_matrix.shape[1]):\n",
        "          ax[index].text(x=j, y=i, s=confusion_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        "          ax[index].set_title(labels[index], size='xx-large')\n",
        "          ax[index].set_xlabel('predicted label')\n",
        "          ax[index].set_ylabel('true label')\n",
        " \n",
        "  if save:\n",
        "    save_path = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/4__plots/' + name + '.png'\n",
        "    plt.savefig(save_path)\n",
        "  plt.show()\n",
        "\n",
        "plot_confusion_matrices_from_list(confusion_matrices_list, True, decimals=2, save=True, name=f'conf_matrices_dataset_{dataset_number}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "peF6Y6WwPDg1",
        "outputId": "1ed0e07c-9de2-4574-8027-3a1b2269791b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot f1-score mean and variance for each effect separately\n",
        "\n",
        "path = os.path.join(ROOTH_DEF, f'joint_guit_mean_std_dataset_{dataset_number}.json')\n",
        "\n",
        "with open(path, 'r') as f:\n",
        "  statistics_mean_var = json.load(f)\n",
        "\n",
        "mean_values = []\n",
        "std_values = []\n",
        "\n",
        "for effect in EFFECTS:\n",
        "  mean = statistics_mean_var[effect]['f1-score']['mean']\n",
        "  std = statistics_mean_var[effect]['f1-score']['std']\n",
        "  mean_values.append(mean)\n",
        "  std_values.append(std)\n",
        "\n",
        "# actual plot\n",
        "def plot_bar_plot_mean_std(labels, mean_values, std_values, save=False, name=None):\n",
        "  plt.figure(figsize=(8,5))\n",
        "  plt.bar(labels, mean_values, yerr=std_values, color=(0.2, 0.4, 0.6, 0.8),  ecolor='black', capsize=10)\n",
        "  plt.ylabel('F1-score')\n",
        "  plt.xlabel('Effect')\n",
        "\n",
        "  if save:\n",
        "    save_path = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/4__plots/' + name + '.png'\n",
        "    plt.savefig(save_path)\n",
        "  plt.show()\n",
        "\n",
        "plot_bar_plot_mean_std(EFFECTS, mean_values, std_values, save=True, name=f'f1_dataset_{dataset_number}_all_guit')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PctqVHoelLUf"
      },
      "source": [
        "#### GET F1 SCORE FOR EACH GUITAR AND EFFECT SEPARATELY (AVERAGING AMONG DATASETS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cz750wc2WTt"
      },
      "outputs": [],
      "source": [
        "# get f1-score value for each guitar separately NEW\n",
        "import json\n",
        "from pprint import pprint\n",
        "\n",
        "EFFECTS = ['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "GUITARS = ['les', 'prs','str', 'tele']\n",
        "\n",
        "path_dataset_1 = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/1__dataset_1_fixed/joint_guit_all_stats_dataset_1.json'\n",
        "path_dataset_2 = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/2__dataset_2_params/joint_guit_all_stats_dataset_2.json'\n",
        "path_dataset_3 = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/3__dataset_3_position/joint_guit_all_stats_dataset_3.json'\n",
        "\n",
        "stats_all_datasets = []\n",
        "\n",
        "with open(path_dataset_1, 'r') as f:\n",
        "  stats_dataset_1 = json.load(f)\n",
        "  stats_all_datasets.append(stats_dataset_1)\n",
        "\n",
        "with open(path_dataset_2, 'r') as f:\n",
        "  stats_dataset_2 = json.load(f)\n",
        "  stats_all_datasets.append(stats_dataset_2)\n",
        "\n",
        "with open(path_dataset_3, 'r') as f:\n",
        "  stats_dataset_3 = json.load(f)\n",
        "  stats_all_datasets.append(stats_dataset_3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itlV4FbB3uIB",
        "outputId": "9c9e3a19-ae7e-4a27-800b-9f0911d21d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'overdrive': [0.978287841191067,\n",
            "               0.9131058216231717,\n",
            "               0.9628275441803779,\n",
            "               0.97796817625459,\n",
            "               0.9310445155659005,\n",
            "               0.9922287845819087,\n",
            "               0.9517282479141835,\n",
            "               0.8577563070316693,\n",
            "               0.8786381109280614],\n",
            " 'chorus': [0.9993753903810119,\n",
            "            0.9987515605493134,\n",
            "            0.9993753903810119,\n",
            "            0.9867004433185561,\n",
            "            0.9737010904425913,\n",
            "            0.9767156862745098,\n",
            "            0.9893216080402011,\n",
            "            0.9828353464717101,\n",
            "            0.9877397044954417],\n",
            " 'tremolo': [0.999687597625742,\n",
            "             0.99812734082397,\n",
            "             0.9993746091307067,\n",
            "             0.9531297248261265,\n",
            "             0.9638407778790642,\n",
            "             0.9657747355320472,\n",
            "             0.9204413472706156,\n",
            "             0.9511220411927451,\n",
            "             0.8689509007417873],\n",
            " 'delay': [0.9959260419931056,\n",
            "           0.9922480620155039,\n",
            "           0.9812940815700706,\n",
            "           0.8934707903780068,\n",
            "           0.9838509316770186,\n",
            "           0.9772447724477246,\n",
            "           0.9661954517516902,\n",
            "           0.9599260172626388,\n",
            "           0.9606201550387596],\n",
            " 'reverb': [1.0,\n",
            "            0.9993746091307067,\n",
            "            0.9949748743718593,\n",
            "            0.9990633780830471,\n",
            "            0.9978172747115684,\n",
            "            0.999375,\n",
            "            0.9889415481832544,\n",
            "            0.9990633780830471,\n",
            "            0.9993746091307067]}\n"
          ]
        }
      ],
      "source": [
        "les_f1_all_datasets = {'overdrive':[], 'chorus':[], 'tremolo':[], 'delay':[], 'reverb':[]}\n",
        "prs_f1_all_datasets = {'overdrive':[], 'chorus':[], 'tremolo':[], 'delay':[], 'reverb':[]}\n",
        "str_f1_all_datasets = {'overdrive':[], 'chorus':[], 'tremolo':[], 'delay':[], 'reverb':[]}\n",
        "tele_f1_all_datasets = {'overdrive':[], 'chorus':[], 'tremolo':[], 'delay':[], 'reverb':[]}\n",
        "\n",
        "# pprint(stats_all_datasets[0]['chorus']['f1-score'], sort_dicts=False)\n",
        "# pprint(stats_all_datasets[1]['chorus']['f1-score'], sort_dicts=False)\n",
        "# pprint(stats_all_datasets[2]['chorus']['f1-score'], sort_dicts=False)\n",
        "\n",
        "# les\n",
        "for stat_single_dataset in stats_all_datasets:\n",
        "  for effect in EFFECTS:\n",
        "    for i in (0,1,2):\n",
        "      f1_value = stat_single_dataset[effect]['f1-score'][i]\n",
        "      les_f1_all_datasets[effect].append(f1_value)\n",
        "\n",
        "# prs\n",
        "for stat_single_dataset in stats_all_datasets:\n",
        "  for effect in EFFECTS:\n",
        "    for i in (3,4,5):\n",
        "      f1_value = stat_single_dataset[effect]['f1-score'][i]\n",
        "      prs_f1_all_datasets[effect].append(f1_value)\n",
        "\n",
        "# str\n",
        "for stat_single_dataset in stats_all_datasets:\n",
        "  for effect in EFFECTS:\n",
        "    for i in (6,7,8):\n",
        "      f1_value = stat_single_dataset[effect]['f1-score'][i]\n",
        "      str_f1_all_datasets[effect].append(f1_value)\n",
        "\n",
        "# tele\n",
        "for stat_single_dataset in stats_all_datasets:\n",
        "  for effect in EFFECTS:\n",
        "    for i in (9,10,11):\n",
        "      f1_value = stat_single_dataset[effect]['f1-score'][i]\n",
        "      tele_f1_all_datasets[effect].append(f1_value)\n",
        "\n",
        "\n",
        "pprint(les_f1_all_datasets, sort_dicts=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S47573BdCGZw",
        "outputId": "8c7678e4-6249-46ec-a2df-31f7946d4fae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'les': {'overdrive': {'mean': 0.9381761499189921, 'std': 0.0442177714851508},\n",
            "         'chorus': {'mean': 0.988279580039372, 'std': 0.009041036247663383},\n",
            "         'tremolo': {'mean': 0.9578276750025339, 'std': 0.04022938652966638},\n",
            "         'delay': {'mean': 0.9678640337927242, 'std': 0.028980121921392134},\n",
            "         'reverb': {'mean': 0.9975538524104655, 'std': 0.0033562572621563583}},\n",
            " 'prs': {'overdrive': {'mean': 0.9925746265897144, 'std': 0.01078547578135084},\n",
            "         'chorus': {'mean': 0.9826764851423947, 'std': 0.025170176509837605},\n",
            "         'tremolo': {'mean': 0.9684930420114648, 'std': 0.02311418336828296},\n",
            "         'delay': {'mean': 0.9802796323002442, 'std': 0.016243396992604492},\n",
            "         'reverb': {'mean': 0.9996875323995494, 'std': 0.0003293013764875062}},\n",
            " 'str': {'overdrive': {'mean': 0.9842634277430284, 'std': 0.00868928653341254},\n",
            "         'chorus': {'mean': 0.9786477300605352, 'std': 0.03636472205105556},\n",
            "         'tremolo': {'mean': 0.9483330521941598, 'std': 0.08615102791804795},\n",
            "         'delay': {'mean': 0.9711784234151639, 'std': 0.02887233214661743},\n",
            "         'reverb': {'mean': 0.9948729671505152, 'std': 0.009753677850455321}},\n",
            " 'tele': {'overdrive': {'mean': 0.9827027920698987,\n",
            "                        'std': 0.024875550154981912},\n",
            "          'chorus': {'mean': 0.9885669465760935, 'std': 0.008850744070355368},\n",
            "          'tremolo': {'mean': 0.968338395504088, 'std': 0.027489303934738536},\n",
            "          'delay': {'mean': 0.9843432486048366, 'std': 0.018466070629314005},\n",
            "          'reverb': {'mean': 0.9986130794291529, 'std': 0.0008943740383902265}}}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "les_f1_mean_std =  {'overdrive':{}, 'chorus':{}, 'tremolo':{}, 'delay':{}, 'reverb':{}}\n",
        "prs_f1_mean_std =  {'overdrive':{}, 'chorus':{}, 'tremolo':{}, 'delay':{}, 'reverb':{}}\n",
        "str_f1_mean_std =  {'overdrive':{}, 'chorus':{}, 'tremolo':{}, 'delay':{}, 'reverb':{}}\n",
        "tele_f1_mean_std = {'overdrive':{}, 'chorus':{}, 'tremolo':{}, 'delay':{}, 'reverb':{}}\n",
        "\n",
        "\n",
        "for effect in EFFECTS:\n",
        "  mean = np.mean(les_f1_all_datasets[effect])\n",
        "  std = np.std(les_f1_all_datasets[effect])\n",
        "  les_f1_mean_std[effect]['mean'] = mean\n",
        "  les_f1_mean_std[effect]['std'] = std\n",
        "\n",
        "for effect in EFFECTS:\n",
        "  mean = np.mean(prs_f1_all_datasets[effect])\n",
        "  std = np.std(prs_f1_all_datasets[effect])\n",
        "  prs_f1_mean_std[effect]['mean'] = mean\n",
        "  prs_f1_mean_std[effect]['std'] = std\n",
        "\n",
        "for effect in EFFECTS:\n",
        "  mean = np.mean(str_f1_all_datasets[effect])\n",
        "  std = np.std(str_f1_all_datasets[effect])\n",
        "  str_f1_mean_std[effect]['mean'] = mean\n",
        "  str_f1_mean_std[effect]['std'] = std\n",
        "\n",
        "for effect in EFFECTS:\n",
        "  mean = np.mean(tele_f1_all_datasets[effect])\n",
        "  std = np.std(tele_f1_all_datasets[effect])\n",
        "  tele_f1_mean_std[effect]['mean'] = mean\n",
        "  tele_f1_mean_std[effect]['std'] = std\n",
        "\n",
        "\n",
        "\n",
        "f1_mean_std = {'les': les_f1_mean_std, 'prs': prs_f1_mean_std,'str': str_f1_mean_std, 'tele': tele_f1_mean_std}\n",
        "\n",
        "pprint(f1_mean_std, sort_dicts=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzkzMVc6EwRS",
        "outputId": "2e6df20c-99b0-4771-e09d-b13f3d29d3c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'overdrive': [0.9381761499189921,\n",
            "               0.9925746265897144,\n",
            "               0.9842634277430284,\n",
            "               0.9827027920698987],\n",
            " 'chorus': [0.988279580039372,\n",
            "            0.9826764851423947,\n",
            "            0.9786477300605352,\n",
            "            0.9885669465760935],\n",
            " 'tremolo': [0.9578276750025339,\n",
            "             0.9684930420114648,\n",
            "             0.9483330521941598,\n",
            "             0.968338395504088],\n",
            " 'delay': [0.9678640337927242,\n",
            "           0.9802796323002442,\n",
            "           0.9711784234151639,\n",
            "           0.9843432486048366],\n",
            " 'reverb': [0.9975538524104655,\n",
            "            0.9996875323995494,\n",
            "            0.9948729671505152,\n",
            "            0.9986130794291529]}\n"
          ]
        }
      ],
      "source": [
        "# save mean vector and std vector for each effect\n",
        "# the position on the list indivate the corresponding guitar\n",
        "\n",
        "# for each effect I have the mean value for each guitar es [0.9, 0.83, 0.88, 0.8]\n",
        "mean_dict_each_effect = {'overdrive':[], 'chorus':[], 'tremolo':[], 'delay':[], 'reverb':[]}\n",
        "std_dict_each_effect = {'overdrive':[], 'chorus':[], 'tremolo':[], 'delay':[], 'reverb':[]}\n",
        "\n",
        "for effect in EFFECTS:\n",
        "  for guitar in GUITARS:\n",
        "\n",
        "    mean = f1_mean_std[guitar][effect]['mean']\n",
        "    std = f1_mean_std[guitar][effect]['std']\n",
        "\n",
        "    mean_dict_each_effect[effect].append(mean)\n",
        "    std_dict_each_effect[effect].append(std)\n",
        "\n",
        "\n",
        "pprint(mean_dict_each_effect, sort_dicts=False)\n",
        "#pprint(std_dict_each_effect, sort_dicts=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imEkpQ7JsJkX",
        "outputId": "e15b3d5b-37f8-4af7-86aa-a8d55e2139e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9711784234151639"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = 0.999687597625742 + 0.99812734082397 + 0.9993746091307067 + 0.9531297248261265 + 0.9638407778790642 + 0.9657747355320472 + 0.9204413472706156 + 0.9511220411927451 + 0.8689509007417873\n",
        "b = a/9\n",
        "a2 = 0.9931719428926133 + 0.9931719428926133 + 0.995334370139969 + 0.9878542510121456 + 0.984934086629002 + 0.984481688392303 + 0.9482758620689655 + 0.9469943737044715 + 0.9063872930043934\n",
        "b2 = a2/9\n",
        "b2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "sOP5n0xpEbyW",
        "outputId": "f976a333-5d85-4d73-a16a-09d1b3d5b667"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# constants\n",
        "x_values = np.arange(4)\n",
        "width = 0.15\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# create bars\n",
        "bar_position = (-2,-1,0,1,2)\n",
        "for effect, bar_pos in zip(EFFECTS, bar_position):\n",
        "  plt.bar(x_values + bar_pos*width, mean_dict_each_effect[effect], yerr=std_dict_each_effect[effect], width=width)\n",
        "\n",
        "plt.xticks(x_values, GUITARS)\n",
        "plt.legend(EFFECTS, loc='lower right')\n",
        "plt.title('F1-score averaging the 3 datasets')\n",
        "plt.ylabel('F1-score')\n",
        "plt.xlabel('test set')\n",
        "\n",
        "save_path = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/4__plots/' + 'f1_each_guitar_each_effect' + '.png'\n",
        "plt.savefig(save_path)\n",
        "\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_jDw5VO76lz"
      },
      "source": [
        "### new not used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaZUC6MYorN8",
        "outputId": "de1175c0-539b-4e20-d5cf-c44c90f29e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'les': ['/content/drive/MyDrive/Colab '\n",
            "         'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/1__dataset_1_fixed/statistics__dataset_1__guitar_les__runs_3.json',\n",
            "         '/content/drive/MyDrive/Colab '\n",
            "         'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/2__dataset_2_params/statistics__dataset_2__guitar_les__runs_3.json',\n",
            "         '/content/drive/MyDrive/Colab '\n",
            "         'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/3__dataset_3_position/statistics__dataset_3__guitar_les__runs_3.json'],\n",
            " 'prs': ['/content/drive/MyDrive/Colab '\n",
            "         'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/1__dataset_1_fixed/statistics__dataset_1__guitar_prs__runs_3.json',\n",
            "         '/content/drive/MyDrive/Colab '\n",
            "         'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/2__dataset_2_params/statistics__dataset_2__guitar_prs__runs_3.json',\n",
            "         '/content/drive/MyDrive/Colab '\n",
            "         'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/3__dataset_3_position/statistics__dataset_3__guitar_prs__runs_3.json'],\n",
            " 'str': ['/content/drive/MyDrive/Colab '\n",
            "         'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/1__dataset_1_fixed/statistics__dataset_1__guitar_str__runs_3.json',\n",
            "         '/content/drive/MyDrive/Colab '\n",
            "         'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/2__dataset_2_params/statistics__dataset_2__guitar_str__runs_3.json',\n",
            "         '/content/drive/MyDrive/Colab '\n",
            "         'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/3__dataset_3_position/statistics__dataset_3__guitar_str__runs_3.json'],\n",
            " 'tele': ['/content/drive/MyDrive/Colab '\n",
            "          'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/1__dataset_1_fixed/statistics__dataset_1__guitar_tele__runs_3.json',\n",
            "          '/content/drive/MyDrive/Colab '\n",
            "          'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/2__dataset_2_params/statistics__dataset_2__guitar_tele__runs_3.json',\n",
            "          '/content/drive/MyDrive/Colab '\n",
            "          'Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/3__dataset_3_position/statistics__dataset_3__guitar_tele__runs_3.json']}\n"
          ]
        }
      ],
      "source": [
        "# get f1-score value for each guitar separately\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "\n",
        "GUITARS = ['les', 'prs','str', 'tele']\n",
        "EFFECTS = ['overdrive', 'chorus', 'tremolo', 'delay', 'reverb']\n",
        "STATISTICS = ['precision', 'recall', 'f1-score', 'support']\n",
        "\n",
        "path_dataset_1 = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/1__dataset_1_fixed/statistics__dataset_1__guitar_'\n",
        "path_dataset_2 = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/2__dataset_2_params/statistics__dataset_2__guitar_'\n",
        "path_dataset_3 = '/content/drive/MyDrive/Colab Notebooks/5__paper_effects/3__statistics/2__each_guitar_as_test/3__dataset_3_position/statistics__dataset_3__guitar_'\n",
        "end_path = '__runs_3.json'\n",
        "\n",
        "# get path for each guitar and dataset\n",
        "paths_each_guitar = {'les': [], 'prs': [],'str': [], 'tele': []}\n",
        "for guitar in GUITARS:\n",
        "  path_1 = path_dataset_1 + guitar + end_path\n",
        "  path_2 = path_dataset_2 + guitar + end_path\n",
        "  path_3 = path_dataset_3 + guitar + end_path\n",
        "  paths_each_guitar[guitar] = [path_1, path_2, path_3]\n",
        "\n",
        "pprint(paths_each_guitar, sort_dicts=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msrtodsyvKzS",
        "outputId": "ac5e415d-896f-428e-aff5-4d652ac7b8f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'les': [{'overdrive': {'precision': 0.9710591133004927,\n",
            "                        'recall': 0.985625,\n",
            "                        'f1-score': 0.978287841191067,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9987515605493134,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9993753903810119,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9993753903810119,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 0.999687597625742,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9987429289754871,\n",
            "                    'recall': 0.993125,\n",
            "                    'f1-score': 0.9959260419931056,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 1.0,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9935145921676228,\n",
            "                        'recall': 0.99575,\n",
            "                        'f1-score': 0.9946310400799102,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9935857986412611,\n",
            "                        'recall': 0.9957499999999999,\n",
            "                        'f1-score': 0.9946553742381854,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.993585798641261,\n",
            "                           'recall': 0.99575,\n",
            "                           'f1-score': 0.9946553742381853,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9628072916666668,\n",
            "                          'recall': 0.96375,\n",
            "                          'f1-score': 0.9622958829365079,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.8436671966083731,\n",
            "                        'recall': 0.995,\n",
            "                        'f1-score': 0.9131058216231717,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9975062344139651,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9987515605493134,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9968827930174564,\n",
            "                      'recall': 0.999375,\n",
            "                      'f1-score': 0.99812734082397,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9846153846153847,\n",
            "                    'recall': 1.0,\n",
            "                    'f1-score': 0.9922480620155039,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 0.99875,\n",
            "                     'f1-score': 0.9993746091307067,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9604472228901179,\n",
            "                        'recall': 0.998625,\n",
            "                        'f1-score': 0.9791641132491726,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9645343217310358,\n",
            "                        'recall': 0.998625,\n",
            "                        'f1-score': 0.980321478828533,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9645343217310358,\n",
            "                           'recall': 0.998625,\n",
            "                           'f1-score': 0.9803214788285332,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9367656249999999,\n",
            "                          'recall': 0.9671614583333334,\n",
            "                          'f1-score': 0.9482127976190478,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.93935790725327,\n",
            "                        'recall': 0.9875,\n",
            "                        'f1-score': 0.9628275441803779,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9987515605493134,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9993753903810119,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 1.0,\n",
            "                      'recall': 0.99875,\n",
            "                      'f1-score': 0.9993746091307067,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.963275135460566,\n",
            "                    'recall': 1.0,\n",
            "                    'f1-score': 0.9812940815700706,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 0.99,\n",
            "                     'f1-score': 0.9949748743718593,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9796973052787006,\n",
            "                        'recall': 0.99525,\n",
            "                        'f1-score': 0.9874124139641595,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9802769206526298,\n",
            "                        'recall': 0.9952500000000001,\n",
            "                        'f1-score': 0.9875692999268052,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9802769206526298,\n",
            "                           'recall': 0.99525,\n",
            "                           'f1-score': 0.9875692999268053,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9514427083333333,\n",
            "                          'recall': 0.9643437499999998,\n",
            "                          'f1-score': 0.9554756944444444,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.9580335731414868,\n",
            "                        'recall': 0.99875,\n",
            "                        'f1-score': 0.97796817625459,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 1.0,\n",
            "                     'recall': 0.97375,\n",
            "                     'f1-score': 0.9867004433185561,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9232571763327475,\n",
            "                      'recall': 0.985,\n",
            "                      'f1-score': 0.9531297248261265,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9923664122137404,\n",
            "                    'recall': 0.8125,\n",
            "                    'f1-score': 0.8934707903780068,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9981285090455396,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9990633780830471,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9727249553912822,\n",
            "                        'recall': 0.954,\n",
            "                        'f1-score': 0.9632714880726998,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.974357134146703,\n",
            "                        'recall': 0.954,\n",
            "                        'f1-score': 0.9620665025720653,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9743571341467029,\n",
            "                           'recall': 0.954,\n",
            "                           'f1-score': 0.9620665025720654,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9422604166666667,\n",
            "                          'recall': 0.9287864583333334,\n",
            "                          'f1-score': 0.9299181547619049,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.8709853021230267,\n",
            "                        'recall': 1.0,\n",
            "                        'f1-score': 0.9310445155659005,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 1.0,\n",
            "                     'recall': 0.94875,\n",
            "                     'f1-score': 0.9737010904425913,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.937906564163217,\n",
            "                      'recall': 0.99125,\n",
            "                      'f1-score': 0.9638407778790642,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9777777777777777,\n",
            "                    'recall': 0.99,\n",
            "                    'f1-score': 0.9838509316770186,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9956440572495333,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9978172747115684,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9534630726459568,\n",
            "                        'recall': 0.986,\n",
            "                        'f1-score': 0.9694586124254901,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.956462740262711,\n",
            "                        'recall': 0.986,\n",
            "                        'f1-score': 0.9700509180552286,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9564627402627109,\n",
            "                           'recall': 0.986,\n",
            "                           'f1-score': 0.9700509180552286,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9310572916666666,\n",
            "                          'recall': 0.9580937499999999,\n",
            "                          'f1-score': 0.9394843750000001,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.987012987012987,\n",
            "                        'recall': 0.9975,\n",
            "                        'f1-score': 0.9922287845819087,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9579326923076923,\n",
            "                     'recall': 0.99625,\n",
            "                     'f1-score': 0.9767156862745098,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9615861214374225,\n",
            "                      'recall': 0.97,\n",
            "                      'f1-score': 0.9657747355320472,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.961864406779661,\n",
            "                    'recall': 0.993125,\n",
            "                    'f1-score': 0.9772447724477246,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.999375,\n",
            "                     'recall': 0.999375,\n",
            "                     'f1-score': 0.999375,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9733644286240334,\n",
            "                        'recall': 0.99125,\n",
            "                        'f1-score': 0.9822258004582894,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9735542415075524,\n",
            "                        'recall': 0.99125,\n",
            "                        'f1-score': 0.9822677957672381,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9735542415075525,\n",
            "                           'recall': 0.99125,\n",
            "                           'f1-score': 0.982267795767238,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9479010416666667,\n",
            "                          'recall': 0.9621145833333332,\n",
            "                          'f1-score': 0.9520935019841269,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.9094533029612756,\n",
            "                        'recall': 0.998125,\n",
            "                        'f1-score': 0.9517282479141835,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9943181818181818,\n",
            "                     'recall': 0.984375,\n",
            "                     'f1-score': 0.9893216080402011,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.8595444685466378,\n",
            "                      'recall': 0.990625,\n",
            "                      'f1-score': 0.9204413472706156,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9504232164449818,\n",
            "                    'recall': 0.9825,\n",
            "                    'f1-score': 0.9661954517516902,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 0.978125,\n",
            "                     'f1-score': 0.9889415481832544,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9394263953349994,\n",
            "                        'recall': 0.98675,\n",
            "                        'f1-score': 0.9625068585014936,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9427478339542154,\n",
            "                        'recall': 0.98675,\n",
            "                        'f1-score': 0.9633256406319891,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9427478339542154,\n",
            "                           'recall': 0.98675,\n",
            "                           'f1-score': 0.963325640631989,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.92153125,\n",
            "                          'recall': 0.9588177083333332,\n",
            "                          'f1-score': 0.9344218749999998,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.7516462841015993,\n",
            "                        'recall': 0.99875,\n",
            "                        'f1-score': 0.8577563070316693,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 1.0,\n",
            "                     'recall': 0.96625,\n",
            "                     'f1-score': 0.9828353464717101,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9358741681790683,\n",
            "                      'recall': 0.966875,\n",
            "                      'f1-score': 0.9511220411927451,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9470802919708029,\n",
            "                    'recall': 0.973125,\n",
            "                    'f1-score': 0.9599260172626388,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9981285090455396,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9990633780830471,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9155389640690621,\n",
            "                        'recall': 0.981,\n",
            "                        'f1-score': 0.9471397538015931,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9265458506594019,\n",
            "                        'recall': 0.9810000000000001,\n",
            "                        'f1-score': 0.950140618008362,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9265458506594021,\n",
            "                           'recall': 0.981,\n",
            "                           'f1-score': 0.9501406180083621,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.8983541666666668,\n",
            "                          'recall': 0.9546041666666667,\n",
            "                          'f1-score': 0.9171081349206349,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.7835455435847208,\n",
            "                        'recall': 1.0,\n",
            "                        'f1-score': 0.8786381109280614,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9936748893105629,\n",
            "                     'recall': 0.981875,\n",
            "                     'f1-score': 0.9877397044954417,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9991876523151909,\n",
            "                      'recall': 0.76875,\n",
            "                      'f1-score': 0.8689509007417873,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9532307692307692,\n",
            "                    'recall': 0.968125,\n",
            "                    'f1-score': 0.9606201550387596,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 0.99875,\n",
            "                     'f1-score': 0.9993746091307067,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9345053856629937,\n",
            "                        'recall': 0.9435,\n",
            "                        'f1-score': 0.938981153200224,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9459277708882489,\n",
            "                        'recall': 0.9435,\n",
            "                        'f1-score': 0.9390646960669514,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9459277708882488,\n",
            "                           'recall': 0.9435,\n",
            "                           'f1-score': 0.9390646960669512,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.91025,\n",
            "                          'recall': 0.9193437499999999,\n",
            "                          'f1-score': 0.9062534722222222,\n",
            "                          'support': 8000}}],\n",
            " 'prs': [{'overdrive': {'precision': 1.0,\n",
            "                        'recall': 0.985,\n",
            "                        'f1-score': 0.9924433249370278,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9975062344139651,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9987515605493134,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 1.0,\n",
            "                      'recall': 0.9975,\n",
            "                      'f1-score': 0.9987484355444306,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9919404835709857,\n",
            "                    'recall': 1.0,\n",
            "                    'f1-score': 0.9959539371304077,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 1.0,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.99787207410189,\n",
            "                        'recall': 0.9965,\n",
            "                        'f1-score': 0.9971855650759898,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9978893435969901,\n",
            "                        'recall': 0.9964999999999999,\n",
            "                        'f1-score': 0.9971794516322359,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9978893435969901,\n",
            "                           'recall': 0.9965,\n",
            "                           'f1-score': 0.997179451632236,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.96515625,\n",
            "                          'recall': 0.9644947916666666,\n",
            "                          'f1-score': 0.9642524801587302,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.9943538268506901,\n",
            "                        'recall': 0.990625,\n",
            "                        'f1-score': 0.9924859110832811,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9981285090455396,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9990633780830471,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 1.0,\n",
            "                      'recall': 0.998125,\n",
            "                      'f1-score': 0.9990616202690022,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.99812734082397,\n",
            "                    'recall': 0.999375,\n",
            "                    'f1-score': 0.9987507807620237,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 1.0,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9981240620310156,\n",
            "                        'recall': 0.997625,\n",
            "                        'f1-score': 0.9978744686171543,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.99812193534404,\n",
            "                        'recall': 0.997625,\n",
            "                        'f1-score': 0.9978723380394708,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9981219353440399,\n",
            "                           'recall': 0.997625,\n",
            "                           'f1-score': 0.9978723380394708,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9670885416666667,\n",
            "                          'recall': 0.9668541666666667,\n",
            "                          'f1-score': 0.9665634920634922,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.999375,\n",
            "                        'recall': 0.999375,\n",
            "                        'f1-score': 0.999375,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 1.0,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 1.0,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 1.0,\n",
            "                      'recall': 0.999375,\n",
            "                      'f1-score': 0.9996874023132228,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9968847352024922,\n",
            "                    'recall': 1.0,\n",
            "                    'f1-score': 0.9984399375975038,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9993753903810119,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.999687597625742,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9991255465334166,\n",
            "                        'recall': 0.99975,\n",
            "                        'f1-score': 0.9994376757263355,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9991270251167009,\n",
            "                        'recall': 0.99975,\n",
            "                        'f1-score': 0.9994379875072937,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9991270251167008,\n",
            "                           'recall': 0.99975,\n",
            "                           'f1-score': 0.9994379875072936,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9680208333333333,\n",
            "                          'recall': 0.9685833333333334,\n",
            "                          'f1-score': 0.9681944444444445,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 1.0,\n",
            "                        'recall': 0.99875,\n",
            "                        'f1-score': 0.9993746091307067,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9993642720915448,\n",
            "                     'recall': 0.9825,\n",
            "                     'f1-score': 0.9908603844941696,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9305882352941176,\n",
            "                      'recall': 0.98875,\n",
            "                      'f1-score': 0.9587878787878787,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9137931034482759,\n",
            "                    'recall': 0.99375,\n",
            "                    'f1-score': 0.9520958083832336,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 0.99875,\n",
            "                     'f1-score': 0.9993746091307067,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.96723108783043,\n",
            "                        'recall': 0.9925,\n",
            "                        'f1-score': 0.9797026343389474,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9687491221667877,\n",
            "                        'recall': 0.9925,\n",
            "                        'f1-score': 0.980098657985339,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9687491221667877,\n",
            "                           'recall': 0.9925,\n",
            "                           'f1-score': 0.980098657985339,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9441041666666666,\n",
            "                          'recall': 0.9623385416666668,\n",
            "                          'f1-score': 0.9501778273809524,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.9993753903810119,\n",
            "                        'recall': 1.0,\n",
            "                        'f1-score': 0.999687597625742,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9987381703470032,\n",
            "                     'recall': 0.989375,\n",
            "                     'f1-score': 0.9940345368916798,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.8788046485888212,\n",
            "                      'recall': 0.9925,\n",
            "                      'f1-score': 0.9321984150278838,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9900435594275047,\n",
            "                    'recall': 0.994375,\n",
            "                    'f1-score': 0.992204552541316,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 1.0,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9709756097560975,\n",
            "                        'recall': 0.99525,\n",
            "                        'f1-score': 0.9829629629629629,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9733923537488682,\n",
            "                        'recall': 0.9952500000000001,\n",
            "                        'f1-score': 0.9836250204173244,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9733923537488682,\n",
            "                           'recall': 0.99525,\n",
            "                           'f1-score': 0.9836250204173244,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9459479166666667,\n",
            "                          'recall': 0.9645885416666666,\n",
            "                          'f1-score': 0.9525210813492064,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.9993753903810119,\n",
            "                        'recall': 1.0,\n",
            "                        'f1-score': 0.999687597625742,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9968612680477087,\n",
            "                     'recall': 0.9925,\n",
            "                     'f1-score': 0.9946758534293768,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9158986175115207,\n",
            "                      'recall': 0.99375,\n",
            "                      'f1-score': 0.9532374100719424,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9580335731414868,\n",
            "                    'recall': 0.99875,\n",
            "                    'f1-score': 0.97796817625459,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9993753903810119,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.999687597625742,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9728015611659958,\n",
            "                        'recall': 0.997,\n",
            "                        'f1-score': 0.9847521451941478,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.973908847892548,\n",
            "                        'recall': 0.9970000000000001,\n",
            "                        'f1-score': 0.9850513270014787,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9739088478925481,\n",
            "                           'recall': 0.997,\n",
            "                           'f1-score': 0.9850513270014788,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9472812500000001,\n",
            "                          'recall': 0.9664270833333333,\n",
            "                          'f1-score': 0.9543898809523809,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.9791538933169834,\n",
            "                        'recall': 0.998125,\n",
            "                        'f1-score': 0.9885484370164036,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.993103448275862,\n",
            "                     'recall': 0.99,\n",
            "                     'f1-score': 0.9915492957746478,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9919893190921228,\n",
            "                      'recall': 0.92875,\n",
            "                      'f1-score': 0.9593285990961911,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9739938080495356,\n",
            "                    'recall': 0.983125,\n",
            "                    'f1-score': 0.9785381026438569,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 0.99875,\n",
            "                     'f1-score': 0.9993746091307067,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9875267733400529,\n",
            "                        'recall': 0.97975,\n",
            "                        'f1-score': 0.9836230156240195,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9876480937469008,\n",
            "                        'recall': 0.9797500000000001,\n",
            "                        'f1-score': 0.9834678087323612,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.987648093746901,\n",
            "                           'recall': 0.97975,\n",
            "                           'f1-score': 0.9834678087323612,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9583020833333333,\n",
            "                          'recall': 0.9533489583333332,\n",
            "                          'f1-score': 0.9532420634920635,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.9962593516209476,\n",
            "                        'recall': 0.99875,\n",
            "                        'f1-score': 0.9975031210986267,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 1.0,\n",
            "                     'recall': 0.9075,\n",
            "                     'f1-score': 0.9515072083879423,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9482968369829684,\n",
            "                      'recall': 0.974375,\n",
            "                      'f1-score': 0.9611590628853267,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9901380670611439,\n",
            "                    'recall': 0.94125,\n",
            "                    'f1-score': 0.9650752963793656,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9981285090455396,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9990633780830471,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9860685071574642,\n",
            "                        'recall': 0.964375,\n",
            "                        'f1-score': 0.9751011122345804,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9865645529421199,\n",
            "                        'recall': 0.9643750000000001,\n",
            "                        'f1-score': 0.9748616133668616,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9865645529421199,\n",
            "                           'recall': 0.964375,\n",
            "                           'f1-score': 0.9748616133668617,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9564010416666666,\n",
            "                          'recall': 0.940625,\n",
            "                          'f1-score': 0.9450310019841269,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 1.0,\n",
            "                        'recall': 0.930625,\n",
            "                        'f1-score': 0.9640660407898997,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 1.0,\n",
            "                     'recall': 0.858125,\n",
            "                     'f1-score': 0.9236461486713757,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9264273101824603,\n",
            "                      'recall': 0.98375,\n",
            "                      'f1-score': 0.9542285541073053,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9540441176470589,\n",
            "                    'recall': 0.973125,\n",
            "                    'f1-score': 0.963490099009901,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 1.0,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9743359425125112,\n",
            "                        'recall': 0.949125,\n",
            "                        'f1-score': 0.9615652504274046,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9760942855659038,\n",
            "                        'recall': 0.9491250000000001,\n",
            "                        'f1-score': 0.9610861685156962,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9760942855659038,\n",
            "                           'recall': 0.949125,\n",
            "                           'f1-score': 0.9610861685156964,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9418697916666667,\n",
            "                          'recall': 0.9206197916666667,\n",
            "                          'f1-score': 0.9253313492063492,\n",
            "                          'support': 8000}}],\n",
            " 'str': [{'overdrive': {'precision': 1.0,\n",
            "                        'recall': 0.9325,\n",
            "                        'f1-score': 0.9650711513583441,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9993753903810119,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.999687597625742,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 1.0,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 1.0,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9864364981504316,\n",
            "                    'recall': 1.0,\n",
            "                    'f1-score': 0.9931719428926133,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9791921664626683,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.989486703772418,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9928292867027299,\n",
            "                        'recall': 0.9865,\n",
            "                        'f1-score': 0.9896545237945953,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9930008109988222,\n",
            "                        'recall': 0.9865,\n",
            "                        'f1-score': 0.9894834791298234,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9930008109988223,\n",
            "                           'recall': 0.9865,\n",
            "                           'f1-score': 0.9894834791298235,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9624322916666667,\n",
            "                          'recall': 0.9570104166666666,\n",
            "                          'f1-score': 0.9581121031746034,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.990642545227698,\n",
            "                        'recall': 0.9925,\n",
            "                        'f1-score': 0.9915704027474243,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9950217797137524,\n",
            "                     'recall': 0.999375,\n",
            "                     'f1-score': 0.9971936389148739,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9993753903810119,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 0.999687597625742,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9864364981504316,\n",
            "                    'recall': 1.0,\n",
            "                    'f1-score': 0.9931719428926133,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 1.0,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9942736213120876,\n",
            "                        'recall': 0.998375,\n",
            "                        'f1-score': 0.9963200898147571,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9942952426945787,\n",
            "                        'recall': 0.998375,\n",
            "                        'f1-score': 0.9963247164361307,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9942952426945787,\n",
            "                           'recall': 0.998375,\n",
            "                           'f1-score': 0.9963247164361307,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9640520833333334,\n",
            "                          'recall': 0.9673333333333335,\n",
            "                          'f1-score': 0.9649722222222222,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 1.0,\n",
            "                        'recall': 0.950625,\n",
            "                        'f1-score': 0.9746876001281641,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9925558312655087,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9962640099626401,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 1.0,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 1.0,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9907120743034056,\n",
            "                    'recall': 1.0,\n",
            "                    'f1-score': 0.995334370139969,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9968847352024922,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9984399375975038,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9959763611215894,\n",
            "                        'recall': 0.990125,\n",
            "                        'f1-score': 0.9930420610543471,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9960305281542812,\n",
            "                        'recall': 0.9901250000000001,\n",
            "                        'f1-score': 0.9929451835656554,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9960305281542813,\n",
            "                           'recall': 0.990125,\n",
            "                           'f1-score': 0.9929451835656554,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9637916666666666,\n",
            "                          'recall': 0.9587447916666667,\n",
            "                          'f1-score': 0.9600017361111111,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 1.0,\n",
            "                        'recall': 0.9775,\n",
            "                        'f1-score': 0.988621997471555,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 1.0,\n",
            "                     'recall': 0.97125,\n",
            "                     'f1-score': 0.9854153455928979,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9980145598941098,\n",
            "                      'recall': 0.9425,\n",
            "                      'f1-score': 0.9694631951141112,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9844816883923029,\n",
            "                    'recall': 0.99125,\n",
            "                    'f1-score': 0.9878542510121456,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9981285090455396,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9990633780830471,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9960474308300395,\n",
            "                        'recall': 0.9765,\n",
            "                        'f1-score': 0.9861768604430979,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9961249514663905,\n",
            "                        'recall': 0.9765,\n",
            "                        'f1-score': 0.9860836334547514,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9961249514663905,\n",
            "                           'recall': 0.9765,\n",
            "                           'f1-score': 0.9860836334547514,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9637656250000001,\n",
            "                          'recall': 0.948015625,\n",
            "                          'f1-score': 0.9534181547619047,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.9821538461538462,\n",
            "                        'recall': 0.9975,\n",
            "                        'f1-score': 0.9897674418604652,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9968334388853705,\n",
            "                     'recall': 0.98375,\n",
            "                     'f1-score': 0.99024850581944,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9320843091334895,\n",
            "                      'recall': 0.995,\n",
            "                      'f1-score': 0.9625151148730351,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.989281210592686,\n",
            "                    'recall': 0.980625,\n",
            "                    'f1-score': 0.984934086629002,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 1.0,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9793776241047172,\n",
            "                        'recall': 0.991375,\n",
            "                        'f1-score': 0.9853397937632004,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9800705609530784,\n",
            "                        'recall': 0.991375,\n",
            "                        'f1-score': 0.9854930298363884,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9800705609530784,\n",
            "                           'recall': 0.991375,\n",
            "                           'f1-score': 0.9854930298363884,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.951484375,\n",
            "                          'recall': 0.96146875,\n",
            "                          'f1-score': 0.9540890376984127,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.9864197530864197,\n",
            "                        'recall': 0.99875,\n",
            "                        'f1-score': 0.9925465838509316,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 1.0,\n",
            "                     'recall': 0.981875,\n",
            "                     'f1-score': 0.9908546199936928,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 1.0,\n",
            "                      'recall': 0.549375,\n",
            "                      'f1-score': 0.709156918112142,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9778051787916153,\n",
            "                    'recall': 0.99125,\n",
            "                    'f1-score': 0.984481688392303,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9993753903810119,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.999687597625742,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9919100507335802,\n",
            "                        'recall': 0.90425,\n",
            "                        'f1-score': 0.9460537500817368,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9927200644518093,\n",
            "                        'recall': 0.90425,\n",
            "                        'f1-score': 0.9353454815949622,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9927200644518094,\n",
            "                           'recall': 0.90425,\n",
            "                           'f1-score': 0.9353454815949624,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9599270833333332,\n",
            "                          'recall': 0.891375,\n",
            "                          'f1-score': 0.9172410714285715,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.981226533166458,\n",
            "                        'recall': 0.98,\n",
            "                        'f1-score': 0.9806128830519074,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 1.0,\n",
            "                     'recall': 0.780625,\n",
            "                     'f1-score': 0.8767988767988768,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9701965757767914,\n",
            "                      'recall': 0.95625,\n",
            "                      'f1-score': 0.963172804532578,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9041950113378685,\n",
            "                    'recall': 0.996875,\n",
            "                    'f1-score': 0.9482758620689655,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 1.0,\n",
            "                     'recall': 0.939375,\n",
            "                     'f1-score': 0.96873992910087,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9680145624756209,\n",
            "                        'recall': 0.930625,\n",
            "                        'f1-score': 0.9489516283219681,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9711236240562237,\n",
            "                        'recall': 0.930625,\n",
            "                        'f1-score': 0.9475200711106396,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9711236240562237,\n",
            "                           'recall': 0.930625,\n",
            "                           'f1-score': 0.9475200711106396,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9398020833333334,\n",
            "                          'recall': 0.9121302083333334,\n",
            "                          'f1-score': 0.9187576884920635,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.9980769230769231,\n",
            "                        'recall': 0.973125,\n",
            "                        'f1-score': 0.9854430379746836,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9844527363184079,\n",
            "                     'recall': 0.989375,\n",
            "                     'f1-score': 0.9869077306733166,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.98468410976388,\n",
            "                      'recall': 0.964375,\n",
            "                      'f1-score': 0.9744237448689612,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.8998311761395611,\n",
            "                    'recall': 0.999375,\n",
            "                    'f1-score': 0.9469943737044715,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9975062344139651,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9987515605493134,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.9711680630852637,\n",
            "                        'recall': 0.98525,\n",
            "                        'f1-score': 0.9781583519483743,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9729102359425476,\n",
            "                        'recall': 0.98525,\n",
            "                        'f1-score': 0.9785040895541492,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9729102359425474,\n",
            "                           'recall': 0.98525,\n",
            "                           'f1-score': 0.9785040895541492,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9460364583333333,\n",
            "                          'recall': 0.9577760416666666,\n",
            "                          'f1-score': 0.9487418154761904,\n",
            "                          'support': 8000}},\n",
            "         {'overdrive': {'precision': 0.9851485148514851,\n",
            "                        'recall': 0.995,\n",
            "                        'f1-score': 0.9900497512437811,\n",
            "                        'support': 1600},\n",
            "          'chorus': {'precision': 0.9993560849967804,\n",
            "                     'recall': 0.97,\n",
            "                     'f1-score': 0.9844592451633364,\n",
            "                     'support': 1600},\n",
            "          'tremolo': {'precision': 0.9932705248990579,\n",
            "                      'recall': 0.9225,\n",
            "                      'f1-score': 0.9565780946208684,\n",
            "                      'support': 1600},\n",
            "          'delay': {'precision': 0.9867549668874173,\n",
            "                    'recall': 0.838125,\n",
            "                    'f1-score': 0.9063872930043934,\n",
            "                    'support': 1600},\n",
            "          'reverb': {'precision': 0.9993753903810119,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.999687597625742,\n",
            "                     'support': 1600},\n",
            "          'micro avg': {'precision': 0.992908732764281,\n",
            "                        'recall': 0.945125,\n",
            "                        'f1-score': 0.9684277937880242,\n",
            "                        'support': 8000},\n",
            "          'macro avg': {'precision': 0.9927810964031505,\n",
            "                        'recall': 0.945125,\n",
            "                        'f1-score': 0.9674323963316243,\n",
            "                        'support': 8000},\n",
            "          'weighted avg': {'precision': 0.9927810964031506,\n",
            "                           'recall': 0.945125,\n",
            "                           'f1-score': 0.9674323963316243,\n",
            "                           'support': 8000},\n",
            "          'samples avg': {'precision': 0.9625208333333333,\n",
            "                          'recall': 0.9264270833333333,\n",
            "                          'f1-score': 0.939530009920635,\n",
            "                          'support': 8000}}],\n",
            " 'tele': [{'overdrive': {'precision': 1.0,\n",
            "                         'recall': 0.9925,\n",
            "                         'f1-score': 0.9962358845671266,\n",
            "                         'support': 1600},\n",
            "           'chorus': {'precision': 0.9987515605493134,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 0.9993753903810119,\n",
            "                      'support': 1600},\n",
            "           'tremolo': {'precision': 0.9968827930174564,\n",
            "                       'recall': 0.999375,\n",
            "                       'f1-score': 0.99812734082397,\n",
            "                       'support': 1600},\n",
            "           'delay': {'precision': 0.9919404835709857,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9959539371304077,\n",
            "                     'support': 1600},\n",
            "           'reverb': {'precision': 0.9937888198757764,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 0.9968847352024921,\n",
            "                      'support': 1600},\n",
            "           'micro avg': {'precision': 0.9962579518523138,\n",
            "                         'recall': 0.998375,\n",
            "                         'f1-score': 0.9973153524380345,\n",
            "                         'support': 8000},\n",
            "           'macro avg': {'precision': 0.9962727314027063,\n",
            "                         'recall': 0.998375,\n",
            "                         'f1-score': 0.9973154576210016,\n",
            "                         'support': 8000},\n",
            "           'weighted avg': {'precision': 0.9962727314027063,\n",
            "                            'recall': 0.998375,\n",
            "                            'f1-score': 0.9973154576210017,\n",
            "                            'support': 8000},\n",
            "           'samples avg': {'precision': 0.9654739583333334,\n",
            "                           'recall': 0.9669791666666666,\n",
            "                           'f1-score': 0.9656746031746033,\n",
            "                           'support': 8000}},\n",
            "          {'overdrive': {'precision': 0.9937888198757764,\n",
            "                         'recall': 1.0,\n",
            "                         'f1-score': 0.9968847352024921,\n",
            "                         'support': 1600},\n",
            "           'chorus': {'precision': 1.0,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 1.0,\n",
            "                      'support': 1600},\n",
            "           'tremolo': {'precision': 0.9981285090455396,\n",
            "                       'recall': 1.0,\n",
            "                       'f1-score': 0.9990633780830471,\n",
            "                       'support': 1600},\n",
            "           'delay': {'precision': 0.9987507807620237,\n",
            "                     'recall': 0.999375,\n",
            "                     'f1-score': 0.9990627928772258,\n",
            "                     'support': 1600},\n",
            "           'reverb': {'precision': 0.9950248756218906,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 0.9975062344139651,\n",
            "                      'support': 1600},\n",
            "           'micro avg': {'precision': 0.9971328845674395,\n",
            "                         'recall': 0.999875,\n",
            "                         'f1-score': 0.9985020596679565,\n",
            "                         'support': 8000},\n",
            "           'macro avg': {'precision': 0.9971385970610461,\n",
            "                         'recall': 0.9998750000000001,\n",
            "                         'f1-score': 0.998503428115346,\n",
            "                         'support': 8000},\n",
            "           'weighted avg': {'precision': 0.9971385970610461,\n",
            "                            'recall': 0.999875,\n",
            "                            'f1-score': 0.9985034281153461,\n",
            "                            'support': 8000},\n",
            "           'samples avg': {'precision': 0.9666562500000001,\n",
            "                           'recall': 0.96859375,\n",
            "                           'f1-score': 0.9673789682539683,\n",
            "                           'support': 8000}},\n",
            "          {'overdrive': {'precision': 0.9925465838509316,\n",
            "                         'recall': 0.99875,\n",
            "                         'f1-score': 0.995638629283489,\n",
            "                         'support': 1600},\n",
            "           'chorus': {'precision': 1.0,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 1.0,\n",
            "                      'support': 1600},\n",
            "           'tremolo': {'precision': 1.0,\n",
            "                       'recall': 1.0,\n",
            "                       'f1-score': 1.0,\n",
            "                       'support': 1600},\n",
            "           'delay': {'precision': 1.0,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 1.0,\n",
            "                     'support': 1600},\n",
            "           'reverb': {'precision': 0.9962640099626401,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 0.9981285090455396,\n",
            "                      'support': 1600},\n",
            "           'micro avg': {'precision': 0.9977544910179641,\n",
            "                         'recall': 0.99975,\n",
            "                         'f1-score': 0.9987512487512487,\n",
            "                         'support': 8000},\n",
            "           'macro avg': {'precision': 0.9977621187627144,\n",
            "                         'recall': 0.99975,\n",
            "                         'f1-score': 0.9987534276658057,\n",
            "                         'support': 8000},\n",
            "           'weighted avg': {'precision': 0.9977621187627144,\n",
            "                            'recall': 0.99975,\n",
            "                            'f1-score': 0.9987534276658057,\n",
            "                            'support': 8000},\n",
            "           'samples avg': {'precision': 0.9665416666666666,\n",
            "                           'recall': 0.96828125,\n",
            "                           'f1-score': 0.9671686507936508,\n",
            "                           'support': 8000}},\n",
            "          {'overdrive': {'precision': 0.9797917942437232,\n",
            "                         'recall': 1.0,\n",
            "                         'f1-score': 0.9897927621404268,\n",
            "                         'support': 1600},\n",
            "           'chorus': {'precision': 0.9993493819128172,\n",
            "                      'recall': 0.96,\n",
            "                      'f1-score': 0.9792795664647753,\n",
            "                      'support': 1600},\n",
            "           'tremolo': {'precision': 0.9829545454545454,\n",
            "                       'recall': 0.973125,\n",
            "                       'f1-score': 0.9780150753768845,\n",
            "                       'support': 1600},\n",
            "           'delay': {'precision': 0.9845679012345679,\n",
            "                     'recall': 0.996875,\n",
            "                     'f1-score': 0.9906832298136646,\n",
            "                     'support': 1600},\n",
            "           'reverb': {'precision': 0.9981285090455396,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 0.9990633780830471,\n",
            "                      'support': 1600},\n",
            "           'micro avg': {'precision': 0.9888429234047887,\n",
            "                         'recall': 0.986,\n",
            "                         'f1-score': 0.9874194154096514,\n",
            "                         'support': 8000},\n",
            "           'macro avg': {'precision': 0.9889584263782387,\n",
            "                         'recall': 0.986,\n",
            "                         'f1-score': 0.9873668023757597,\n",
            "                         'support': 8000},\n",
            "           'weighted avg': {'precision': 0.9889584263782387,\n",
            "                            'recall': 0.986,\n",
            "                            'f1-score': 0.9873668023757597,\n",
            "                            'support': 8000},\n",
            "           'samples avg': {'precision': 0.9598177083333335,\n",
            "                           'recall': 0.9573125,\n",
            "                           'f1-score': 0.9565813492063492,\n",
            "                           'support': 8000}},\n",
            "          {'overdrive': {'precision': 1.0,\n",
            "                         'recall': 0.99875,\n",
            "                         'f1-score': 0.9993746091307067,\n",
            "                         'support': 1600},\n",
            "           'chorus': {'precision': 1.0,\n",
            "                      'recall': 0.9625,\n",
            "                      'f1-score': 0.980891719745223,\n",
            "                      'support': 1600},\n",
            "           'tremolo': {'precision': 0.9596330275229358,\n",
            "                       'recall': 0.980625,\n",
            "                       'f1-score': 0.970015455950541,\n",
            "                       'support': 1600},\n",
            "           'delay': {'precision': 0.9949843260188088,\n",
            "                     'recall': 0.991875,\n",
            "                     'f1-score': 0.9934272300469483,\n",
            "                     'support': 1600},\n",
            "           'reverb': {'precision': 0.9987515605493134,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 0.9993753903810119,\n",
            "                      'support': 1600},\n",
            "           'micro avg': {'precision': 0.9904642409033877,\n",
            "                         'recall': 0.98675,\n",
            "                         'f1-score': 0.9886036318096431,\n",
            "                         'support': 8000},\n",
            "           'macro avg': {'precision': 0.9906737828182116,\n",
            "                         'recall': 0.98675,\n",
            "                         'f1-score': 0.9886168810508862,\n",
            "                         'support': 8000},\n",
            "           'weighted avg': {'precision': 0.9906737828182115,\n",
            "                            'recall': 0.98675,\n",
            "                            'f1-score': 0.9886168810508863,\n",
            "                            'support': 8000},\n",
            "           'samples avg': {'precision': 0.960515625,\n",
            "                           'recall': 0.9577968750000001,\n",
            "                           'f1-score': 0.95735689484127,\n",
            "                           'support': 8000}},\n",
            "          {'overdrive': {'precision': 0.999375,\n",
            "                         'recall': 0.999375,\n",
            "                         'f1-score': 0.999375,\n",
            "                         'support': 1600},\n",
            "           'chorus': {'precision': 1.0,\n",
            "                      'recall': 0.985,\n",
            "                      'f1-score': 0.9924433249370278,\n",
            "                      'support': 1600},\n",
            "           'tremolo': {'precision': 0.9959866220735786,\n",
            "                       'recall': 0.930625,\n",
            "                       'f1-score': 0.9621970920840065,\n",
            "                       'support': 1600},\n",
            "           'delay': {'precision': 0.9881398252184769,\n",
            "                     'recall': 0.989375,\n",
            "                     'f1-score': 0.9887570268582137,\n",
            "                     'support': 1600},\n",
            "           'reverb': {'precision': 0.9987515605493134,\n",
            "                      'recall': 1.0,\n",
            "                      'f1-score': 0.9993753903810119,\n",
            "                      'support': 1600},\n",
            "           'micro avg': {'precision': 0.9964444444444445,\n",
            "                         'recall': 0.980875,\n",
            "                         'f1-score': 0.9885984251968505,\n",
            "                         'support': 8000},\n",
            "           'macro avg': {'precision': 0.9964506015682739,\n",
            "                         'recall': 0.9808749999999999,\n",
            "                         'f1-score': 0.9884295668520519,\n",
            "                         'support': 8000},\n",
            "           'weighted avg': {'precision': 0.9964506015682738,\n",
            "                            'recall': 0.980875,\n",
            "                            'f1-score': 0.988429566852052,\n",
            "                            'support': 8000},\n",
            "           'samples avg': {'precision': 0.9653333333333333,\n",
            "                           'recall': 0.9534010416666666,\n",
            "                           'f1-score': 0.9576125992063491,\n",
            "                           'support': 8000}},\n",
            "          {'overdrive': {'precision': 0.9009009009009009,\n",
            "                         'recall': 1.0,\n",
            "                         'f1-score': 0.947867298578199,\n",
            "                         'support': 1600},\n",
            "           'chorus': {'precision': 0.9702489374620522,\n",
            "                      'recall': 0.99875,\n",
            "                      'f1-score': 0.9842931937172774,\n",
            "                      'support': 1600},\n",
            "           'tremolo': {'precision': 0.9985754985754985,\n",
            "                       'recall': 0.87625,\n",
            "                       'f1-score': 0.9334221038615179,\n",
            "                       'support': 1600},\n",
            "           'delay': {'precision': 0.9929305912596401,\n",
            "                     'recall': 0.965625,\n",
            "                     'f1-score': 0.9790874524714829,\n",
            "                     'support': 1600},\n",
            "           'reverb': {'precision': 1.0,\n",
            "                      'recall': 0.998125,\n",
            "                      'f1-score': 0.9990616202690022,\n",
            "                      'support': 1600},\n",
            "           'micro avg': {'precision': 0.9701754385964912,\n",
            "                         'recall': 0.96775,\n",
            "                         'f1-score': 0.9689612015018774,\n",
            "                         'support': 8000},\n",
            "           'macro avg': {'precision': 0.9725311856396184,\n",
            "                         'recall': 0.96775,\n",
            "                         'f1-score': 0.9687463337794959,\n",
            "                         'support': 8000},\n",
            "           'weighted avg': {'precision': 0.9725311856396185,\n",
            "                            'recall': 0.96775,\n",
            "                            'f1-score': 0.9687463337794959,\n",
            "                            'support': 8000},\n",
            "           'samples avg': {'precision': 0.94515625,\n",
            "                           'recall': 0.9430104166666666,\n",
            "                           'f1-score': 0.9394784226190477,\n",
            "                           'support': 8000}},\n",
            "          {'overdrive': {'precision': 0.8643243243243244,\n",
            "                         'recall': 0.999375,\n",
            "                         'f1-score': 0.9269565217391305,\n",
            "                         'support': 1600},\n",
            "           'chorus': {'precision': 0.9993472584856397,\n",
            "                      'recall': 0.956875,\n",
            "                      'f1-score': 0.9776500638569604,\n",
            "                      'support': 1600},\n",
            "           'tremolo': {'precision': 0.9993174061433447,\n",
            "                       'recall': 0.915,\n",
            "                       'f1-score': 0.9553017944535074,\n",
            "                       'support': 1600},\n",
            "           'delay': {'precision': 0.8820286659316428,\n",
            "                     'recall': 1.0,\n",
            "                     'f1-score': 0.9373169302870533,\n",
            "                     'support': 1600},\n",
            "           'reverb': {'precision': 1.0,\n",
            "                      'recall': 0.999375,\n",
            "                      'f1-score': 0.9996874023132228,\n",
            "                      'support': 1600},\n",
            "           'micro avg': {'precision': 0.9434624697336562,\n",
            "                         'recall': 0.974125,\n",
            "                         'f1-score': 0.958548585485855,\n",
            "                         'support': 8000},\n",
            "           'macro avg': {'precision': 0.9490035309769903,\n",
            "                         'recall': 0.9741249999999999,\n",
            "                         'f1-score': 0.9593825425299748,\n",
            "                         'support': 8000},\n",
            "           'weighted avg': {'precision': 0.9490035309769904,\n",
            "                            'recall': 0.974125,\n",
            "                            'f1-score': 0.9593825425299749,\n",
            "                            'support': 8000},\n",
            "           'samples avg': {'precision': 0.9250052083333332,\n",
            "                           'recall': 0.9490520833333332,\n",
            "                           'f1-score': 0.9308430059523809,\n",
            "                           'support': 8000}},\n",
            "          {'overdrive': {'precision': 0.9906542056074766,\n",
            "                         'recall': 0.99375,\n",
            "                         'f1-score': 0.9921996879875196,\n",
            "                         'support': 1600},\n",
            "           'chorus': {'precision': 0.9993544222078761,\n",
            "                      'recall': 0.9675,\n",
            "                      'f1-score': 0.9831692600825659,\n",
            "                      'support': 1600},\n",
            "           'tremolo': {'precision': 0.8536193029490616,\n",
            "                       'recall': 0.995,\n",
            "                       'f1-score': 0.9189033189033189,\n",
            "                       'support': 1600},\n",
            "           'delay': {'precision': 0.9954397394136808,\n",
            "                     'recall': 0.955,\n",
            "                     'f1-score': 0.9748006379585327,\n",
            "                     'support': 1600},\n",
            "           'reverb': {'precision': 1.0,\n",
            "                      'recall': 0.996875,\n",
            "                      'f1-score': 0.9984350547730829,\n",
            "                      'support': 1600},\n",
            "           'micro avg': {'precision': 0.9636765247269604,\n",
            "                         'recall': 0.981625,\n",
            "                         'f1-score': 0.9725679608644499,\n",
            "                         'support': 8000},\n",
            "           'macro avg': {'precision': 0.9678135340356189,\n",
            "                         'recall': 0.981625,\n",
            "                         'f1-score': 0.973501591941004,\n",
            "                         'support': 8000},\n",
            "           'weighted avg': {'precision': 0.9678135340356191,\n",
            "                            'recall': 0.981625,\n",
            "                            'f1-score': 0.9735015919410038,\n",
            "                            'support': 8000},\n",
            "           'samples avg': {'precision': 0.940203125,\n",
            "                           'recall': 0.954921875,\n",
            "                           'f1-score': 0.9437388392857143,\n",
            "                           'support': 8000}}]}\n"
          ]
        }
      ],
      "source": [
        "statistics_each_guitar = {'les': [], 'prs': [],'str': [], 'tele': []}\n",
        "\n",
        "for guitar in GUITARS:\n",
        "\n",
        "  for file_index in range(3):\n",
        "    path = paths_each_guitar[guitar][file_index]\n",
        "    with open(path, 'r') as f:\n",
        "      statistics = json.load(f)\n",
        "    \n",
        "    for element in statistics:\n",
        "      statistics_each_guitar[guitar].append(element)\n",
        "    \n",
        "pprint(statistics_each_guitar, sort_dicts=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAikr5bYw9gR",
        "outputId": "6022d69d-3daa-4a04-c867-e63d23fa23f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n"
          ]
        }
      ],
      "source": [
        "# for each guitar find the f1-score for each effect\n",
        "for guitar in GUITARS:\n",
        "  print(len(statistics_each_guitar[guitar]))\n",
        "\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHY5FFuv4Dov"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "4HIk8qoVEAK0",
        "i-cElUkd1kpP",
        "tAMbPZI7DuBh",
        "vo0y2ZxXtNsd",
        "uQ2C3xWnYHu8",
        "P_jDw5VO76lz"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1ug2cyRp_KCvrJHgC2i77_Ii2Jn1rE-WS",
      "authorship_tag": "ABX9TyOosHK4lE6z388EpagbpOP6",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}